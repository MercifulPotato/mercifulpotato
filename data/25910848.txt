Item(by='mistermann', descendants=None, kids=None, score=None, time=1611620755, title=None, item_type='comment', url=None, parent=25909489, text='&gt; I think the idea of finding truth through consensus is the flaw here.<p>Oh, I&#x27;m not proposing that truth should be (or can be) defined by consensus, nor does the article.<p>This might be a decent example of the value of such a system:  if someone makes such a proposal (ie: &quot;Truth is defined by consensus.&quot;), or if someone <i>asserts that someone else had made such a proposal</i>, rather than the tweet being left as it is allowing the misinformation to propagate through the memeplex and into people&#x27;s minds (aka: <i>their reality</i>), a formal rebuttal can be attached <i>directly to it</i> (so anyone happening upon can see that <i>a collaborative consensus has been reached</i> that it is <i>plausibly</i> misinformation), which is distinctly different from the tweet being <i>declared(!) as conclusively(!) and unambiguously FALSE</i>.<p>Sometimes such distinctions are important, sometimes they are not.  In this case, the distinction is important, because of an anticipatory line I included in my comment:<p>&gt; Of course, the flaws in such a plan are numerous. Reality is complex - we can face that head on and manage it, or bury our heads in the sand with speculative claims like &quot;this wouldn&#x27;t work&quot;.<p>In this case, you seem to be asserting that this wouldn&#x27;t work, due to a specific flaw.  However, the flaw you point out is not actually valid - I think this is a legitimate demonstration of how crowdsourcing can address a situation where the truth of a matter is &quot;in play&quot;...one person suggests an idea, another person asserts that it cannot work because &lt;X&gt;, another user realizes that &lt;X&gt; is a false statement and points that out.  <i>To be clear</i>: this has not rendered the initial tweet to be True (that would be invalid logic), but it has cast significant and valid doubt on the assertion of ~&quot;Viability = False&quot; (because of a specific reason).<p>I think it wouldn&#x27;t hurt to maybe have a little primer on the basics of logic embedded somewhere in this process as well - we always talk about how the general public needs improved critical thinking, so why not teach that wherever we can?<p>I think the general idea behind Birdwatch is plausibly workable and valuable, and using crowdsourcing allows it to scale.  Similarly, I believe the general idea behind my idea to <i>ensure that everyone is kept honest</i> is also plausibly workable and valuable (until someone points out a valid reason that it isn&#x27;t, of course).<p>&gt; A system like this would have silenced the great revolutionary thinkers of history.<p>Can you explain your reasoning?  I don&#x27;t see anything in the proposal that suggests an intention to use this for precision or wholesale censorship - in fact, the article explicitly says the exact opposite of your concern:<p>&gt; Eventually we aim to <i>make notes visible directly on Tweets</i> for the global Twitter audience, when there is consensus from a broad and diverse set of contributors.<p>&gt; In this first phase of the pilot, notes will only be visible on a separate Birdwatch site. On this site, pilot participants can also rate the helpfulness of notes added by other contributors. These notes are being intentionally kept separate from Twitter for now, while we build Birdwatch and gain confidence that it produces context people find helpful and appropriate. Additionally, <i>notes will not have an effect on the way people see Tweets or our system recommendations</i>.<p>Are you seeing something here regarding censorship that I&#x27;m not?')