Item(by='ssivark', descendants=None, kids=[24770231], score=None, time=1602620413, title=None, item_type='comment', url=None, parent=24769677, text='&gt; It is at best fundamentally nihilist and at worst reduces human value to its ability to do work and produce value<p>I see Jaron Lanier’s position as exactly the opposite, in an interesting accounting of second order effects.<p>“We shape our tools, and then our tools shape us.”<p>You are imagining that AI is going to be fantastically impactful in reducing human drudgery, which might lead to a flowering of human potential. JL argues that since most AI applications today perceive human development as increasing consumption (and people’s interaction with the products&#x2F;services they use is very passive) — which means that as AI gets better, the ambient environment discourages human development. Imagine you satisfied every whim of a child, making it so comfortable that it never has to “grow” — that’s how technology is infantilizing us (AI is just the latest and most impactful layer on top).<p>&gt; I live the present and believe (perhaps naively) I have some agency to impact the future.<p>To give the lion’s share of the credit&#x2F;benefits&#x2F;power to AI&#x2F;algorithms vests all the agency in the hands of those who can control&#x2F;influence them, and condemns those who cannot to a life “below the API” (even if they might be crucial to generate training data) where their voices are drowned out.<p>As JL says multiple times, he is very excited about (the same) AI research when we perceive it as “just” code&#x2F;models&#x2F;linear-algebra, because then suddenly the questions we pose are from a position of much higher human agency (probing the system and how we might influence it), rather than a position of awestruck breathless learned helplessness to the machine.')