Item(by='colanderman', descendants=None, kids=None, score=None, time=1603979417, title=None, item_type='comment', url=None, parent=24928829, text='To run with the example, GPT-3 is obviously not self-aware, and therefore cannot feel pain or have a sense of self.<p>But what if we change that? Run a recurrent GPT-3 instance where (a) some of its prompt input is a description of the current state of its own process, system, and environs, (b) the prompt defines certain of these stimuli as &quot;painful&quot; and to be avoided (and others &quot;joyful&quot; and to be sought out), and (c) the prompt instructs GPT-3 to respond as an individual experiencing these phenomena.<p>What then visibly&#x2F;measurably differentiates this &quot;self-aware&quot; GPT-3 server from any other conscious entity? Or is consciousness necessarily not visible&#x2F;measurable and thus unscientific?<p>Moreover -- what if consciousness is <i>easy</i> to create, simply by meeting the requirements of self-awareness, and ability to experience and respond to qualia? Having a tool like GPT-3, which can compute how existing conscious beings might react to any given qualia, just makes such an artificial consciousness more intelligent and relatable.')