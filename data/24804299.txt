Item(by='AndrewKemendo', descendants=None, kids=[24805112, 24804852, 24804948], score=None, time=1602877436, title=None, item_type='comment', url=None, parent=24803540, text='I was very involved with the Less Wrong community starting when it was the joint Overcoming Bias blog between Yudkowski and Hanson through the splinter off and into the formation of MIRI (fmr: Singularity institute) around 2008-2011 or so.<p>I think it comes down to a few factors.<p>1. Deep Learning took off and took the narrative as the &quot;right path&quot; to &quot;General AI.&quot; Back in its heyday all the LW folks (including myself) were really focused on approaching AI from the perspective of Pearl&#x27;s Causality and the work of Ray Solomonoff<p>2. There were no practical products, tools, frameworks or research that came out of that group that could either be easily applied to existing business or demonstrated SOTA on any computing domain.<p>3. AGI&#x2F;GAI&#x2F;HLAI&#x2F;etc... is generally still (unfairly IMO) seen as the domain for cranks and zealots - which was the primary end-goal of the LW crowd, where &quot;rationality&quot; was the practical middle-step.<p>4. It kind of turned into a mini-cult around Yudkowski, which IMO turned people off<p>[0] <a href="https:&#x2F;&#x2F;intelligence.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;intelligence.org&#x2F;</a>')