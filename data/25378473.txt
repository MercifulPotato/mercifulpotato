Item(by='seanwilson', descendants=None, kids=[25380234], score=None, time=1607633549, title=None, item_type='comment', url=None, parent=25372336, text='<a href="https:&#x2F;&#x2F;blog.tomilkieway.com&#x2F;72k-2&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.tomilkieway.com&#x2F;72k-2&#x2F;</a><p>&gt; To overcome the timeout limitation, I suggested using POST requests (with URL as data) to send jobs to an instance, and use multiple instances in parallel instead of using one instance serially. Because each instance in Cloud Run would only be scraping one page, it would never time out, process all pages in parallel (scale), and also be highly optimized because Cloud Run usage is accurate to milliseconds.<p>&gt; If you look closely, the flow is missing few important pieces.<p>&gt; Exponential Recursion without Break: The instances wouldn’t know when to break, as there was no break statement.<p>&gt; The POST requests could be of the same URLs. If there’s a back link to the previous page, the Cloud Run service will be stuck in infinite recursion, but what’s worst is, that this recursion is multiplying exponentially (our max instances were set to 1000!)<p>Did you not consider how to stop this blowing up before implementing? Having one cloud function trigger another like this with no way to control how many functions are running at the same time with no simple and quickly met termination condition (with uncapped billing) is playing with fire. It&#x27;s not going to be optimal either if most of the time each function is waiting for the URL data to download.<p>You need to be using something like a work queue, or just keep life simple and keep it on a single server if you can.')