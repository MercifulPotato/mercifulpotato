Item(by='ianbicking', descendants=None, kids=[25297536], score=None, time=1607040623, title=None, item_type='comment', url=None, parent=25296221, text='I agree, reading the article (<a href="https:&#x2F;&#x2F;syncedreview.com&#x2F;2020&#x2F;06&#x2F;30&#x2F;yann-lecun-quits-twitter-amid-acrimonious-exchanges-on-ai-bias&#x2F;" rel="nofollow">https:&#x2F;&#x2F;syncedreview.com&#x2F;2020&#x2F;06&#x2F;30&#x2F;yann-lecun-quits-twitter...</a>) and the thread I also don&#x27;t see how one puts this on Timnit.<p>Coming back to the original tweet: if you changed the training data have more black people instead of white, would it perform the same but with inverted racial biases? Maybe? You really can&#x27;t know without doing it. It might generate faces with a dark complexion but also big distortions or unrealistic colors. The original model doesn&#x27;t just produce white people because of the training data, the hyperparameter tuning, perhaps the entire architecture, would have been modified until it produced acceptable outputs... using white training data. Ultimately the engineers and other humans behind the scenes are the arbiters of success, loss functions are chosen by humans, and swapping training data on the same model won&#x27;t change those early decisions.<p>In another context I&#x27;m sure LeCun could have offered his somewhat reductionist take on this example of bias (something I might have done myself â€“ reductionism flows in technologists&#x27; veins!) A discussion could have ensued, and everyone could have come out with a better understanding. A hot Twitter thread isn&#x27;t where that will happen. Neither LeCun nor Timnit have the power to change what Twitter is. LeCun (reasonably!) doesn&#x27;t like the nature of the discussion, and he leaves, and I think that&#x27;s OK.')