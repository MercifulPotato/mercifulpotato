Item(by='nefitty', descendants=None, kids=None, score=None, time=1607211426, title=None, item_type='comment', url=None, parent=25318846, text='I really like this train of thought. I want to push on the idea of an AI-focused corporation “insulating” itself from backlash. I think what’s happening here is an example of the human agents inside of a corporation acting human, counter to the interest of the organization within which they find themselves. This particular spat might not necessarily be the tipping point, but it looks like history is starting to overtly dance with the impacts AI will have, as you stated.<p>The current imperatives of a profit-focused corporation are not aligned with human interests. This has been clear since the time of 1940’s fascist Germany. There are examples of corporations aligning themselves with that government, solely because of the stability that a strong government structure provided. In hindsight, it is clear that corporations provided Hitler et al with the economic powerhouses that moved him and other sympathetic leaders to construct frameworks which were not in accordance with modern ideas of human rights. Especially under the imperative of shareholder primacy in the US, that motivation is stronger than ever. In China, the imperative is strengthening government power.<p>A development I’m personally watching is how AI will fit into that tension between human-interests and corporate interests. Alphabet’s leaders seem to be attempting to steer that corporation closer in alignment with human interests, although the profit motive is an unshakeable goal. Should the US government take a more active role in the development and control of AI, or should we mainly allow the market to pursue AI within the framework of profit motive?<p>Offhandedly, I am wary of allowing unrestrained pursuit of AI development, and so departments like which Gebru was leading take a historically vital role. I also feel a tension between my awe of progress (as a layman) and the possibilities that AI might unlock for humanity. That leaves me with the question of, who should be in charge of artificial intelligence? From our perspective in 2020, I know Bostrom’s and Musk’s concerns about the future of AI seem far-fetched, but even if those negative outcomes have a non-zero possibility of coming true, then we should spend time considering them.')