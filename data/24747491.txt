Item(by='jcims', descendants=None, kids=[24748269, 24749436, 24747792], score=None, time=1602437465, title=None, item_type='comment', url=None, parent=24746066, text='I embarrassed myself as a Noogler trying to explain what in my head seemed like a good tradeoff between hash size (also of URIs) and collision handling.  The process had fixed storage for a table of known hashes, and every collision was tested for validity before taking action. If you could use a truncated hash, you’d obviously increase your collisions, but if you’re going to validate all collisions anyway, it seemed like you could increase your coverage substantially (in the 60-bit case it would have been 4x) while only marginally increasing your overhead of collision handling.<p>There&#x27;s some kind of sparsity&#x2F;entropy function involved with optimizing these two but I&#x27;m too clueless to sort it out.  Without the vocabulary to make my case I just got weirded out by a bunch of smart people staring at me quizzically. Sooo..')