Item(by='amw-zero', descendants=None, kids=[24990635], score=None, time=1604505593, title=None, item_type='comment', url=None, parent=24988050, text='The <i>difference</i> in those probabilities is the same. In each case, the event with the greater probability is 1-in-a-thousand times more likely to occur than the lesser.<p>Let&#x27;s walk through an example with these numbers. Each case has 2 probabilities and we&#x27;ll assign them each to the possible outcomes of a coin flip.<p>Case 1:<p>The probability of heads is 0 and the probability of tails is 0.001. We flip the coin 1,000 times. The ideal outcome is that we see 0 heads and 1 tails.<p>Case 2:<p>The probability of heads is 0.499 and the probability of tails is 0.500. We flip the coin 1,000 times. The ideal outcome is that we see 499 heads and 500 tails.<p>(You&#x27;ll notice that the outcomes don&#x27;t add up to 1,000 in either case, and that&#x27;s because the probabilities don&#x27;t add up to 1. That means there is actually a third possible outcome, but that can be ignored for the purpose of this example.)<p>They each differ by a result of 1 result per 1,000 trials. This is because probability is simply the likelihood of an event occurring. There is no super-linear pattern going on here. It is no harder to get from 0.7 to 0.9 probability than it is to get from 0.2 to 0.4. It is just a measure of likelihood.<p>What is causing people to misunderstand this? I wonder if you&#x27;re thinking about probability distributions vs. probability itself?')