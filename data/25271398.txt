Item(by='throwaway894345', descendants=None, kids=None, score=None, time=1606864984, title=None, item_type='comment', url=None, parent=25270780, text='&gt; You&#x27;re mixing arguments here. It&#x27;s not the occasional 5-second long request, it&#x27;s &quot;the app doesn&#x27;t start serving requests for 5 seconds&quot;.<p>Lambdas cold-start during requests. So the unlucky request that triggers a cold start eats that cold start.<p>&gt; Using data science tooling in a lambda seems iffy, especially ones that are not production ready.<p>Nonsense, there are a lot of lambdas that just load, transform, and shovel data between services using pandas or whathaveyou. Anyway, don&#x27;t get hung up on data science; it was just an example, but there are packages across the ecosystem that behave poorly at startup (usually it&#x27;s not any individual package taking 1-2s but rather a whole bunch of them scattered across your dependency tree that take 100+ms).<p>&gt; And good luck getting such libraries in go.<p>Go doesn&#x27;t have all of the specialty libraries that Python has, but it has enough for the use case I described above.<p>&gt; Python cold booting an interpreter 3 seconds faster than Go is a big deal, especially if your target execution time is &lt;50ms and you&#x27;ve got a large volume of invocations<p>According to <a href="https:&#x2F;&#x2F;mikhail.io&#x2F;serverless&#x2F;coldstarts&#x2F;aws&#x2F;languages&#x2F;" rel="nofollow">https:&#x2F;&#x2F;mikhail.io&#x2F;serverless&#x2F;coldstarts&#x2F;aws&#x2F;languages&#x2F;</a>, Go takes ~450ms on average to cold start which is still up a bit from Python&#x27;s ~250ms. To your point, if you&#x27;re just slinging boto calls (and a lot of lambdas do just this!) and you care a lot about latency, then Python is the right tool for the job.<p>&gt; not being silly and importing ridiculously heavy dependencies into a lambda for no reason other than to make a strange point about Python being unsuitable for something nobody should be doing.<p>Not every lambda is just slinging API requests--some of them actually have to do things with data. Maybe someone is transforming a bit of audio as part of a pipeline or doing some analysis on a CSV or something else. Latency probably matters to them, but they still have to import things to get their work done. And according to <a href="https:&#x2F;&#x2F;mikhail.io&#x2F;serverless&#x2F;coldstarts&#x2F;aws&#x2F;#does-package-size-matter" rel="nofollow">https:&#x2F;&#x2F;mikhail.io&#x2F;serverless&#x2F;coldstarts&#x2F;aws&#x2F;#does-package-s...</a> (at least for JavaScript) just 35mb of dependencies (which will buy you half of a numpy iirc) causes cold start performance to go from ~250ms to 4000ms.<p>My rule of thumb (based on some profiling) is that for every 30mb of Python dependency, the equivalent Go binary grows by 1mb, moreover, it all gets loaded at once (as opposed to resolving each unique import to a location on disk, then parsing, compiling, and finally loading it). Lastly, Go programs are more likely to be &quot;lazy&quot;--that is, they only run the things they need in the main() part of the program whereas Python packages are much more likely to do file or network I&#x2F;O to initialize clients that may or may not be used by the program.')