Item(by='evjrob', descendants=None, kids=None, score=None, time=1603994217, title=None, item_type='comment', url=None, parent=24932937, text='I think it&#x27;s clear that humans at least try to pick out the causal factors, and reason causally about the outcomes of specific actions. Non human animals do too; they can learn to take specific actions for food rewards in a Skinner Box for example. Now I agree humans get it wrong a lot of the time, and other animals might get it wrong even more than we do.<p>I don&#x27;t think our fallibility in causal reasoning makes it useless to pursue as a goal in artificially intelligent systems. It doesn&#x27;t need to be perfect, just useful and better than not having it. Afterall, our perception systems are pretty fallible too, otherwise things like optical illusions wouldn&#x27;t exist.')