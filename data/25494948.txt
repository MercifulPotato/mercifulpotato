Item(by='mjburgess', descendants=None, kids=[25498266], score=None, time=1608559026, title=None, item_type='comment', url=None, parent=25494725, text='We aren&#x27;t comparing commmander data and a human being. This isn&#x27;t a philosophical point.<p>It is a literal point. There is no ML system that can talk to me: there is no system that I can ask if it likes my clothes; or where my shoes are.<p>You might think this is &quot;just adding some I&#x2F;O&quot;, but then show me that system.<p>This is the same shysterism and self-delusion that accompanies every generation of AI hysteria: the first lot in the 40s and 50s claimed, likewise, self-driving cars were &quot;in development&quot; and &quot;almost ready&quot;, etc.<p>It isn&#x27;t true.<p>Animal intelligence is embedded in an environment and it is <i>about</i> an environment. That is what it is, that is what it is for.<p>Efforts which do even have a mechanism to do this aren&#x27;t even in the same field.<p>GPT3 cannot have any internal models of an environment because it isn&#x27;t &quot;trained&quot; on an environment.<p>This isn&#x27;t a philosophical debate; it is an observation that this system cannot do almost anything of interest. It is a toy: literally. It isn&#x27;t with anyone anywhere modelling anything, saying anything, observing anything.<p>It isn&#x27;t reasoning counterfactually; it isn&#x27;t inferring any future states of an environment given a potential change. It isn&#x27;t talking about what I am doing. It isn&#x27;t responding to changes anywhere, it isn&#x27;t asking for changes in response to its needs. It has no causal models; it has no environment models; it has no intentions; it has no memories; it has no desires. It expresses nothing because it has nothing to express.<p>The list of things it isn&#x27;t doing is absurdly long. The philosophical point is moot. It is technically incapable of having a conversation with me about almost anything.<p>It can only generate a long-form document which is grammatically correct, and semantically -- when read by a human -- coherent. Regenerate, and the document would be compeletely different with contradictory claims in it.<p>Even if human beings were mere symbol manipulators, it wouldn&#x27;t make a ferris wheel a viable alternative. And GPT is nothing much more.')