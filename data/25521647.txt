Item(by='philipkglass', descendants=None, kids=[25521693, 25523380], score=None, time=1608754377, title=None, item_type='comment', url=None, parent=25521453, text='A machine controlling a real car gathers feedback no faster than real time and cannot afford to learn the meanings of street signs from the consequences of ignoring them. A machine can learn the rules of Atari games from scratch by playing them orders of magnitude faster than real time and treating &quot;death&quot; as one signal among many.<p>In order for a machine to learn driving the same way it learns Atari games, it seems that it would need an extremely high fidelity virtual environment to learn in. The high fidelity requirement would necessitate a lot of up-front investment in trying to get the simulations right. You might spend a whole career just trying to build a drivable Virtual Philadelphia as challenging as the real thing. The details would also make it much more expensive to run training sessions at high multiples of real time.<p>Given those factors, I&#x27;m not surprised that self-driving vehicle experiments just use real environments and don&#x27;t try to learn the fundamental rules from scratch. But it&#x27;s an interesting point that these choices may make it harder for agents to keep improving.')