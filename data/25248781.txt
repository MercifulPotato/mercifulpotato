Item(by='ilaksh', descendants=None, kids=[25249075], score=None, time=1606689880, title=None, item_type='comment', url=None, parent=25247499, text='I actually registered a company named &quot;General Biomimetics&quot; in Delaware and have so much ambition and so many (unfortunately mostly vague) ideas about this.  Specifically I have been thinking about washing dishes and other tasks in the kitchen.  So its been something I have been spending at least two days a week on (I have a job).<p>But due to the depth of the problem and not having resources or much knowledge, it was maybe a little silly to create the company. But I like the idea of reserving that name, just in case I ever get anywhere.<p>From the hardware side, I feel like some of the robotics issues can be resolved by &quot;just&quot; copying people more closely.  For example, it seems like the way real arms and muscles work should provide more leverage and force than the typical servo setup.  And having five fingers provides the potential that manipulations could be copied from people.<p>There is also a very promising new type of artificial muscles called HASEL.<p>Of course, in order to efficiently build these human-like limbs, &quot;all&quot; we need is a way to 3D print with several materials at once, including a new type of conductive ink that can handle high voltages for the HASEL muscles.<p>But the starting point to me is a robot that can actually understand what it&#x27;s looking at.  In that it sees with depth, and understands the composition of objects and their orientation, etc.<p>Capsule networks seem interesting but also maybe are a bit computationally expensive and unproven?  Also he seems to be focused on just the transformation matrix, but it seems like there are more aspects of the state that could be relevant and maybe are unique to different object types.  But I am slowly trying to understand capsules anyway.<p>I have seen a few ideas about more general neural network-based systems that suggest it is necessarily to have multiple neural networks, or networks of networks, or neural modules, etc.<p>To me it seems like the ideal thing would be to have some standard shapes for networks or modules and also be able to reuse and adapt them for different tasks.<p>So my vague ideas now are something like: standard-shaped modules, trained on core modeling tasks such as finding 3d surfaces in 2d images.  But at the same time somehow segmenting into different objects.  And the potential high-level objects should be able to feed into the potential low-level understanding and visa-versa.<p>My intuition is that ideally there is a sort of 3d wireframe overlayed on the 2d image, identifying each object and sub-object with its exact dimensions, shape and orientation.  Kind of like I&#x27;ve seen in one or two science fiction movies.  So if I can somehow generate all of that, I know I have properly decoded the image.<p>Today I was looking at a GAN tutorial.  But I have never made a CNN before, so decided that must be first.<p>Usually I think about this stuff for awhile and then just decide I don&#x27;t really know what to do and then go back to Coursera.  I finish Ng&#x27;s first class and am looking at the hyperparameters one.  I feel like I need to make some actual neural networks on my own though, because mainly Ng is teaching me how to convert from math notation to vectorized Python as much as anything.<p>If nothing else, this is really motivating me to learn about existing AI techniques.  Which I feel like, to be a good programmer, I actually should be able to use things like Tensorflow etc. for narrow AI tasks.')