Item(by='spiznnx', descendants=None, kids=[25586299, 25586593, 25587917], score=None, time=1609363188, title=None, item_type='comment', url=None, parent=25585706, text='BERT is much smaller than GPT-3 (500x fewer parameters), not sure why the article doesn&#x27;t point that out more explicitly.<p>The mentioned paper itself notes a 300,000x increase in compute used for training language models over the last 6 years.<p>I think the point is, if nothing changes, the costs will be very significant very soon.')