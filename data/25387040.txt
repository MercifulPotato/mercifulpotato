Item(by='jstephan', descendants=None, kids=None, score=None, time=1607701866, title=None, item_type='comment', url=None, parent=25387036, text='Hello HN community,<p>I’m JY, co-founder of Data Mechanics (YC S19, <a href="https:&#x2F;&#x2F;www.datamechanics.co" rel="nofollow">https:&#x2F;&#x2F;www.datamechanics.co</a>). But this post is NOT about startup core product (a managed Spark platform, deployed on a k8s cluster in our customers cloud account, see our HN Launch <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23142831" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23142831</a>).<p>This post is about a free and partly open-source monitoring tool for Apache Spark that we just released.<p>It works by installing an open-source Spark agent (<a href="https:&#x2F;&#x2F;github.com&#x2F;datamechanics&#x2F;delight" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;datamechanics&#x2F;delight</a>) on your Spark infrastructure — whatever it is: commercial or open-source, on Kubernetes or on YARN, in the cloud or on-premise.<p>This agent streams event metrics from Spark (metadata about your Spark applications) to our backend, which then serves a dashboard listing the Spark applications, and giving you access to the Spark UI (Spark History Server) for each of them. The blog post has a lot more details about the architecture and security of it.<p>This release is just a first milestone for us, in our next release in January we will add new screens to gradually replace the Spark UI with a new monitoring view, you can see a glimpse of it at the GIF at the bottom of this page (<a href="https:&#x2F;&#x2F;www.datamechanics.co&#x2F;delight" rel="nofollow">https:&#x2F;&#x2F;www.datamechanics.co&#x2F;delight</a>)<p>We’d love your feedback about it — is it easy to install and use? What would you like to see in following releases?\nThanks so much!\nJY')