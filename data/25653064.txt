Item(by='crdrost', descendants=None, kids=[25653370], score=None, time=1609891232, title=None, item_type='comment', url=None, parent=25652529, text='If we knew how it did it, it wouldn&#x27;t be machine learning.<p>The defining feature of machine learning in other words is that the machine constructs a hypersurface in a very-high-dimensional space based on the samples that it sees, and then extrapolates along the surface for new queries. Whereas you can explain features of why the hypersurface is shaped the way it is, the machine learning algorithm essentially just tries to match its shape well, and intentionally does not try to extract reasons &quot;why&quot; that shape &quot;has to be&quot; the way it is. It is a correlator, not a causalator.<p>If you had something bigger you&#x27;d call it &quot;artificial intelligence research&quot; or something. Machine learning is precisely the subset right now that is focused on “this whole semantic mapping thing that characterized historical AI research programs—figure out amazing strategy so that you need very little compute—did not bear fruit fast enough compared to the exponential increases in computing budget so let us instead see what we can do with tons of compute and vastly less strategy.” It is a deliberate reorientation with some good and some bad parts to it. (Practical! Real results now! Who cares whether it “really knows” what it’s doing? But also, you peer inside the black box and the numbers are quite inscrutable; and also, adversarial approaches routinely can train another network to find regions of the hyperplane where an obvious photograph of a lion is mischaracterized as a leprechaun or whatever.)')