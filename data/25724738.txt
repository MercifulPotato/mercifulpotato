Item(by='eru', descendants=None, kids=None, score=None, time=1610341252, title=None, item_type='comment', url=None, parent=25685098, text='&gt; Interesting thought. I imagine just about every language spec (with the possible exception of assembly languages) states something like If memory is exhausted, a handler is executed or If memory is exhausted, the behaviour is undefined, and it&#x27;s always going to be up to the compiler&#x2F;interpreter to make reasonable use of the available memory on the specific target platform.<p>I would have expected some words to those effects, but extensive browsing and grepping in the C++ spec did not reveal such language.  (They do not mention the call stack at all, which is a fair enough decision.)<p>I was first looking into this, because I had hoped the standard would specify a way to check for whether the next call would blow up the stack before you actually engaged in the call.<p>&gt; Would a C compiler be non-compliant if it generated code that used 100x the memory that would be used by code generated by typical C compiler? How about 1,000,000,000x so that its generated programs always failed immediately?<p>You could ask the same for speed of execution.  I think it would be standards compliant, but not very useful.  Standard compliance ain&#x27;t the only thing people look for in a compiler.<p>In practice, you could make a C++ compiler that does the standard compliant thing to virtually all of people&#x27;s programs, by just emitting the nethack executable regardless of input.  After all, virtually all real world C++ programs have undefined behaviour somewhere, and undefined behaviour is allowed to &#x27;travel backwards in time&#x27;.  (Ie undefined behaviour anywhere makes the whole execution undefined, not just after it is encountered.)<p>Hey, you could even just start nethack instead of producing any files with your compiler at all.  Enough undefined behaviour goes all the way to compile time, like eg not closing your quotes, I think.<p>&gt; I imagine the formal methods folks must have done some thinking on this topic, as their whole field is about doing better than just go ahead and test it out. Could a standards-compliant C compiler used in a safety-critical domain generate code that, only very occasionally, uses a billion times the memory it typically uses?<p>I think for safety-critical code, you solve this conundrum by relying on extra guarantees that your compiler implementation makes, not just on the standard.')