Item(by='YeGoblynQueenne', descendants=None, kids=[25031321], score=None, time=1604865995, title=None, item_type='comment', url=None, parent=25026577, text='&gt;&gt; Sorry, I did misunderstand what you were saying.<p>Thank you for your honesty and there&#x27;s no need to apologise.<p>Let me explain my point above, if I can. You said that search, planning,\nexpert systems, etc, are &quot;not AI, and they never will be&quot;. I understand that\nas saying that such systems are not artificial intelligences, in the sense of\nan intelligent machine created by humans out of whole cloth (without trying to\ndefine what &quot;intelligent&quot; means).<p>That is certainly true, but it is also uncontroversial that the above are\nsub-fields of the field of research that is known as &quot;AI&quot;. That is, there is a\nfield that researches approaches that could lead to the creation of\nintelligent machines and that is called &quot;AI&quot; and then there&#x27;s the ultimate\ntarget of that field which is to create &quot;AI&quot;.<p>My original comment bemoans the fact that in some sectors, &quot;AI&quot;, as a field of\nresearch, has become synonymous with only one sub-sub-field of AI research,\nthat is, deep learning.<p>Contrary to what you state, these &quot;GOFAI&quot; fields (symbolic AI, if you will)\nare still active and far from having &quot;failed&quot; in any way, they are &quot;SOTA&quot; in\ntheir respective tasks. For example, the field of automated theorem proving is\ndominated by systems that employ the resolution rule, a logic-based approach\nand while recent efforts have been made to make inroads into theorem proving\nwith deep neural nets (e.g. a recent attempt to use transformers) results are\nstill very far from being comparable to the traditional approaches. I know\nmore about automated theorem proving that I know e.g. about planning or search\n(because my PhD is in a subject close to the former) but my understanding is\nthat in those fields too, traditional techniques dominate- which is why\nresearch in them is still active.<p>If I am permitted to tout my own horn, my broader subject area can be\ndescribed as &quot;program learning&quot;, i.e. machine learning of arbitrary programs\nfrom examples of their inputs and outputs. In this area also, deep learning\nsystems are hopelessly outclassed by symbolic approaches, not least because\nthese approaches learn precise representations of target programs (rather than\napproximations) from a mere handful of examples (four or five, etc).<p>And so on. These are just some examples of AI research that is ongoing, that\nis not deep learning, and that is state of the art for its respective tasks.\nIn view of that, I consider that using &quot;AI&quot; to mean &quot;deep learning&quot; (as the\narticle above does) is not only misinformed but also misinforming and actively\nharmful. In the sense of harming people&#x27;s understanding, that is.<p>As to your comment about how GOFAI &quot;failed&quot;, I&#x27;m afraid this opinion, which is\ncommon, is also misinformed. Here, too, a knowledge of the history of the\nfield helps, but to summarise, the last winter happened because of strictly\npolitical reasons and for no reason that had anything to do with the\nscientific merits, or practical successes of the relevant approaches. In fact,\nexpert systems, now widely considered a failure, were one of the first big\nsuccess stories of AI; a success story that was cut short only because, again,\nof political reasons.<p>I could talk about the AI winter subject for hours (it&#x27;s a favourit subject of\nmine) but a good starting point is this article by the editor of the IEEE\njournal Intelligent Systems: (Avoiding Another Winter)\n<a href="https:&#x2F;&#x2F;www.computer.org&#x2F;csdl&#x2F;magazine&#x2F;ex&#x2F;2008&#x2F;02&#x2F;mex2008020002&#x2F;13rRUyeCkdP" rel="nofollow">https:&#x2F;&#x2F;www.computer.org&#x2F;csdl&#x2F;magazine&#x2F;ex&#x2F;2008&#x2F;02&#x2F;mex2008020...</a>.\nThe wikipedia page on <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AI_winter" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AI_winter</a> also has a\ndecent summary and some sources. Finally, see the wikipedia article on the\nLighthill Report <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lighthill_report" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lighthill_report</a> which is more\nrelevant to AI research in the UK (the Report killed AI research in the UK,\ndead) and this review of the report by John McCarthy:\n<a href="http:&#x2F;&#x2F;www-formal.stanford.edu&#x2F;jmc&#x2F;reviews&#x2F;lighthill&#x2F;lighthill.html" rel="nofollow">http:&#x2F;&#x2F;www-formal.stanford.edu&#x2F;jmc&#x2F;reviews&#x2F;lighthill&#x2F;lighthi...</a> (man who\ncoined the term AI and also created LISP on the side).<p>&gt;&gt; As much as you argue I should adopt the subject&#x27;s history, I&#x27;m saying you\nshould adopt its present.<p>More to the point, I&#x27;m recommending that you should know a subject&#x27;s history\nbefore forming a strong opinion about its present and future. As to me, I&#x27;m\nfirmly rooted to the present. About half of the literature I read is neural\nnetworks- and that&#x27;s not even the subject of my research. But if you think\nabout it, in the era where the trend is to use deep learning, the most\ninteresting results can only come from <i>not</i> using deep learning. In a gold\nrush, if everyone is digging up Widow&#x27;s Creek, then Widow&#x27;s Creek is the last\nplace to dig for gold.')