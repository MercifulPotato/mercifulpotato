Item(by='Jtsummers', descendants=None, kids=None, score=None, time=1601671001, title=None, item_type='comment', url=None, parent=24666120, text='Related: pigeonhole principle.<p>If you have n buckets, and n+1 items you&#x27;re guaranteed to have a shared bucket.<p>In the case of hash algorithms you&#x27;re taking an arbitrary sized input and &quot;compressing&quot; (in quotes because this is one way, you can&#x27;t decompress it because of collisions) into a fixed size. If you permit more inputs to your hash function than there are hash values, then you will eventually have a collision.<p>A stupid awful hash function: n mod 100<p>So long as n is less than 100, you will never have a collision. But as soon as you compute the hash of n = 100, you will get a collision (with 0 in this case). Now, real world hash algorithms have larger spaces they map to, and more complicated mappings, but they all have this same problem. The larger the space (like 256-bits versus 64-bits) the less likely collisions become, but it could still happen.')