Item(by='fenomas', descendants=None, kids=[25330252, 25330371], score=None, time=1607312421, title=None, item_type='comment', url=None, parent=25327533, text='As someone who&#x27;s worked on this <i>a lot</i>, this article resonated but I disagree with the conclusions. (Or at any rate I feel like my procedural stuff is listenable, though I can&#x27;t read or compose music.)<p>I think the author&#x27;s biggest problem is the bottom-up approach of creating lots of raw clips and then at a higher level trying to assemble them. I&#x27;ve found music generation to consistently be a very similar task to text generation, and to me the author&#x27;s approach seems analogous to generating lots of random sentences and then trying to assemble them into a short story.<p>Everything I&#x27;ve done that&#x27;s worked has been completely top down - the core of the engine determines the state of the song (we&#x27;re in the A section, bar 7, the current chord is V&#x2F;V, etc.) and the low level parts generate something to match all that. E.g. the melody part might decide to play the root tone of the current chord, but it has to ask the core what note that would be.<p>The hard thing about this approach is that you need an environment where you can dynamically play notes of an arbitrary pitch&#x2F;length&#x2F;instrument, which either means lots of sound fonts or realtime audio gen. I&#x27;ve been doing this with WebAudio, and while it works it&#x27;s been very painful - for me the &quot;play sounds&quot; part of procedural music has more difficult than the &quot;compose music&quot; part.')