Item(by='YeGoblynQueenne', descendants=None, kids=None, score=None, time=1610891201, title=None, item_type='comment', url=None, parent=25810047, text='&gt;&gt; AI agents will control the future, and which ones we create is the only thing about our time that will matter in the long run.<p>Every time there&#x27;s a big story in the news about a new thing achieved by an AI\nsystem, someone will lose their shit and go on social media to say how it&#x27;s a\nsign of the end times where Terminators will roam the Earth and humans will hide\nin caves. At least the article has the common indicency of placing this\ninevitable eventuality &quot;in the future&quot;, with all the precision typical of palm\nreaders and popular entertainers.<p>For perspective, here&#x27;s an article I found by following the wikipedia links on\nGary Kasparov&#x27;s 1997 defeat by Deep Blue in chess:<p><a href="https:&#x2F;&#x2F;www.washingtonexaminer.com&#x2F;weekly-standard&#x2F;be-afraid-9802" rel="nofollow">https:&#x2F;&#x2F;www.washingtonexaminer.com&#x2F;weekly-standard&#x2F;be-afraid...</a><p>The article is titled &quot;Be Afraid&quot; (!) and it includes passages like the\nfollowing:<p><pre><code>  In Game Two, Deep Blue passed the Turing test. Yes, of course, it was for\n  chess only, a very big caveat. But, first, no one was ever quite sure that a\n  machine ever would pass even this limited test.\n\n  And second, if a computer has passed the Turing test for chess, closed logical\n  system though it may be, that opens the possibility that computers might in\n  time pass the Turing test in other areas.\n</code></pre>\nBesides the typical abuse of the Turing test to mean anything anyone wants it to\nmean, as long as it means something as vague and fuzzy as it is irrelevant, I\nremind the esteemed reader that the year is 1997 and people are raising the\nalarm about AI going superintelligent and taking over the world a long time\nbefore Eliezer Yudkowski or Elon Musk and OpenAI. And if you look further back,\nyou&#x27;ll find similar predictions of AI being &quot;just around the corner&quot; since 1957.\nMaybe we need to build guns that can shoot behind corners, to protect ourselves\nfrom evil superintelligences, eh?<p>So hold your horses and don&#x27;t lose your mind. AI today is just as limited as it\nwas in 1997 and in 1957. We have more data and bigger computers but we still\ndon&#x27;t understand intelligence and our best bet to reproduce it on a digital\ncomputer remains the hope that it will somehow arise, magickally, unexpectedly,\non its own, fully formed like Athena from the brow of Zeus, if only we throw\nmore big data and more big computers at narrow tasks in irrelevant domains- like\nchess, Atari, Dota 2... or, indeed, protein structure prediction (not quite a\nhallmark of intelligence that).')