Item(by='qznc', descendants=None, kids=None, score=None, time=1609236767, title=None, item_type='comment', url=None, parent=25556470, text='For an article which aspires to clarify safety I would expect a good definition of the term. Is it &quot;preventing a system from reaching dangerous states&quot;?<p>In my opinion, you should start with defining what harm to humans you think about.\nHarm due to privacy leaks?\nFinancial loss due to miscalculations?\nLocked out by your home security system?\nElectrocuted by your home security system?<p>I&#x27;m working in driver assistance, safety-critical software in cars. Here is a very high level description how we treat safety:<p>We start with a high level feature, e.g. automated emergency breaking (AEB). Now someone determines safety goals like &quot;don&#x27;t break unintentionally&quot; and &quot;don&#x27;t break too hard&quot;. Violating those goals would probably mean the driver loses control of the car and thus harms humans. It needs to be a more specific, of course. Breaking too hard is &quot;decelerate no more than 60km&#x2F;h in 1.2 seconds&quot; if I remember it correctly. Note that all usual features always use the human driver as fallback mechanism. That results in very interesting questions for autonomous driving.<p>From those high level requirements it traces down to various parts (hardware, software, electric, mechanics, whatever). There might be a requirement like &quot;this device (ECU), never send signal AebBreakRequest=1 for longer than 1.2seconds&quot;.<p>Then the tedious work comes. You think through all the parts and safety goals and wonder: If something goes wrong here, would it violate the safety goal? If you don&#x27;t find a good argument, then you need to build some mechanism to prevent it from going wrong. Examples: What if a bit flips in RAM? Use ECC RAM then the probability is low enough. What if there is noise on the CAN vehicle bus? We do check sums. How can we be sure that our radar sensor does not trigger an unintentional break due to a plastic bag blowing in the wind? We collect 10000h of real world driving evidence. Those question and answer games can become quite elaborate.<p>Note that the general pattern here is &quot;if there is a fault, will a safety goal be violated.&quot; \nThese days Safety Of The Intended Function (SOTIF) comes with a new pattern &quot;if everything is working as intended, is it safe?&quot;\nThis is mostly triggered from autonomous driving and deep learning approaches.\nAbsent any faults like bit flips, how can we be sure that it won&#x27;t kill pedestrians dressed up as chickens?')