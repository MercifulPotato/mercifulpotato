Item(by='lasagnaphil', descendants=None, kids=[24850479], score=None, time=1603302960, title=None, item_type='comment', url=None, parent=24848249, text='Although I have only skimmed the paper, I think it&#x27;s kinda trying to say (although someone with a better mathematical background than me might poke me for this) that the reward hypothesis (<a href="http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;rlai.cs.ualberta.ca&#x2F;RLAI&#x2F;rewardhypothesis.html" rel="nofollow">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;rlai.cs.ualberta.ca&#x2F;RLAI&#x2F;rewa...</a>) - the notion that every goal or purpose can be framed as the maximization of a real-valued function - isn&#x27;t really applicable for most of the time. This is quite intuitively agreeable even without the math - do we really think that the many things we do in our lives were perfromed to optimize an &quot;oracle&quot; loss function? Our human mind is comprised of ridiculously complex systems of neurons and cells that generates a variety of emergent behaviors, and saying that those emergent behaviors are actually a <i></i>solution<i></i> of a very complex optimization problem is very, very bold. Often the reward functions are just abstractions of what we perceive (although they aren&#x27;t entirely useless - keep in mind that all models are wrong but some are useful).<p>Although the paper is trying to say that the real number system isn&#x27;t robust enough to express the goal&#x2F;purpose of more complicated, &quot;abstract&quot; tasks, it speculates that a higher-order number system (such as the hyperreal or surreal numbers) would be able to achieve this. I currently disagree with this view - I view of &quot;intelligence&quot; as we know of today more as emergent phenomena of complex systems of autonomous agents (in the case of human intelligence, the emergent phenomena of neurons and other cells interacting with the external world), but that&#x27;s a topic for another day.')