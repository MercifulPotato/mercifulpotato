Item(by='oppositelock', descendants=None, kids=[24817098, 24817719], score=None, time=1602995051, title=None, item_type='comment', url=None, parent=24813795, text='You have to put a lot of thought into protecting and backing up production databases, and backups are not good enough without regular testing of recovery.<p>I have been running Postgres in production supporting $millions in business for years. Here&#x27;s how it&#x27;s set up. These days I use RDS in AWS, but the same is doable anywhere.<p>First, the primary server is configured to send write ahead logs (WAL) to a secondary server. What this means is that before a transaction completes on the master, she slave has written it too. This is a hot spare in case something happens to the master.<p>Secondly, WAL logs will happily contain a DROP DATABASE in them, they&#x27;re just the transaction log, and don&#x27;t prevent bad mistakes, so I also send the WAL logs to backup storage via WAL-E. In the tale of horror in the linked article, I&#x27;d be able to recover the DB by restoring from the last backup, and applying the WAL delta. If the WAL contains a &quot;drop database&quot;, then some manual intervention is required to only play them back up to the statement before that drop.<p>Third is a question of access control for developers. Absolutely nobody should have write credentials for a prod DB except for the prod services. If a developer needs to work with data to develop something, I have all these wonderful DB backups lying around, so I bring up a new DB from the backups, giving the developer a sandbox to play in, and also testing my recovery procedure, double-win. Now, there are emergencies where this rule is broken, but it&#x27;s an anomalous situation handled on a case by case basis, and I only let people who know what they&#x27;re doing touch that live prod DB.')