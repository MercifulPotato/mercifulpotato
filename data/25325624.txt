Item(by='Straw', descendants=None, kids=None, score=None, time=1607280789, title=None, item_type='comment', url=None, parent=25325491, text='Absolutely, modern NN architectures have been inspired by biological ones- despite their massive differences.<p>Even in cases like attention, the modern version (that actually works in GPT-3, AlphaFold2, etc), has little in common with both the english word and what we think of as attention. Its a formula with two matmuls and a softmax: softmax(AB)C. In particular, it doesn&#x27;t necessarily look anywhere at all- just a weighted sum of the inputs. Nothing like the hard attention used by the human visual cortex.\nIts not even that different from a convolution where you allow the weights to be a function of the input.<p>So the inspiration might have come from humans, but the actual architectures have largely come from pure trial and error, with limited, difficult to explain intuition on what tends to work.')