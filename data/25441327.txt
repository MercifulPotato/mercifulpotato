Item(by='touisteur', descendants=None, kids=None, score=None, time=1608117640, title=None, item_type='comment', url=None, parent=25438200, text='Why not? You got thousands of tensor cores, or tflops under your hand, with already developed APIs, and if you&#x27;re not too latency-sensitive you can batch a lot. Since you&#x27;ll be doing the same inference operation millions of time, you don&#x27;t have to re-prepare kernels and such, use cuda graphs or whatever is the flavour of the day for low overhead, repetitive computation? And if you want to scale a bit, you can add some GPUs before all the PCIe-lanes are all saturated, right? Apart from myriad-x and tpus I&#x27;m not sure what could be more useful?')