Item(by='rayiner', descendants=None, kids=[25313185, 25315016, 25312799], score=None, time=1607146694, title=None, item_type='comment', url=None, parent=25311402, text='&gt; An AI model taught to view racist language as normal is obviously bad. The researchers, though, point out a couple of more subtle problems. One is that shifts in language play an important role in social change; the MeToo and Black Lives Matter movements, for example, have tried to establish a new anti-sexist and anti-racist vocabulary. An AI model trained on vast swaths of the internet won’t be attuned to the nuances of this vocabulary and won’t produce or interpret language in line with these <i>new cultural norms.</i><p>This is a pretty superficial take on what is an extremely interesting sociological topic. (To be clear, I’m referring to the article, not the underlying paper which we don’t have.) Obviously just because social movements “have tried to establish ... vocabulary” doesn’t meant that vocabulary has become a “new cultural norm.” Plenty of such efforts end up being cultural dead-ends.<p>Take for example a term like “LatinX.” This term has been proposed and is used by certain people, but is extremely unfamiliar and often alienating to Latinos themselves: <a href="https:&#x2F;&#x2F;www.vox.com&#x2F;2020&#x2F;11&#x2F;5&#x2F;21548677&#x2F;trump-hispanic-vote-latinx" rel="nofollow">https:&#x2F;&#x2F;www.vox.com&#x2F;2020&#x2F;11&#x2F;5&#x2F;21548677&#x2F;trump-hispanic-vote-l...</a> (“[O]nly 3 percent of US Hispanics actually use it themselves.... The message of the term, however, is that the entire grammatical system of the Spanish language is problematic, which in any other context progressives would recognize as an alienating and insensitive message.”).<p>The article hand-waves away a deeply interesting question: What <i>should</i> an AI do here? Should AI reflect society, or be a vehicle for accelerating change? It seems at least reasonable to say that the AI should reflect what people actually say, in which case a big training dataset is appropriate, instead of what some experts decide that people should say. In some contexts, for example with “LatinX,” researchers seeking to enhance inclusivity could instead end up imposing a kind of racist elitism. (People without college educations—which disproportionately comprises immigrants and people of color—tend to be less knowledgeable about and slower to adopt these changes in vocabulary.)<p>The paper seems to imply that AIs should not reflect “social norms” but that training data should be selected to accentuate “attempt[ed]” shifts in such norms. Maybe that’s true, but it doesn’t seem obviously true. To return to the example above, is some Google AI generating the phrase “LatinX” (which 3&#x2F;4 of Latinos have never even heard of: <a href="https:&#x2F;&#x2F;www.pewresearch.org&#x2F;hispanic&#x2F;2020&#x2F;08&#x2F;11&#x2F;about-one-in-four-u-s-hispanics-have-heard-of-latinx-but-just-3-use-it" rel="nofollow">https:&#x2F;&#x2F;www.pewresearch.org&#x2F;hispanic&#x2F;2020&#x2F;08&#x2F;11&#x2F;about-one-in...</a>) in preference to “Latino” or “Hispanic” actually the desired result?')