Item(by='wegs', descendants=None, kids=[25558792], score=None, time=1609158269, title=None, item_type='comment', url=None, parent=25558028, text='No, the missing part is not time travel. Sound comes from the skin and engines of the plane, where microphones could be located, and could potentially predict sound throughout the plane well in advance with an appropriate microphone array. You&#x27;d need a fair number of microphones, but I suspect the noise profile isn&#x27;t too chaotic, which helps. You&#x27;re talking about things like jet engines (which are repetitive), turbulence (which seems chaotic, but in practice, you shed vertices at a known rate), and a known cabin configuration (modulo people moving about). I suspect while the general solutions suffers from the curse of dimensionality, the specific one probably doesn&#x27;t. A reasonable number of microphones, combined with decent models, could characterize the whole sound field.<p>Speakers, located in the seats, if they knew where ears were, could play sound to cancel that.<p>Decent microphones are $2, and what was expensive were things like microphone preamps, ADC, and the whole data pipeline. From there, we need a shit-ton of computation which really wasn&#x27;t practical until... big-ass computation systems came out for the rise of ML.<p>The problem is hard today, but definitely not impossible. I don&#x27;t think I would have given that same answer a decade ago. An NVidia Titan V brings over 100 teraflops. That&#x27;s a lot of cycles one can throw at trying to predict sound by my ear from sound at the skin of the airplane in real-time.')