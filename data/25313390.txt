Item(by='mschuster91', descendants=None, kids=[25313629, 25313829], score=None, time=1607164171, title=None, item_type='comment', url=None, parent=25313000, text='&gt; Ok, basically she is pissed as AI is picking normal language, that people use, and not using the vocabulary that is in vogue on certain political circles. Basically censure, and forced speech.<p>The thing is: The language that people use is often enough offensive: racial slurs, sexism and other forms of discrimination, plus seemingly innocent &quot;code words&quot; like &quot;globalist&quot;.<p>AI developers should know about these problems and keep them in mind while developing training data for AI models. The consequences of ignoring such bias is continuing discrimination - with the most obvious and low-tech reminder being the &quot;racist soap dispenser&quot; which had only been trained on white people&#x27;s skin and failed to dispense soap for people of color.<p>The danger in such discriminatory models is that while it&#x27;s an annoyance that a soap dispenser does not dispense soap for a person of color, with algorithms running more and more of our daily lives, the <i>impact</i> is way higher: whether being refused credit or affordable insurance rates because an AI &quot;thinks&quot; the applicant is black and living in a black, poor neighborhood is grounds enough for that, or &quot;predictive policing&quot; AIs sending in massive police responses to everyday calls, this directly hits on people&#x27;s survival without human oversight.<p>That is why ethics in AI are so important and why &quot;social justice activism&quot; is so desperately needed!')