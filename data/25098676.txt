Item(by='dwohnitmok', descendants=None, kids=None, score=None, time=1605419994, title=None, item_type='comment', url=None, parent=25098507, text='No they still can. You can still have concurrency bugs in the absence of parallelism (the classic example of why concurrency and parallelism are not the same thing) as long as you have a concurrent API (which the Elm architecture is an example of).<p>The basic problem is that there is an undefined delay between a message is issued and when `update` is called on the message which can be caused by other messages being in the queue.<p>Here&#x27;s an example with subscriptions and views.<p>Time 0: A subscription arrives with message `A` which is added to the message queue in Elm&#x27;s runtime. Note that one &quot;tick&quot; in Elm&#x27;s runtime has not yet passed so we don&#x27;t process the queue just yet (to see why this can happen we can either look at Elm&#x27;s source code or note that the fact that Elm doesn&#x27;t lose a subscription even if updates are busy processing forces there to be a message queue of length &gt; 1).<p>Time 1: Your view sends a message `B` which contains a snapshot of the model `M0` at Time 1. `B` is added to the message queue.<p>Time 2: Your update function pops off the message queue and processes `A`, resulting in a new model `M1`.<p>Time 3: The Elm runtime processes another tick and sees no new messages from either views or subscriptions.<p>Time 4: Since the runtime is now done examining subscriptions and view messages, your update function pops off the message queue and processes `B`, resetting the model back to `M0`.<p>At the end of this sequence you effectively haven&#x27;t handled the subscription at all, and all this is on a single thread.')