Item(by='burlesona', descendants=None, kids=[25245625, 25245508, 25245570, 25247341, 25246932, 25250718, 25248171, 25248456], score=None, time=1606662036, title=None, item_type='comment', url=None, parent=25245206, text='I got really into computers in the mid-late 90s by which point we were mostly down to Wintel and Apple hanging on by a thread.<p>What I remember from that era is that nothing was compatible with anything else. It took a lot of work to interoperate between two PCs, let alone cross the gap between OSes. So for a long time, I have kind of taken the current world of few OSes that are highly interoperable as being a great thing: you can build your own Linux machine and still do real work with people on Windows and Mac, etc.<p>But the more I learn about computing in the 80s and early 90s, the more I’m impressed by the variety and diversity of ideas that came out of that era. I see now that today’s standardization has a real cost, which is that we don’t really see new ideas or new paradigms.<p>For the HN crowd, especially those who are older than me and can remember the earlier era of computing, what do you think about that trade off and where we’ve ended up today?<p>Are we better off living in a world where all computers can work together with minimal fuss? Or would it be better if we still had a wide range of vendors taking significantly different approaches and innovating at a much faster pace - albeit in incompatible ways?')