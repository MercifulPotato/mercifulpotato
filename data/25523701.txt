Item(by='judofyr', descendants=None, kids=None, score=None, time=1608767789, title=None, item_type='comment', url=None, parent=25522598, text='&gt; Web servers are all about I&#x2F;O and handling small tasks (requests), and are a perfect use case for asynchronous programming.<p>In principle yes, but in practice I disagree. Due to keep-alive you want to be able to handle many <i>idle</i> connections at the same time, but you rarely want to handle many <i>active</i> connections at the same time.<p>Example: Whenever you talk to another services (e.g. a database) you need to limit the number of connections you have open. You can&#x27;t just blindly open a new connection per incoming request. This means that your <i>practical</i> level by parallelism is often bounded by your database. If every request talks to Postgres and you have a connection pool with a limit of 50, then there is nothing to gain by having support for 1000s of &quot;active&quot; connections. You&#x27;d rather want Postgres to focus on finishing existing requests than opening new ones.<p>And once you look into Postgres you&#x27;ll observe the same thing: There&#x27;s only limited amount of CPU&#x2F;IO so there&#x27;s no point in having 1000s of &quot;active&quot; requests going on at the same time.')