Item(by='choppaface', descendants=None, kids=[24849889], score=None, time=1603290741, title=None, item_type='comment', url=None, parent=24847630, text='Agree that they missed broadcast joins, which can greatly impact how you’d go about a query versus plain SQL for big data.  One of the best parts about Spark is how it supports rapid iteration—- you can use it to discover what joins are computationally infeasible.<p>It’s notable that in Spark 3.x, Koalas is standard, which adopts the Pandas API.  Yet this style guide uses the Spark DataFrame API.  So the guide might be a little stale anyways.<p>In my experience, it’s helpful to write queries in plain portable (or mostly portable) SQL, because once a Spark job becomes useful it often gets translated or refactored into something else.  Definitely depends on the team &#x2F; context, but plain SQL is often more widely accessible.  For fast-moving data science stuff, it’s important to think about extensibility in terms of not just code (style &amp; syntax) but people (who is going to remix this?).')