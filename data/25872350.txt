Item(by='Grimm1', descendants=None, kids=None, score=None, time=1611328842, title=None, item_type='comment', url=None, parent=25867693, text='Personally, after now seeing this, I think it&#x27;s going to solve a problem for us that we&#x27;re going to run into in the medium term so that&#x27;s pretty neat, but we are dealing with a lot of data and re-computing certain things from scratch for us would be potentially prohibitive at our scale of data.<p>I think the main issue is that in most shops is that the scale of their data isn&#x27;t so large that a re-computation of a query with new data takes long enough that they would want to put it engineering effort to switch off more common tools like spark, airflow and columnar storage dbs. They&#x27;re also likely, with decent engineering, not yet at a point where they run into tuning issues on their ingest side. An ETL taking an hour every night and then taking a couple seconds to run that query or even have that query set up on a job that just sends out a report isn&#x27;t really an issue for most small - medium sized companies, and even at larger ones if your data throughput isn&#x27;t particularly high I don&#x27;t see people needing to reach for this for the same reasons.<p>You obviously can do those less intensive tasks in DDF but it doesn&#x27;t really strongly make a case for itself in those regards, largely because DDF doesn&#x27;t seem to offer anymore benefit on those smaller tasks, 15s to 230ms is a really tremendous leap in performance but for many companies I doubt the 15s is a bottleneck in the first place so it&#x27;s not actually solving a problem there, it would be a nice to have.')