Item(by='sliken', descendants=None, kids=None, score=None, time=1606803787, title=None, item_type='comment', url=None, parent=25261619, text='I&#x27;ve replicated them myself with my own code, so I&#x27;m pretty confident.  It doesn&#x27;t hurt that my numbers match Anandtech&#x27;s, at least for the range of arrays they use and only using a single thread.<p>On pretty much any current CPU if you randomly access an array significantly larger than cache (12MB in the M1 case) you end up thrashing the TLB which significantly impacts latency.  The number of pages that can be quickly access depends on the number of page in the TLB.<p>To separate out TLB latency from memory latency I allow controlling size of the  sliding window for randomizing the array, so that only a few pages are heavily used at any one time, while visiting each cache line exactly once.<p>That&#x27;s exactly what the brown &quot;R per RV prange&quot; does.  For more info look at the description at:\n<a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;14072&#x2F;the-samsung-galaxy-s10plus-review&#x2F;5" rel="nofollow">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;14072&#x2F;the-samsung-galaxy-s10p...</a><p>My code builds an array, then does a knuth shuffle, but modified so the maximum shuffle distance is 64 pages, so the average shuffle is 32 pages or so.  I get a nice clean line at 34ns.  With 2 or 4 threads I get a throughput (not true latency) of a cacheline every 21ns.  With 8 threads (using the 4 slow and 4 fast cores) I get a somewhat better cacheline per 12.5ns.<p>Pretty stunning to have latencies that low on a low end $700 mac mini that embarrasses machines that costs 10x that much.  Even high end Epyc machines (200 watt TDP) with 8 x 64 bit memory channels have to try hard to get a cacheline every 10ns.')