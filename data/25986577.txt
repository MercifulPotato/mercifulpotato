Item(by='ramoz', descendants=None, kids=[25988532, 25987409, 25987105], score=None, time=1612166694, title=None, item_type='comment', url=None, parent=25986508, text='Advanced scheduling with K8s... inference requests distributed across a ton of spot&#x2F;preemptible VMs. We’ve achieved best performance on CPU with MKL.<p>It’s often a misconception that you need GPU for inference. It many cases, the overhead of data transfer to GPU makes it much slower than a well tuned CPU.')