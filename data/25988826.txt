Item(by='stingraycharles', descendants=None, kids=[25988898, 25989011], score=None, time=1612188790, title=None, item_type='comment', url=None, parent=25988702, text='Ok so I’ve evaluated spacy a few years ago, but nowadays we’re using huggingface’s transformers &#x2F; tokenizers &#x2F; etc to train our own language models + fine tuned models. I see there’s now transformer based pipeline support, how do the two relate?<p>Phrased differently, how does spacy fit in with today’s world of transformers? Would it still be interesting for me?')