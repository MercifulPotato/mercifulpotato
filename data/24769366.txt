Item(by='tboyd47', descendants=None, kids=None, score=None, time=1602617719, title=None, item_type='comment', url=None, parent=24753664, text='&gt; Glen Weyl is Founder and Chair of the RadicalxChange Foundation and Microsoft’s Office of the Chief Technology Officer Political Economist and Social Technologist (OCTOPEST). Jaron Lanier is the author of Ten Arguments for Deleting Your Social Media Accounts Right Now and Dawn of the New Everything. He (and Glen) are researchers at Microsoft but do not speak for the company.<p>The statement that Lanier and Weyl &quot;do not speak for the company&quot; includes an unacknowledged assumption that their position is not tacitly influenced by Microsoft. I don&#x27;t think this assumption is demonstrably true for these two, nor for anyone who works for a company. Rather, the general maxim applies: &quot;It&#x27;s difficult to make a man understand something when his sustenance depends on his not understanding it.&quot;<p>That said, what are Lanier and Weyl incentivized not to understand?<p>Let&#x27;s look deeper at (what I believe is) the central thesis of the article. There is a problem:<p>&gt; When people provide data, behavioral examples, and even active problem solving online, it is not considered “work” but is instead treated as part of an off-the-books barter for certain free internet services.<p>And the solution:<p>&gt; Active engagement is possible only if, unlike in the usual AI attitude, all contributors, not just elite engineers, are considered crucial role players and are financially compensated.<p>AI is presented as a one-sided type of commerce where &quot;contributors&quot; (the vast majority of people) are unwittingly exploited by &quot;elite engineers&quot; -- Google, Facebook, Twitter, Amazon, TikTok, etc. M$ plays in this space, but they lack a competitive advantage and do probably would prefer the whole idea disappear. I&#x27;ll call these two groups &quot;AI losers&quot; and &quot;AI winners&quot; for clarity.<p>Here&#x27;s how I interpret this thesis:<p>The AI losers consume, engage with, and create content, cluelessly leaving behind a trail of golden breadcrumbs (&quot;data&quot;) for the AI winners to profit from. To change this, AI losers just need to wake up to the fact that they&#x27;re all pooping out gold and start selling these nuggets to AI winners on some kind of open market.<p>The question looming above all of this is, &quot;Why haven&#x27;t they already done so?&quot; No one wants to ask this question, much less answer it.<p>Why is that? In the mindset of Lanier, Weyl and the entire &quot;humanist&quot; camp (including Tristan Harris and his team), the AI losers aren&#x27;t just being exploited, but they are too stupid to realize they&#x27;re being exploited. Hence, the injustice will only stop if brilliant ethicists like themselves step in to intervene. At present, they are addressing the general public, but inevitably their crusade will take them to Washington, where either they will team up with the same people they&#x27;re crusading against or fizzle out.<p>What they are incentivized not to understand is that the AI losers are not stupid. I don&#x27;t even agree that they&#x27;re necessarily being exploited. They&#x27;re getting world-class online services from giant tech companies without paying a cent. They&#x27;re also engaging in collective bargaining with these giants to get their way (via the social lever of brand safety, which is flawed, but that&#x27;s another issue). This is an equation that actually works in their favor; if the equation changes, you can&#x27;t assume that their behavior will remain the same.<p>Lanier and Weyl don&#x27;t consider that perhaps the AI losers pay $0.00 these services not because they de-value their own privacy, but because these services are actually worth $0.00 to them. They don&#x27;t see usage of technology as a choice on the part of consumers, but a compulsion that must be satisfied at any price. But they don&#x27;t know how many users a $5&#x2F;year Google would have, or a $5&#x2F;month Facebook, if any at all.<p>Another question that remains to be seen is what the legal environment is going to look like for these companies in the post-Snowden, post-Techlash environment. Is this &quot;data&quot; a trail of golden breadcrumbs (like all big tech spokespeople including Lanier and Weyl believe it is -- and in fact, their salary depends on that being so), or a trail of nuclear waste? Only time will tell, really.<p>I agree that there is a form of commerce going on, but the commerce is three-sided, not two-. It&#x27;s actually between the AI winners, AI losers, and the government, and it&#x27;s much more complicated than the authors lead on. I submit that the AI &quot;winners&quot; are in a more tenuous position (financially and legally) than we are being led to believe.')