Item(by='hailwren', descendants=None, kids=None, score=None, time=1606764649, title=None, item_type='comment', url=None, parent=25257694, text='There are two threads here. The first is that it would not be surprising to learn that describing the way that proteins fold is a very hard thing for humans to understand. See i.e. 4CT [1] and its computational proofs.<p>The second is that explainability in ML is much more tractable than it was 10 years ago. This is not to say that it&#x27;s solved, but having solved the predictive problem -- I would expect model simplifications and SME research to proceed more quickly towards understanding the how now. I did some work w&#x2F; an Astrophysics postdoc using beta-VAEs [2] to classify astronomical observations, and simplifying models in order to achieve human-explainability proved to not cost as much predictive power as you might expect. It might be that the same holds true here.<p>1- <a href="https:&#x2F;&#x2F;mathworld.wolfram.com&#x2F;Four-ColorTheorem.html" rel="nofollow">https:&#x2F;&#x2F;mathworld.wolfram.com&#x2F;Four-ColorTheorem.html</a><p>2 - <a href="https:&#x2F;&#x2F;paperswithcode.com&#x2F;method&#x2F;beta-vae" rel="nofollow">https:&#x2F;&#x2F;paperswithcode.com&#x2F;method&#x2F;beta-vae</a>')