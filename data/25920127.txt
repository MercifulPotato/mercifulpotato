Item(by='Animats', descendants=None, kids=[25923776, 25921183, 25921070, 25921261, 25920634], score=None, time=1611689686, title=None, item_type='comment', url=None, parent=25900461, text='That&#x27;s progress.<p>I&#x27;ve previously suggested that operating systems should have stronger file integrity guarantees. &quot;Unit&quot; files (rewriting replaces the whole file atomically, no reader ever sees a partially written file). That&#x27;s the default. &quot;Log&quot; files (always end at a clean end point, don&#x27;t tail off into junk). &quot;Temp&quot; files (disappear on reboot). And, for databases, &quot;Managed&quot; files.<p>Managed files have more I&#x2F;O functions. In particular, you get two completion events on writes - &quot;copy complete&quot; (the caller can reuse the buffer) and &quot;safely stored&quot; (the data has reached its final resting place, all links are complete, etc.). Programs like databases would use that. Those are the semantics databases want, and struggle to get by flushing, waiting, and various workarounds.<p>When I mention this, what usually happens is that people get lost in complicated workarounds for simulating unit files. Different approaches are needed for Linux, Windows, NTFS, and various VM systems. This should Just Work.<p>This isn&#x27;t my invention; it&#x27;s from Popek&#x27;s kernel in 1985 at UCLA, later seen as UCLA-Locus and as an IBM product. They had explicit commit and revert functions for file systems. I&#x27;d suggest having the default be commit on normal close or normal program exit, but if the program aborts or crashes or is killed, unit files don&#x27;t commit and remain unchanged.')