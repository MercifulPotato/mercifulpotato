Item(by='sinenomine', descendants=None, kids=None, score=None, time=1602439826, title=None, item_type='comment', url=None, parent=24745064, text='One can use this to express a large part of a deep ML model as a reversible function, thus drastically lowering memory requirements for backpropagation. The same technique, but applied by hand was recently used to speed up training for transformer language model: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2001.04451" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2001.04451</a><p>I think in the future we will see a trend of expressing most of DL model as reversible computation, with minimal irreversible module in the end and in the beginning.')