Item(by='vvern', descendants=None, kids=[25351863], score=None, time=1607461296, title=None, item_type='comment', url=None, parent=25350068, text='&gt; 1. Log &quot;intents to write&quot; rather than writes themselves in Topic A 2. Have a separate denormalization computed and kept in a separate Topic B, which can be read from. This denormalization needs to be read until the intent propagates from Topic A. 3. Convert those intents into commits. 4. Deal with all the failure cases in a distributed system, e.g. cleaning up abandoned intents, etc.<p>People do do this. I have done this. I wish I had been more principled with the error paths. It got there _eventually_.<p>It was a lot of code and complexity to ship a feature which in retrospect could have been nearly trivial with a transactional database. I&#x27;d say months rather than days. I won&#x27;t get those years of my life back.<p>The products were build on top of Kafka, Cassandra, and Elasticsearch where, over time, there was a desire to maintain some amount of referential integrity. The only reason we bought into this architecture at the time was horizontal scalability (not even multi-region). Kafka, sagas, 2PC at the &quot;application layer&quot; can work, but you&#x27;re going to spend a heck of a lot on engineering.<p>It was this experience that drove me to Cockroach and I&#x27;ve been spreading the good word ever since.<p>&gt; If you use an OLTP database, and generate events into Kafka via CDC, you get the best of both worlds.<p>This is the next chapter in the gospel of the distributed transaction.')