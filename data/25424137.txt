Item(by='simias', descendants=None, kids=[25424309], score=None, time=1607984233, title=None, item_type='comment', url=None, parent=25423098, text='It would sometimes work but I think this (very common comment) misses the general point, there&#x27;s absolutely fine and non buggy on warning-worthy code that can be optimized away if the compiler relies on UB. A very simple example:<p><pre><code>    void do_stuff(int *some_ptr) {\n        do_substuff(some_ptr);\n\n        *some_ptr += 2;\n    }\n\n    static void do_substuff(int *some_ptr) {\n        if (some_ptr != NULL) {\n            *some_ptr = 10;\n        }\n    }\n</code></pre>\ndo_stuff calls a subroutine that does a NULL pointer check, then unconditionally dereferences the same pointer.<p>From this the compiler, if it decides to inline that code, can decide to optimize the NULL check away since if the pointer is NULL it&#x27;s guaranteed to trigger UB. The logic being &quot;clearly the programmer assumes that the pointer can&#x27;t be NULL here, so thanks to UB rules I can too&quot;.<p>There&#x27;s nothing wrong with this code, there&#x27;s no reason to emit a warning.<p>Distinguishing between &quot;of course that&#x27;s a reasonable optimization, that&#x27;s probably what the developer intended&quot; and &quot;wow this compiler is so dumb, obviously I never meant for that to happen&quot; is a very tough nut to crack.<p>At this point you can push the blame to the C language not being expressive enough, in this case not giving us a way to express nullable vs. non-nullable pointers within the language, which forces the compiler to lean onto these UB heuristics to optimize.')