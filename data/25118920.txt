Item(by='RemingtonLak', descendants=None, kids=[25119066], score=None, time=1605572554, title=None, item_type='comment', url=None, parent=25118724, text='I feel our (human&#x27;s) great &quot;weakness&quot; or crutch is to care for one another.   I believe we have this inherent nature to care.  Unless you&#x27;re power&#x2F;money hungry, then even the act of killing won&#x27;t deter as long as that person doesn&#x27;t witness it.  Case and point: Covid.<p>although I guess one could &quot;code&quot; that ethics like aka Isaac&#x27;s 3 rules of robotics but how would one do that to an autonomous killing drone?  Or an autonomous car that needs to decide to kill one person or several depending on what?  that one person is a father of 6 and does humanitarian work vs the other 6 are criminal low lifes?  How does one &quot;code&quot; such algo?<p>Yes AI is a tool but then it wields a car, drone, finances that determines whether you get cancer treatment or not when you&#x27;re 80.<p>Yeah, we&#x27;re entering into a new phase of humanity.....<p>Funny, these are the exact same philosophical thoughts the Terminator movie series was addressing.  Where the AI did become onto itself and became &quot;self aware.&quot;  Then did the only logical thing: get rid of humans which is the cancer to everything&#x27;s existence.<p>Lots existentials to go through.  Should we force AI to go through that?  Maybe should be a prerequisite before we let it &quot;live.&quot;')