Item(by='naniwaduni', descendants=None, kids=[25905131, 25909290], score=None, time=1611553230, title=None, item_type='comment', url=None, parent=25898936, text='It looks pretty much the some, except that you assume the input is already in your library&#x27;s canonical encoding (probably utf-8 nowadays).<p>I realize this sounds like a total cop-out, but when the use-case is destructively best-effort tokenizing an input string using library functions, it doesn&#x27;t really matter whether your internal encoding is utf-32 or utf-8. I mean, under the hood, normalize still has to map arbitrary-length sequences to arbitrary-length sequences even when working with utf-32 (see: unicodedata.normalize(&quot;NFKC&quot;, &quot;a\\u0301 ï¬ƒ&quot;) == &quot;\\xe1 ffi&quot;).<p>So on the happy path, you don&#x27;t see much of a difference.<p>The main observable difference is that if you take input without decoding it explicitly, then the always-decode approach has already crashed long before reaching this function, while the assume-the-encoding approach probably spouts gibberish at this point. And sure, there are plenty of plausible scenarios where you&#x27;d rather get the crash than subtly broken behaviour. But ... I don&#x27;t see this reasonably being one of them, considering that you&#x27;re apparently okay with discarding all \\W+.')