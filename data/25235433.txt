Item(by='nickysielicki', descendants=None, kids=[25235962, 25236321], score=None, time=1606539927, title=None, item_type='comment', url=None, parent=25234830, text='&gt; The reality is that the reasons these chips are fast are either unknown or boring. I suspect that these will one out as we play around with them more, but we donâ€™t have the details right now.<p>I disagree, I think we have plenty of information. This is what happens when a huge proportion of your die isn&#x27;t doing instruction decoding. x86&#x2F;amd64 are old and crufty. Lessons have been learned, and had been learned for some time, but people (AMD&#x2F;Intel) were not brave enough to fix them because they didn&#x27;t have adequate control of their software ecosystem to say, &quot;Your software from your old computer will not run&#x2F;will not run as well on your new computer.&quot; (For emphasis, let me just put it clearly what I&#x27;m claiming: x86 was designed in the 1970s. This is what happens when you use an ISA that was not designed in the 1970s.)<p>Apple, however, does have control of their ecosystem, and they&#x27;re allowed to be brave, provided they can support their ecosystem.<p>Here&#x27;s my hot take: Intel tried to be brave with Itanium, but failed because compilers weren&#x27;t up to the job at the time. That&#x27;s changed. First things first, we&#x27;re going to see mainstream desktop-class&#x2F;laptop-class ARM being extended to linux and Windows. But I also believe that sometime in the next ten years, after all this newfangled high-performance ARM stuff is sorted out, we&#x27;re also going to see someone give VLIW another shot, and they&#x27;re going to succeed this time.')