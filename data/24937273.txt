Item(by='mlyle', descendants=None, kids=None, score=None, time=1604013628, title=None, item_type='comment', url=None, parent=24923109, text='&gt; 20% faster is nothing. You want at least a magnitude faster to justify the cost and risk of switching.<p>Eh.  If newer versions of cpython end up 20% faster, eventually most things will end up running on those newer versions.  It may take years for almost everything to drift to newer versions, but there&#x27;s a noticeable performance benefit we all realize over time.<p>&gt; Learn the lessons from both the good and bad of whatâ€™s been done before, and move on. A better long-term answer would be to design a much faster, more efficient language for running Numpy, Scikit, and Tensorflow, then port those libraries over to that. If that language turns out to be good for other things too, then great. If not, let a thousand flowers bloom.<p>Python&#x27;s great at running numpy, scikit, and tensorflow.  It&#x27;s not the bottleneck, because these are largely native libraries-- achieving something &quot;much faster&quot; and &quot;more efficient&quot; for this are doubtful.<p>The benefits of Python are that it A) has a huge ecosystem, B) it&#x27;s relatively polished and expedient to write code in, and C) there&#x27;s a ton of people who know it.  These are not easy things to create somewhere else, and there&#x27;s no guarantee that the set of tradeoffs you choose will leave you in a better place afterwards.<p>The biggest downside of Python is that if you want to get a lot of concurrency or performance for Python code (instead of things like numpy, scikit, and tensorflow), you get pushed into the edges of the Python ecosystem, where you only get a <i>portion</i> of A&#x27;s advantage (but still largely realize B &amp; C).')