Item(by='mannykannot', descendants=None, kids=[24767430], score=None, time=1602606945, title=None, item_type='comment', url=None, parent=24766243, text='Your response on definitions actually supports my point on the matter: definitions follow from knowledge (&quot;a phenomenon that everyone agree exists&quot;) and are modified in response to new knowledge (&quot;if that definition turns out to be adequate...&quot; - and if not?) As before, &quot;energy&quot; stands as an example of how it works, and &quot;computability&quot; did not enter the lexicon until there was a use for it.<p>Nevertheless, I agree that in the specific case of current AI, using the word &quot;intelligence&quot; is misleading. I do not, however, think this misuse has any serious consequences, as, to reverse how I put it before, usage does not establish truths about the world.<p>&gt;&gt; which are not &quot;just&quot; machine code either<p>&gt; I&#x27;m using &quot;machine code&quot; as proxy for &quot;instructions&#x2F;lambdas&#x2F;whatever for a computational model of your choice&quot;, which they certainly are.<p>Then that is an unfortunate choice of proxy, unless, perhaps, you intended to imply that it is a priori impossible for intelligence to be created by running x86 machine code. It was not clear to me whether, by introducing machine code into the discussion, you were not making some sort of argument from incredulity against the possibility of AI.<p>&gt; My point is that any association of a formal concept (math, models, etc.) with philosophical concepts (intelligence, &quot;truths about the world&quot;, consciousness, etc.) is always on thin ice, because natural language and formal concepts are hard to mix. Especially so when the concepts at play are so ephemeral.<p>At least since Newton, mathematical models have proved very useful in discerning truths about the world. Are we to just assume they will not work for the biological phenomena of intelligence and consciousness?')