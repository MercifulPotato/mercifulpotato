Item(by='bschne', descendants=None, kids=None, score=None, time=1611917915, title=None, item_type='comment', url=None, parent=25953897, text='I loved reading this earlier!<p>&gt; well - have you heard the story of statistical prediction rules in medicine?<p>That just crossed my mind recently with all the talk of bias in AI&#x2F;ML applications (let&#x27;s not say &quot;algorithms&quot;). Horror stories abound, and I do realize today&#x27;s systems are vastly more complex &amp; less (to use a term from this post) legible to humans trying to reason about what&#x27;s going on, but somehow it seems like this aspect is omitted from many discussions today, whereas previously taking the human out of the equation was seen as a success story in some fields.<p>There&#x27;s probably also other issues, e.g. that if you&#x27;re not careful ML can overfit to things that have nothing to do with what you&#x27;re looking for (e.g. all your positive example photos were taken with a different camera than the negative ones, or what have you), which aren&#x27;t as big a deal with those simple rules from medicine. But I feel like I&#x27;m not really clear on the state of this discussion.<p>If anyone knows a good paper&#x2F;article&#x2F;book that deals with the tradeoff between potentially embedding some form of bias in these systems vs. the also very real biases of, you know, human decision making, but focused on contemporary ML, I&#x27;d love to read up on this.')