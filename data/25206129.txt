Item(by='accountofme', descendants=None, kids=[25209323], score=None, time=1606279680, title=None, item_type='comment', url=None, parent=25205199, text='RAM bandwidth limitations (latency and throughput) are generally hidden by the multiple layers of cache in between the ram and CPU prefetching more data than is generally needed. Having memory on chip could make the latency less, but as ATI has shown with HBM memory on a previous generation of its GPUs its not a silver bullet solution.<p>I am going to speculate now, but maybe, just maybe, if some of the silicon that apple has used on the M1 is used for compression&#x2F;decompression they could be transparently compressing all ram in hardware. Since this offloaded from the CPUs and allows a compressed stream of data from memory, they achieve greater ram bandwidth, less latency and less usage for a given amount of memory. If this is the case I hope that the memory has ECC and&#x2F;or the compression has parity checking....')