Item(by='computerphage', descendants=None, kids=None, score=None, time=1609085216, title=None, item_type='comment', url=None, parent=25551854, text='That&#x27;s one of RL&#x27;s traditional formulations, yes. Bandits problems are another one. They&#x27;ve been generalized together into POMDPs partially observable Markov decision processes.')