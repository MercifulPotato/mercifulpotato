Item(by='curryst', descendants=None, kids=[25917989], score=None, time=1611675392, title=None, item_type='comment', url=None, parent=25910720, text='You&#x27;re interweaving several different issues here.<p>&gt; Why fumble around with synchronization? 99% of the data in big datasets doesn&#x27;t change. This doesn&#x27;t even have to be &quot;log-based&quot;, we just need to be able to ship the old, stable data and treat it almost like &quot;cold storage&quot;.<p>This is not a feature of SQL, this is a feature of the database.  Also, this sounds exactly like doing full-table replication to get the &quot;old&quot; data and then turning on log-based replication.  You can do key-based replication if you really want to avoid log-based, but it&#x27;s generally just a less efficient version of log-based replication.<p>&gt; Why is there a single point of entry into the data? You have to use the one database cluster to access the one database and the one set of tables. Why can&#x27;t we expose that same data in multiple ways, using multiple pieces of software, on multiple endpoints?<p>You can.  Postgres supports both Perl and Python extensions that run in the RDBMS process, iirc.  Very few people use them because running in the RDBMS process means that you can break the RDBMS process in really bad ways, and it is very difficult to gain any benefits over just running a separate process that communicates over SQL.<p>So if you consider other processes that communicate with the database and then show views of that over other protocols, that describes most of the backend apps in the world.<p>There&#x27;s also stuff like Presto[1] that allows you to run queries distributed over multiple databases, multiple types of databases, etc, etc, etc.  In that case, conceptually, Presto is &quot;the database&quot; and all the records you refer to are remote.<p>1: <a href="https:&#x2F;&#x2F;prestodb.io&#x2F;" rel="nofollow">https:&#x2F;&#x2F;prestodb.io&#x2F;</a>')