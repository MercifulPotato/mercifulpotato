Item(by='13415', descendants=None, kids=[25608434], score=None, time=1609541411, title=None, item_type='comment', url=None, parent=25605473, text='The only alternatives I see:<p>1. National research funding agencies and universities need to stop doing their assessments based on publication counting. Of course, publications need to be taken into account somehow, but at the very least these indicators should be weighed by curated rankings of journals.<p>2. Existing publications can be used as an indicator for how much output is to be expected in the future, but the goals for research output should be kept reasonably low. You cannot control the output of researchers, you can only control which ones you hire and (to some extent) the type of research they conduct.<p>3. Hiring in academia needs to be based more often on screening candidates by committees of outside experts in the field instead of local staff and people who don&#x27;t know the area well. Projects also always need to be evaluated by experts on project&#x27;s topic. (As strange as this may sound, this is often not the case!) It might even help to prune away irrelevant indicators, e.g. ask candidates to submit only 3-5 of their best publications and completely ignore the rest. And by &quot;completely&quot; I really mean completely. The reason is that if you have two researchers and one of them has 20 publications with five really good ones, and the other has 40 mediocre publications and not a single good one, then it is very hard for a normal assessment committee to justify taking the first one, but it&#x27;s always easy to converge on the second one, even if that is exactly the wrong choice.<p>4. Assessment committees need to be told to evaluate the quality and originality of the research only. If you really want or need a certain output quantity, then make it part of the formal hiring criteria, not part of the scientific evaluation.<p>5. Increase funding for risky projects and risky individual grants, elimination of criteria that exclude unusual CVs (e.g. allow long time after PhD, people from other areas, people with time spent in business, unusual research suggestions). Originality should be one of the highest ranking criteria. There should also be a focus on versatility and <i>hard skills</i>. Even in the humanities, never hire anyone who says anything disparaging about mathematical methods and statistics, and never leverage people who don&#x27;t know the tools of their trade into positions of power.<p>Basically, you cannot push scientists to anything. Once someone is hired at the postdoc level, you cannot steer much, micromanagement and constant evaluation are highly counter-productive. You need to hire scientists that do interesting research. Treat them like an investment in a startup: Most of them will fail but some of them will succeed. Give them a second chance, maybe even a third one, but not indefinitely many. The hiring policies and processes at universities are often bad. Candidates are not evaluated by experts, there is plenty of favoritism, boring high producers are favored over interesting researchers who want to built something up, because the local staff doesn&#x27;t like scientists who &quot;shake things up&quot;, and so on. There is a lot of inertia to overcome in Academia, being a good scientist can sometimes even be harmful to your career. Funding agencies need to steer against this.<p><i>Edit: Much of what I mention can also be achieved by getting an absolute top researcher in an area, give him or her an institute or research unit and ton of money, and let them do their thing. They know what to do and whom to hire. But it&#x27;s expensive.</i>')