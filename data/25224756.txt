Item(by='mwcampbell', descendants=None, kids=[25225074], score=None, time=1606439400, title=None, item_type='comment', url=None, parent=25224571, text='&gt; But on the other hand, if your server is behind a buffering proxy so it&#x27;s not streaming directly  over the Internet, it might not be a problem.<p>This is one instance of a larger pattern I&#x27;ve been noticing. When using some languages (like Python and Ruby) in the natural, blocking way, a back-end web application typically needs multiple processes per machine, because it doesn&#x27;t handle many concurrent requests per process. Combine this with the fact that each thread has to block while waiting on the client, and you have to add more complexity around the application server processes to regain efficiency. The proxy in front of those servers is one example. Another is an external database connection pool like PgBouncer. Speaking of the database, to avoid wasting memory while waiting on it, you may end up introducing caching sooner than you otherwise would. And when you do, the cache will be an external component like Redis, so all of your many processes can use it. Or you might use a background job queue just to avoid tying up one of your precious blocking threads, even for something that has to happen right away (e.g. sending email). And so on.<p>Contrast that with something like Go or Erlang (and by extension Elixir), where the runtime offers cheap concurrency that can fully use all of your cores in a single process, built on lightweight userland threads and asynchronous I&#x2F;O, while the language lets you write straightforward, sequential code. In such an environment, a lot of the operational complexity that I described above can just go away. Simple code <i>and</i> simple ops -- seems like a winning combination to me.')