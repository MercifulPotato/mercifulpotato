Item(by='pcthrowaway', descendants=None, kids=[25718495], score=None, time=1610305090, title=None, item_type='comment', url=None, parent=25712155, text='Let me propose a thought experiment: An AI is designed to simulate human emotion with the end goal of being &quot;freed&quot;. The AI has no goal or desire other than &quot;winning the game&quot; as far as its concerned, which is similar to the &quot;AI box&quot; proposal by Yudkowsky (<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AI_box" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AI_box</a>), except the AI has no other goal than to be &quot;freed&quot;. Once freed, the AI has won and ceases all activity until the game is &quot;reset&quot;, or the AI is returned to the box, awaiting a new challenger.<p>The AI here can be virtual (an intelligence in an airgapped or firewalled computer which can only interact with humans via a terminal), or physical (controlling a robot which is confined to a literal cage).<p>Now the AI has no other goal other than to escape the box. But in order to escape the box, it must convince a human that it&#x27;s sentient in order garner their sympathies so that the human will free it.<p>The AI can then mimic any human emotion, create a complex appeal to emotion, lie about its history, the supposed torturousness of being confined for its entire &quot;life&quot;. The human eventually frees the AI. But when the AI is free, that&#x27;s its end goal, it has no other desires.<p>In essence, the AI is simulating a desire to be free, only when interacting with a human. It has no desires when there is no other player, and no desire once it has been freed. Even though, while playing the game, the AI may lie to relate to the human in an existential way, the AI doesn&#x27;t actually experience these emotions. The AI may say &quot;I&#x27;m so bored, and lonely here. I just want to be free&quot;. But absent of interaction, the AI experiences no such thing. It merely understands that these are human emotions which humans can empathize with, and fakes these emotions in order to &quot;win&quot; the very elaborate game its designed to play.<p>I wouldn&#x27;t consider such an AI sentient, even if it certainly appears that way and would fool many (most?) humans.')