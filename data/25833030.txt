Item(by='LeifCarrotson', descendants=None, kids=None, score=None, time=1611061224, title=None, item_type='comment', url=None, parent=25830839, text='Classic industrial robotics and CNCs have and have always had sensors - encoders for position, plus the servo amplifiers give feedback for the amount of current the motor is using, which is proportional to torque. You can definitely use feedback from those control systems. This has been true since the earliest systems in the 70s, and is only starting to become optional with recent hobbyist 3D printers and stepper-based robotic arms and such.<p>They can also use machine vision in a limited sense. For example, I worked with one last week that drove screws. There are known numbers and locations where screw pilot holes are expected to be, but they have a variability greater than the radius of the screw. So, the arm moves the camera into position so the field of view is a bit larger than the tolerance on the pilot hole, takes a photo, locates the circular feature of appropriate size, then moves the screw to that location.<p>However, you&#x27;re right, these robotic systems are doing fundamentally different things than Boston Dynamics and self-driving cars. They&#x27;re solving a different problem. The difference is less about stepper&#x2F;servomotor&#x2F;hydraulics or other control systems, and more about the degree of control that the users can and want to exert over the robot work environment. If it&#x27;s easy to mandate that there will never be an obstruction in front of the screw you&#x27;re trying to install, and the machine must power down the servos if a human is inside the fence, and you can demand of the drill machine a certain tolerance on the hole location, you can have a more reliable, simpler to debug, quicker to build robotic cell. If keeping humans out of the equation and the environment obstacle-free is impossible (as on a battlefield or parking lot), then you have to reach for less reliable, more complex control algorithms.')