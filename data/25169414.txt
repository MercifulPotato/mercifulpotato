Item(by='ece', descendants=None, kids=None, score=None, time=1605963002, title=None, item_type='comment', url=None, parent=25167965, text='I ran memtest+ for a weekend every 3 months or so on 64GB DDR4 Ryzen system for 2+ years and haven&#x27;t found anything. Rock solid system, which has been on almost 24&#x2F;7. No data loss that I can verify with backups.<p>I think the point about chipkill is salient, why isn&#x27;t it more widely used if the benefits there are obvious? I think ECC is completely not worth the price for home users if you can do regular backups, run memtest, and compare checksums for any data corruption. Even with errors near the hard&#x2F;soft boundary, you&#x27;ll likely catch those by just running memtest for a longer period of time. DRAM errors get progressively worse, so you&#x27;ll catch any errors that way as well using memtest again.<p>Datacenters have more surface area which cosmic rays can attack and are also more likely to see weird hard errors which might not have been caught in QC&#x2F;QA, which is very different from isolated home computers or phones which aren&#x27;t on 24&#x2F;7 or can restart easily. If you have a datacenter and have truly sensitive unreplicated data, get chipkill. If you are home user, do regular backups, and run memtest. It&#x27;s that simple. Hard drives have moving parts, and more failure modes, so pick a file system with checksums. CPUs&#x2F;GPUs and SSDs might or might not have ECC caches because they have other ways of reducing hard&#x2F;soft errors in SRAM.<p>People may disagree, but the study I would like to see is one that takes into account the denser environment of a datacenter vs the isolated home user and all modes of data loss&#x2F;corruption in each case. We know Google replicates data in GFS, and a home user can do the same with backups.')