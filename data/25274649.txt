Item(by='foota', descendants=None, kids=None, score=None, time=1606899935, title=None, item_type='comment', url=None, parent=25273968, text='This documentation talks about it in brief: <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;whitepapers&#x2F;life-of-reads-and-writes" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;spanner&#x2F;docs&#x2F;whitepapers&#x2F;life-of-re...</a>. You can read the spanner paper for more detail: <a href="https:&#x2F;&#x2F;static.googleusercontent.com&#x2F;media&#x2F;research.google.com&#x2F;en&#x2F;&#x2F;archive&#x2F;spanner-osdi2012.pdf" rel="nofollow">https:&#x2F;&#x2F;static.googleusercontent.com&#x2F;media&#x2F;research.google.c...</a><p>The simple answer is that there are round trips required between datacenters when you have a quorum that spans data centers. Additionally, one replica of a split is the leader, and the leader holds write locks. So already you have to talk to the leader replica, even if it&#x27;s out of the DC you&#x27;re in. Getting the write lock overlaps with the transaction commit though. So for your example if we say the leader is in Canada and the client is in Australia, and we&#x27;re doing a write to row &#x27;Foo&#x27; without first reading (a so called blind write):<p>Client (Australia) -&gt; Leader (Canada): Take a write write lock on &#x27;Foo&#x27; and try to commit transaction<p>Leader -&gt; other replicas: Start commit, timestamp 123<p>Other replicas -&gt; Leader: Ready for commit<p>Leader waits for majority ready for commit and for timestamp 123 to be before the current truetime interval<p>Leader -&gt; Other replicas: Commit transaction, and in parallel replies to client.<p>Of course there are things you can do to mitigate this depending on your needs, but there&#x27;s no free lunch. If you have a client in Australia and a client in Canada writing to the same data you&#x27;re going to pay for round trips for transactions.')