Item(by='jstimpfle', descendants=None, kids=None, score=None, time=1609863887, title=None, item_type='comment', url=None, parent=25646747, text='&gt; That extra data is used in a linear scan, but is mostly wasted when doing random access<p>You are shifting goalposts. What the parent poster said is that a linear scan will read more memory than a binary search, therefore it will cause more churn in the cache (assuming same cache policies, which I don&#x27;t know is a safe assumption), therefore linear scan may actually be less cache friendly - given that you&#x27;re not interested in the data in any other way besides for the scan - by way of putting other parts of the program whose data was pushed out of the cache at a disadvantage.<p>Implied was also that linear scan might actually result in a slower program, even if the scan itself might be faster than a binary search.<p>What you replied is &quot;The CPU will load less cache data with linear searches&quot;, which I assume to be false, although I will be happy to learn that it&#x27;s actually the case (for example because the CPU has a clever cache eviction policy, executing linear scans by streaming in memory into a small part of the cache instead of thrashing the whole cache).<p>Let&#x27;s say we have an array of 200 4-byte ints. Let&#x27;s do a linear array scan and on average will touch 100 of them (or about 7 cache lines). Now let&#x27;s say we have each integer in its own linked node in a BST in a totally random memory location. We can expect to need about 7 steps as well (2^8 = 256 &gt; 200), which is 7 cache lines. So about 200 is already a lower bound where BST is more efficient in terms of visited cache lines, even for a pessimistic inefficient data structure like this 4-byte integer example.')