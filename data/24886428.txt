Item(by='dragontamer', descendants=None, kids=[24888129, 24888507, 24890933, 24887032], score=None, time=1603635243, title=None, item_type='comment', url=None, parent=24886395, text='x86  has 4k, 2MB, and 1GB page sizes.<p>&gt; This would reduce the amount of bookkeeping if the OS hands out physical memory in large contiguous tracts, but increase it if it is shuffling around individual pages. I have no idea what OS behaviour here actually is.<p>On x86, large 2MB and 1GB __cannot__ be paged. The latency associated with a 2MB or 1GB read&#x2F;write to disk is just too long to be reasonable.<p>These are called &quot;huge pages&quot; (2MB or larger). Memory-intensive applications see benefits from huge-pages, but the additional book-keeping to the user (in particular: huge pages CANNOT be paged, and therefore are a &quot;rare-ish resource&quot;) has made HugePages somewhat uncommon on both Linux and Windows. (Windows only supports the 2MB hugepage, and ignores the 1GB option entirely)<p>&gt; This would reduce the amount of bookkeeping if the OS hands out physical memory in large contiguous tracts<p>Note that all modern chips have a TLB-cache, to the point where the bookkeeping is largely handled by the CPU itself. This TLB-cache still has restrictions, so a huge-page reduces book-keeping and accelerates the speed of memory access slightly.<p>The OS sets up the table, but the CPU itself handles the whole shebang nearly transparently. That&#x27;s why all of these memory-address and data-structure specific details show up when talking about page-tables, you&#x27;ve got to set up the data-structure precisely so that the dedicated hradware inside the CPU can traverse the table correctly.')