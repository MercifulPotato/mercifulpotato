Item(by='TheRealPomax', descendants=None, kids=[24654979], score=None, time=1601569818, title=None, item_type='comment', url=None, parent=24652222, text='A dictionary of n-grams does not change its probabilities based on &quot;text seen so far&quot;, so you&#x27;d need an unbounded n. In practice, n-gram dictionaries don&#x27;t encode for more than very low values of n, so while yes, abstractly we can say that GPT-2 is equivalent to an n-gram dictionary with some high n, those dictionary cannot be constructed, let alone used, leaving the equivalency is purely theoretical.<p>GPT-2 is not a dictionary.')