Item(by='dragonwriter', descendants=None, kids=[25757188], score=None, time=1610501013, title=None, item_type='comment', url=None, parent=25755323, text='&gt; &gt; For many kinds of criminal content posing an acute public safety hazard, it does, and it&#x27;s very simple: if you have knowledge of the existence of the material, you must take it down or become yourself criminally liable for it.<p>&gt; I&#x27;d be quite surprised if this is true in the USA. If you could provide an example of such a case I&#x27;d be very interested. The only time I&#x27;m aware of the Supreme Court ruling on online hate speech<p>This isn&#x27;t about hate speech, which is protected speech. It&#x27;s about a subset of content which is itself criminal (that is, for which the source would be criminally liable), where a service provider knows of the content and the facts which make it criminal (whether or not they understand the criminal prohibition itself)<p>And it&#x27;s not about civil liability (things some private party can sue you for damages, and where therefore the Section 230 protection is likely to apply) but criminal liability, that is, things where the government can take action leading to criminal fines and&#x2F;or imprisonment.<p>Examples of laws creating this kind of knowledge-based obligation are 18 USC Sec 2339A regarding material sorry to terrorists and 18 USC Sec 1466A with regard to obscene visual representation of the sexual abuse of children.')