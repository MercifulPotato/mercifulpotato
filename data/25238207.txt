Item(by='loup-vaillant', descendants=None, kids=[25238265, 25239354, 25238861], score=None, time=1606578236, title=None, item_type='comment', url=None, parent=25237356, text='Tow things.<p>First, probability <i>is</i> real: it&#x27;s a construct in one&#x27;s mind, and minds are just as real as dice or coins.  <a href="https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;f6ZLxEWaankRZ2Crv&#x2F;probability-is-in-the-mind" rel="nofollow">https:&#x2F;&#x2F;www.lesswrong.com&#x2F;posts&#x2F;f6ZLxEWaankRZ2Crv&#x2F;probabilit...</a><p>Second, (and the author may be leading up to this), there&#x27;s Solomonoff&#x27;s theory of inductive inference, which he has proven <i>complete</i>: when we apply Occam&#x27;s razor (where the prior probability of each possible theory drops exponentially with its size), the amount of error a perfect Bayesian makes as they observe event and bet on the next one, ad infinitum, is <i>finite</i>. Roughly proportional to the complexity of the simplest theory that correctly predict the whole sequence of events. It&#x27;s one of the most convincing proofs that Bayesian reasoning <i>works</i>.  <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Solomonoff&#x27;s_theory_of_inductive_inference" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Solomonoff&#x27;s_theory_of_inducti...</a><p>There&#x27;s just a little snag. Perfect Bayesian reasoning is impossible to compute, so us mortals have to resort to approximations. Just as perfect certainty isn&#x27;t possible, perfect reasoning is not attainable. Oh well.')