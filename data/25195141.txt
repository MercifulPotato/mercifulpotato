Item(by='ramraj07', descendants=None, kids=None, score=None, time=1606190383, title=None, item_type='comment', url=None, parent=25189455, text='I have had significantly better uptime with my production dashboard app running on an EC2 instance that has been up and running for 3 years straight, than every other team I am aware of that uses kubernetes. The more complexity you add, the worse things get.<p>Of course, you can&#x27;t most of the time run production apps on a single machine, but my general approach has been to add the least amount of infra overhead - in our case it has been elastic beanstalk. It has been reliabile and zero touch for us for years now. I have heard of some people saying EB is good till it works and when it doesn&#x27;t you&#x27;re screwed - my backup plan for that case is to continue keeping that EC2 instance running, and generally make sure you can run your app without too much hassle in a fundamentally different stack at any given time.<p>In the end, by depending on RDS and EB we have never had to worry about infra or scaling in our team. This is in stark contrast to every other team I&#x27;ve seen or worked with, where upgrading your eks version, or certificates expiring or etcd getting unresponsive or environment variables leaking between multiple prod and stage or someone accidentally deploying to prod because they didn&#x27;t specify the correct name space in their deploy script or a hundred other reasons made their k8s deployment a nightmare. You can argue that this is a sign of bad training or practice, but I&#x27;m working with the same engineers on this stack that&#x27;s so much more foolproof so when can we start blaming the tool a bit as well?')