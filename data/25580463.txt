Item(by='PeterisP', descendants=None, kids=None, score=None, time=1609324075, title=None, item_type='comment', url=None, parent=25580206, text='This seems a quite orthogonal issue to what I was talking about - your comment seems to be about the separation of pipeline in subtasks, while I was talking about methods used for particular subtasks; I would not consider &quot;try to flatten the image first&quot; as part of feature engineering, I would consider it as a preprocessing task that <i>might</i> be done as an engineered feature, but also might be done as a machine-learned subtask, or skipped entirely, or integrated in a more general transformation that&#x27;s believed to inherently correct for non-flat images.<p>I don&#x27;t work on OCR much (and when I did, it was for book digitization which doesn&#x27;t have these specific challenges), so I don&#x27;t have an opinion on what&#x27;s the state of art for a task like you describe (I&#x27;m imagining analysis of receipts or something like that), however, across many domains of ML (incliding but not limited to computer vision) we are seeing the advantages of end-to-end optimization.<p>So, for example, the image preprocessing we would like to allow for input of raw phone camera images includes correction for lighting, angle, and crumpledness of paper. Obviously, I agree that these things should be done, but I do not necessarily agree that they must be done as separate engineered features.<p>I don&#x27;t have an opinion on what&#x27;s the best option &quot;today in production&quot; for OCR - it&#x27;s plausible that the engineered feature way is still the best at the moment, but if we&#x27;re looking at where the field is moving to, then I&#x27;d argue that there is a strong tendencytowards (a) using numerically optimizable methods for these corrections as opposed to hand-selected heuristics; (b) optimizing these corrections for a final OCR result as opposed to treating it as a separate task with separate metrics to optimize; and eventually (c) integrating them in an end-to-end system instead of a clearly separable stage of &quot;correcting for X&quot;. I&#x27;m not certain where the state of art for noisy OCR is <i>today</i> on this, but it&#x27;s a one-way direction; The key point of my comment above is that once (if!) we get these things to work I would not expect to go backwards to specific handcrafted features ever. It&#x27;s plausible that some tasks are better treated as separate and can&#x27;t be integrated well (perhaps the selection of text segments in your OCR example is like that), but for the features that we already <i>have</i> managed to successfully integrate (which was the topic discussed in the grandparent comment), IMHO there is no reason to ever go back.<p>Perhaps a relevant example of a field that has undergone this transformation is machine translation - where just a few years ago production pipelines included literally hundreds of separate subsystems for niche subtasks conceptually similar to those you mention regarding OCR, the shift to neural ML was accompanied by making these subsystems redundant as doing the same thing in an integrated end-to-end optimizable way gets better results <i>and</i> is simpler to implement, maintain and debug due to a more unified architecture.<p>Similar trends have also happened for face recognition and for speech recognition - I would presume that OCR is structurally similar enough to see the same fate if it hasn&#x27;t already.')