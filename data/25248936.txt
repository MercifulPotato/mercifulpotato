Item(by='deathanatos', descendants=None, kids=None, score=None, time=1606691166, title=None, item_type='comment', url=None, parent=25248698, text='&gt; <i>I am not smart enough to make meaningful comments about cryptography, but the expectations from the user to verify things in real life seem the same in both cases.</i><p>It pretty much has to be, because it doesn&#x27;t fall out of any particular crypto algorithm or implementation. When you&#x27;re setting up an encrypted conversation with some other person, let&#x27;s say &quot;Bob&quot;, how do you ensure that you&#x27;ve actually set it up with Bob, vs. someone pretending to be Bob, or merely forwarding your messages to Bob so that both you &amp; Bob think you&#x27;re in contact, when you&#x27;ve really got an eavesdropper between you?<p>In essences, you have to make sure that whatever cryptographic material you&#x27;ve either created or exchanged in order to communicate — e.g., your public keys — are the <i>right</i> ones. (That is, you have actual-Bob&#x27;s key, not an attackers, and vice versa.) So, you must verify them, in whatever manner will convince you that you&#x27;ve gotten the right key(s). Verifying in person is essentially impossible to fake, unless you believe in masks like those from <i>Mission Impossible</i>.<p>In this regard, the really important bit is authentication — making sure you&#x27;re talking to the right person, not <i>just</i> making sure the conversation is private. It does no good to have a private conversation with the wrong person. One might refer to this as the &quot;binding&quot; between the cryptographic key(s) and the real-world meatspace entity (e.g., Bob) those keys represent. Is the binding we have the <i>right</i> binding? And that&#x27;s the hard problem, it isn&#x27;t &quot;solvable&quot; in the sense that we can make it invisible, but good UI can help immensely here.<p>That said, in-person verification isn&#x27;t the only way you can do things. &quot;Trust-on-first-use&quot; (&quot;TOFU&quot;), which is where you just blindly accept the key during the <i>first</i> conversation, but after that, you expect the same key. The idea being that it&#x27;s a trade-off between convenience and safety — as long as that first exchange is fine, then afterwards, we&#x27;d notice anything fishy. And if you get a different one, there needs to be a reason, like Bob saying &quot;oh I have a new phone now&quot; — but does Bob <i>actually</i> have a new phone (and for some reason couldn&#x27;t reuse the key from the old phone?) or is someone impersonating Bob using that as an excuse to get you to accept the new key.<p>Another example is the CA system used by certificates on the web. CA&#x27;s help establish the binding between a website &amp; its private key by signing certificates. They verify keys, e.g., through the ACME challenges. It&#x27;s definitely not without its defects, and a fair amount of ink has been spilled over the problems with the CA system. But it again represents a system of figuring out those bindings.<p>Now, what you <i>should</i> do, e.g., whether TOFU suffices or not, should probably be dictated by some form of threat model. What risks are acceptable to you, what attacks do you expect to see, or that you must guard against (perhaps, e.g., due to legal requirement)? Those will tell you if, e.g., TOFU suffices, or if you need something stronger.<p>From personal experience, specifically with GPG, just getting someone to display, e.g., a GPG fingerprint, long enough to <i>verify</i> it, is a PITA. It takes all of 15 minutes, but the people I&#x27;ve generally had to do this with are too impatient, and expect it to be simpler and quicker than GPG makes it. Marlinspike&#x27;s article touches on that sort of stuff in &quot;technological dead end&quot;; although he is mentioning it more from an API integration point of view (which is painful), just day-to-day use of the CLI is also painful, and painful to teach.')