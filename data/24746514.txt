Item(by='jcranmer', descendants=None, kids=None, score=None, time=1602430815, title=None, item_type='comment', url=None, parent=24746022, text='When I took numerical analysis, the concept was described as &quot;machine epsilon&quot;, which is the smallest number that can be added to 1.0 that is not 1.0.<p>The utility of this metric is that it tells you the best possible relative error, as you can never guarantee a result will be more correct to the true result (in the domain of mathematical real numbers as opposed to machine floating-point numbers) than half of machine epsilon.<p>This concept is often extended into discussions of &quot;units in the last place&quot; (ULPs), which is the magnitude of the value of last bit of the mantissa. So ulp(1.0) = ulp(1.5) = machine epsilon, ulp(2.0) = ulp(3.9) = 2 * machine epsilon, etc. A good floating-point library will document its accuracy in terms of ulps, so that we might say that the maximum error of the exp function is 1 ULP and that of pow might be 6 ULPs.')