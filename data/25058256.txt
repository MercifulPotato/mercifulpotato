Item(by='dragontamer', descendants=None, kids=None, score=None, time=1605101823, title=None, item_type='comment', url=None, parent=25050501, text='&gt; My main point is it&#x27;s actually the case that a copy ties mutation in speed quite often if you structure the flow of your data correctly. If you&#x27;re operating on a value, writing it somewhere else is often close to free.<p>So, here&#x27;s something. I think that a copying-based methodology can be fast, but more importantly, a copying-based methodology can be easier to parallelize.<p>If a mutating state is too hard to parallelize, I think rewriting things to be copy-based, and then using that copy-based methodology as a basis for parallel code, is a good idea.<p>What&#x27;s difficult is that &quot;mutating state&quot; is a local maximum so to speak: probably the fastest that any single-thread can get to. From this perspective, finding parallelism from a &quot;higher level&quot; can be more useful than trying to parallelize a well-optimized single-threaded program.<p>----------<p>Case in point: Multithreaded producer-consumer queues are difficult to write and even define. But multithreaded producer-producer queues (and consumer-consumer queues) are very easy: just an obvious &quot;atomic_add(tail, 1)&quot; (Producer) and &quot;atomic_subtract(tail, 1)&quot; (for consumers) kind of thing.<p>I call it a &quot;producer-producer&quot; queue, because you need assurances that no one is consuming from the queue for it to work. But if you synchronize your threads to all copy to a queue (and no one consumes from it), its really fast, and actually very parallelized. Ditto for the reverse (the consume phase).')