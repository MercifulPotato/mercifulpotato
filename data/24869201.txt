Item(by='spi', descendants=None, kids=[24869580], score=None, time=1603459472, title=None, item_type='comment', url=None, parent=24866610, text='I fully agree with this. As a data scientist, I always think that this is a &quot;natural&quot; consequence of one of the main (if not _the_ main) metric used to evaluate machine translation algorithms, which is BLEU: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;BLEU" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;BLEU</a><p>According to this metric, if you have a moderately long sentence like &quot;I am not the person who said the president should be reelected&quot; and your translation missed the &quot;not&quot;, you would still get a score of 11&#x2F;12 ~ 92%. And, as far as I know, word order doesn&#x27;t even matter, so &quot;I am the person who said the president should not be reelected&quot;, while wrong, would get a perfect score.<p>Of course these are rather artificial examples, and in general machine translation algorithms and their evaluation work because it&#x27;s &quot;easier&quot; to create an algorithm that gets the right translation than one that, unintentionally, fools the metric systematically. Nevertheless if the research community used a metric that punished this kind of mistakes more strongly, I suspect that over time a few new algorithms could come up that improve on this specific point.<p>Alas, I don&#x27;t know of any such metric (nor I would know how to design one, of course, otherwise I&#x27;d publish it ;-) ).')