Item(by='tutfbhuf', descendants=None, kids=[25173526, 25176214, 25173214, 25173533, 25173718, 25175542, 25174038, 25173439, 25173161], score=None, time=1605996453, title=None, item_type='comment', url=None, parent=25149154, text='High-availability durable filesystem is a difficult problem to solve. It usually starts with NFS, which is a big huge single point of failure. Depending on the nature of the application this might be good enough.<p>But if it&#x27;s not, you&#x27;ll typically want cross-datacenter replication so if one rack goes down you don&#x27;t lose all your data. So then you&#x27;re looking at something like Glusterfs&#x2F;MooseFS&#x2F;Ceph. But the latencies involved with synchronously replicating to multiple datacenters can really kill your performance. For example, try git cloning a large project onto a Glusterfs mount with &gt;20ms ping between nodes. It&#x27;s brutal.<p>Other products try to do asynchronous replication, EdgeFS is one I was looking at recently. This follows the general industry trend, like it or not, of &quot;eventually consistent is consistent enough&quot;. Not much better than a cron job + rsync, in my opinion, but for some workloads it&#x27;s good enough. If there&#x27;s a partition you&#x27;ll lose data.<p>Eventually you just give up and realize that a perfectly synchronized geographically distributed POSIX filesystem is a pipe dream, you bite the bullet and re-write your app against S3 and call it a day.')