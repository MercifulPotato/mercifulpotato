Item(by='f154hfds', descendants=None, kids=[25430409], score=None, time=1608040443, title=None, item_type='comment', url=None, parent=25427978, text='I find this semantic critique interesting but I have to disagree with you. Underlying the critique is a hidden arrogance.<p>Agency language is strongly tied to our ability to understand the mechanism by which phenomena occurred. For example, take 4 different chess bots:<p>1. The bot moves in a 100% predictable way to you (say it checks each piece in order to find a possible move, the first it finds that&#x27;s legal it moves)<p>2. The bot moves randomly<p>3. The bot uses minimax + library (traditional chess engine)<p>4. The bot is running via reinforcement learning<p>When we discuss the moves the bot made, in which of the above scenarios would we say it &#x27;chose&#x27; to move in a particular way? These different examples call out different forms of &#x27;agency&#x27;. In cases 3 and 4 (maybe even 2?) most people - including the creator of the bot - would say the bot chose to move pawn to c4.<p>As effect gets sufficiently far removed from cause it&#x27;s natural to ascribe agency to the mechanism. In a very real sense in case 4 the creator designed the bot but has no idea why it moves in certain ways - they can analyze the weights of course - but why did it &#x27;choose&#x27; those weights over others during training? If we knew that we wouldn&#x27;t need the costly training in the first place.<p>So back to your distaste of agency language when describing a phenomena. We&#x27;re talking about _incredibly_ complex machinery. There is no guarantee that these mechanisms are a 1. or even a 3. type bot. They could be a 5. or 6. (whatever that even means). Thus even if we knew _everything_ about the last order mechanism, we would still ascribe agency to the effect.')