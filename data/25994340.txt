Item(by='jpau', descendants=None, kids=[25994576, 25994411, 25994720, 25995478, 25994951, 25995861], score=None, time=1612215504, title=None, item_type='comment', url=None, parent=25992464, text='I&#x27;m deeply disappointed in Databricks as an RDBMS.<p>As a DS&#x2F;DE, there&#x27;s a lot to love (not all, but a lot). The easy provision of Spark clusters. The jobs API. DeltaLake (mostly). Easy notebooks (please don&#x27;t create a prod system from these..). And Spark itself continues to improve, albeit in an increasingly crowded field.<p>But I&#x27;ve worked closely with BigCo SQL analysts on Azure Databricks, and their experience was terrible. For example:<p><pre><code>  - You cannot browse the data structure without an active cluster\n  \n  - Starting a cluster can take ~5 minutes and, since you missed that moment, you may not submit your first query until 10-15 minutes.\n  \n  - The SQL error messages are often (perhaps usually?) nonsense, so you have to operate without them.\n  \n  - An unfortunate amount of downtime, followed by bizarre excuses.\n  \n  - It&#x27;s so darn slow, relative to equivalent queries on BigQuery or Snowflake.\n  \n  - Even submitting a query can take a weird amount of time.\n\n</code></pre>\nIf Databricks-as-an-RDBMS were competing against Teradata, sure, let&#x27;s have a chat.<p>But we&#x27;re in 2021, and there&#x27;s just no comparing the experience of the SQL analyst on Databricks-as-an-RDBMS vs. Snowflake&#x2F;BigQuery.<p>I&#x27;m excited for the potential of Snowflake&#x27;s SnowPark (though know little about it). Calling UDFs from SQL means you can create great features for SQL analysts, provided that they can build the momentum to need it.')