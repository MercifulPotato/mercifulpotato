Item(by='kirillzubovsky', descendants=None, kids=[24798536], score=None, time=1602833511, title=None, item_type='comment', url=None, parent=24798154, text='I believe they are making depth perception using computer vision.<p>The idea is that if you can take an image and predict the distances to the objects in it, you can then create an image that is a transpose of the original based on your predictions, but at a different distance. In case of Tesla moving forward, that would be a split second later, closer to the original image. As the car moves forward, you actually take that second image and compare the virtual to the original.<p>At this point you probably get it wrong, but you adjust your predictions and recalculate until your virtual transposed image looks exactly like the real image, at which point you&#x27;ve got the distances pretty darn close.<p>I remember watching a talk about their computer vision, and it was pretty impressive. The challenge is that despite knowing where the billboards are, they still look that way because sometimes, in obscure situations, in little old towns with fuzzy rules, road signs actually do appear in weird places, and that&#x27;s where the car often trips up because without sufficient data it just can&#x27;t build a prediction model to know when to respond, and when to suppress the new input.')