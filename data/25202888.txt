Item(by='stellalo', descendants=None, kids=None, score=None, time=1606251118, title=None, item_type='comment', url=None, parent=25202723, text='Recasting quantile estimation as an optimization problem is trivial: the q-quantile minimizes the “pinball” loss (see first eqn in <a href="http:&#x2F;&#x2F;statweb.stanford.edu&#x2F;~owen&#x2F;courses&#x2F;305a&#x2F;lec18.pdf" rel="nofollow">http:&#x2F;&#x2F;statweb.stanford.edu&#x2F;~owen&#x2F;courses&#x2F;305a&#x2F;lec18.pdf</a>) with parameter q. What they do in the paper is to take subgradient steps with respect to the latest observation (just think about subgradients as gradients, since the loss function is everywhere differentiable except for one point)')