Item(by='jaybrendansmith', descendants=None, kids=None, score=None, time=1606313963, title=None, item_type='comment', url=None, parent=25207834, text='Introspection.  Some humans seem to do it, others do not, at least that is my observation.  So introspection seems to be the post-processing of inputs to build a coherent conceptual model of the universe. Building inferences between unrelated things, building meta-objects based on those inferences seems to be what humans do quite well.  Questions are formed because there are disparities or disconnects that must be explained in order to form a greater holistic coherence.  Could we build introspection into GPT-3? Can that be a goal, that in addition to &#x27;training&#x27; we add the capability to pull together concepts and classify?  That alone would cause GPT-3 to start to ask questions, starting with &quot;Is 42 really a valid answer, or is it a joke?&quot;')