Item(by='AnimalMuppet', descendants=0, kids=None, score=1, time=1609185247, title='Ask HN: Bayesian Updating and Propaganda', item_type='story', url=None, parent=None, text='Let&#x27;s&#x27; suppose that you think in a Bayesian way (which I suspect most of us do, at least to some degree).  And let&#x27;s suppose that you are subject to a competent propaganda campaign, with endless repetition.<p>You&#x27;re going to wind up believing the propaganda, aren&#x27;t you?  If you adjust your priors <i>at all</i> on exposure to the propaganda, then eventually, after enough repeated exposure, you&#x27;re going to wind up with 100% confidence in it.<p>It seems to me that the only way to avoid this is that you have to detect what&#x27;s happening and break out of the normal Bayesian updating.  You have to decide that something is propaganda and deliberately, consciously not update your priors. Or you could even update them in the opposite direction:  &quot;Oh, that&#x27;s propaganda.  Even less likely to be true than it was last time I heard it.&quot;<p>And I suspect that we have learned to do that with advertising (which is just propaganda for commercial purposes), so I think it can be done.<p>Is this analysis correct (or at least reasonable)?')