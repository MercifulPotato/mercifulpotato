Item(by='confuseshrink', descendants=None, kids=[25762355], score=None, time=1610543545, title=None, item_type='comment', url=None, parent=25761157, text='Interesting point. Nvidia have been improving the int performance for quantized inference on their GPUs a lot. It might be a lot of work but could it be possible to scale up this NNUE approach to the point where it would be worthwhile to run on a GPU?<p>For single-input &quot;batches&quot; (seems like this is what&#x27;s being used now?) it might never be worthwhile but perhaps if multiple positions could be searched in parallel and the NN evaluation batched this might start to look tempting?<p>Not sure what the effect of running PVS with multiple parallel search threads is. Presumably the payoff of searching with less information means you reach the performance ceiling quite a lot quicker than MCTS-like searches as the pruning is a lot more sensitive to having up-to-date information about the principal variation.<p>Disclaimer: My understanding of PVS is very limited.')