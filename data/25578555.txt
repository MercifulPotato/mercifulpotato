Item(by='pdfernhout', descendants=None, kids=None, score=None, time=1609302636, title=None, item_type='comment', url=None, parent=25573761, text='I agree those robots are both exciting and scary. After I graduated from Princeton (doing cognitive science related to AI and robotics), I hung around the CMU Robotics labs in 1985-1986 -- mostly as a visitor to Hans Moravec&#x27;s and Red Whittaker&#x27;s labs. But I also dropped by other labs, including to learn from Ben Brown, who was an awesome mechanical engineer in Raibert&#x27;s Leg Lab. Raibert&#x27;s team had done amazing stuff with the first hopping robot and was then getting going with a first bipedal one.<p>James Crowley had recently left, so sadly I never got to meet him. I think I would have liked him and vice versa, having probably similar interests in personally-assistive household companion robots -- like Silent Running drones. When I was between two housing rentals that did not quite overlap, I slept one night on the floor of his mostly-emptied Household Robots lab next to a running PERQ computer to keep warm (from the cold air conditioning). The crazy things you do when you are twenty... :-)<p>It was kind of sad for me (for a couple of reasons) to see Raibert&#x27;s dynamic robots immobile in the MIT museum when I visited there with my kid a few years ago. But I can be glad those robots got a good home there and the recognition they deserved -- rather than, say, be discarded for scrap like the 1942 Atanasoff-Berry computer at Iowa State (since thankfully reconstructed).<p>CMU&#x27;s Robotics Institute was heavily supported by defense dollars back then -- even as at least some (or maybe even all?) robotics researchers there then thought giving robots guns was a dumb idea. There were also researchers -- especially in Hans&#x27; lab -- who thought robots would and even should surpass humanity as &quot;Mind Children&quot;. But I wondered if even that positive aspiration would really work out as well as some hoped. Since then, I&#x27;ve spent a lot of time thinking about the future of robotics and humanity, and how to get more benefits than harms from robotics. It probably would not take much more than a dumb-ish self-replicating anti-personnel robotic cockroaches to wipe out humanity. (Or even smaller self-replicating things like infectious bioweapons...) And even the smartest AIs like in James P. Hogan&#x27;s &quot;The Two Faces of Tomorrow&quot; novel might wipe out humanity first in their infancy and then perhaps only later regret it. And if robots and AIs are designed mainly by competitive people to give themselves (or their funders) competitive advantages over other people -- whether for military or business reasons -- bad outcomes seem more likely than if other motives guide their creation.<p>Even as there is no certainty even given the best intentions, as I saw from a simulation I made a couple years later on a Symbolics in ZetaLisp of self-replicating robotics -- who unintendedly turned cannibalistic during the first simulation run (eating their own children). I had only programmed them to simply assemble themselves to an ideal form from nearby parts and then divide. But after they divided, the most convenient source of spare parts was their offspring. I ultimately had to add a sense of &quot;smell&quot; and scent marking of self&#x2F;child to avoid that. That unexpected total surprise of the (simulated) robots initial behavior -- obvious now in hindsight -- has stuck in my mind every since.<p>Although, even as I called the fix &quot;smell&quot;, perhaps one might think of it as &quot;love&quot;? :-) Related: &quot;Straight Up -- by\nPaula Abdul&quot;\n<a href="https:&#x2F;&#x2F;genius.com&#x2F;Paula-abdul-straight-up-lyrics" rel="nofollow">https:&#x2F;&#x2F;genius.com&#x2F;Paula-abdul-straight-up-lyrics</a>\n&quot;I&#x27;ve been a fool before &#x2F; Wouldn&#x27;t like to get my love caught in the slammin&#x27; door &#x2F; How about some information, please? &#x2F; ... Do, do you love me? ...&quot;<p>In any case, it seems plausible that our direction heading out of any Singularity may have a lot to do with our social direction&#x2F;maturity going into one. Acting positively and pro-actively may be the best hope we have -- and that means we need to emphasize social wisdom ASAP (whether a UBI or whatever other compassionate initiatives). The result of decades of thinking since then is summarized in my email sig: &quot;The biggest challenge of the 21st century is the irony of technologies of abundance in the hands of those still thinking in terms of scarcity.&quot;<p>Or in more detail, essentially we need to move away from a model of unilateral domineering security to one of mutual intrinsic security, as I explain here:\n&quot;Recognizing irony is key to transcending militarism&quot;\n<a href="https:&#x2F;&#x2F;pdfernhout.net&#x2F;recognizing-irony-is-a-key-to-transcending-militarism.html" rel="nofollow">https:&#x2F;&#x2F;pdfernhout.net&#x2F;recognizing-irony-is-a-key-to-transce...</a>\n&quot;... There is a fundamental mismatch between 21st century reality and 20th century security thinking. Those &quot;security&quot; agencies are using those tools of abundance, cooperation, and sharing mainly from a mindset of scarcity, competition, and secrecy. Given the power of 21st century technology as an amplifier (including as weapons of mass destruction), a scarcity-based approach to using such technology ultimately is just making us all insecure. Such powerful technologies of abundance, designed, organized, and used from a mindset of scarcity could well ironically doom us all whether through military robots, nukes, plagues, propaganda, or whatever else... Or alternatively, as Bucky Fuller and others have suggested, we could use such technologies to build a world that is abundant and secure for all. ...&quot;')