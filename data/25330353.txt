Item(by='talolard', descendants=None, kids=None, score=None, time=1607329831, title=None, item_type='comment', url=None, parent=25328709, text='Hmmm, I think that&#x27;s not precise and my use of &quot;architecture&quot; was misleading.<p>If we&#x27;re thinking in terms of &quot;universal aproximators&quot;, an RNN is a way to make a sequence of approximate functions for a sequence of inputs.<p>But it&#x27;s still a sequence of functions, not a single function.<p>For a 1 layer network to have the same ability as an RNN (take an unbounded amount of context) it would need to have infinite width which is a no-go.')