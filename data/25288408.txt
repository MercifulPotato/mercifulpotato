Item(by='jononor', descendants=None, kids=[25289329, 25290064], score=None, time=1607000605, title=None, item_type='comment', url=None, parent=25287772, text='Trivial models can be rather common, in some application. For example Anomaly Detection per user or per sensor. The simplest models might basically be computing the number of standard deviations* away the new datapoint is from a typical distribution, and then having a well-chosen threshold on this. Since these models are per entity, if one has 100&#x27;000 sensors deployed, then one gets 100&#x27;000 such trivial models.\nInference might run every 1 hour or so, and consume last 48 hours of data for example. Training might run once per week on the last 4 week.<p>This is to me a good candidate for an ML workload to run directly in a database:<p>- Low compute vs storage ratio for the models.<p>- High number of models.<p>- Often only want a small subset of data as input to model (a few numbers typically).<p>- Relational data highly relevant, for contextual data around the entity.<p>- Simple models with few parameters to store.<p>- Frequent updates to models.<p>- Historical models interesting. To implement checking new models against old, running in parallel<p>Other examples with similar characteristics would be Timeseries Forecasting on many different time-series. Could be sensor data,  stock tickers or whatever.<p>* Better to use a robust analog such as Median Absolute Distance.')