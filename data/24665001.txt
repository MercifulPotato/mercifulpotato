Item(by='dragontamer', descendants=None, kids=[24665319], score=None, time=1601660472, title=None, item_type='comment', url=None, parent=24664743, text='&gt; I don&#x27;t know what the CM5 did - was it limited to always-on sets of vector instructions?<p>EDIT: Woops, I mean CM2. CM5 was MIMD and a slightly different architecture. I&#x27;ve edited this post to say CM-2 instead, but my previous post about CM5 will remain in error.<p>Individual thread masking was available on CM-2, for all 4096 cores that were executing in SIMD-parallel.<p>CM2 was a 4096 x 1-bit SIMD processor. Very limited compared to modern GPUs, but the execution model that CM2 experimented with eventually became the modern GPU architecture. Yes, you can have effective execution masks even with only 1-bit cores.<p>EDIT: See the C-Star manuals, a &quot;per-thread if statement&quot; required a &quot;where&quot; construct instead of if. But yes, the &quot;where&quot; statement performed similarly to &quot;CUDA if&quot;:  <a href="http:&#x2F;&#x2F;people.csail.mit.edu&#x2F;bradley&#x2F;cm5docs&#x2F;AReferenceDescriptionoftheCStarLanguage.pdf" rel="nofollow">http:&#x2F;&#x2F;people.csail.mit.edu&#x2F;bradley&#x2F;cm5docs&#x2F;AReferenceDescri...</a><p>The MIMD thing that CM-5 did didn&#x27;t seem to stick. CM-2&#x27;s SIMD execution seems to be a bigger influence. But C-Star ran on both... and it was the high-level languages like C-Star or Parallel-Lisp that influenced GPU languages like CUDA.<p>&gt; The where statement is involved with setting the context, a process known as\ncontextualization. The context is a parallel boolean mask (i.e., each element of it is true or false)\nthat controls the execution of parallel operations position by position. A different context is\nassociated with each shape object, and the context associated with the current shape is always\napplied to operators.<p>A CUDA-block was roughly equivalent to a CStar-Shape. A CUDA-if is roughly equivalent to a CStar-where.<p>&gt; Current GPUs also support certain amounts of fully independent thread scheduling, e.g., per-thread instruction counters, etc. Maybe that is beginning to leak out of the SIMT model.<p>NVidia was calling SIMT back in 2010, long before per-thread instruction counters were available in Pascal (GTX 10xx series of GPUs)')