Item(by='dragontamer', descendants=None, kids=[25050501, 25043567], score=None, time=1604992191, title=None, item_type='comment', url=None, parent=25043351, text='&gt; Really? I mean like pretty much every instruction has separate source and destination addresses&#x2F;registers, memory caches obviously complicate things, but it seems that processing data from one location to another is the most efficient operation.<p>I can&#x27;t think of any algorithm where copying is faster than mutating.<p>* Chess Bitboards: Make &#x2F; Unmake is a methodology for a reason.<p>* Mergesort: In-place mergesort is far faster than copy-merge sort. Its much harder to write in-place mergesort, but it really makes a big difference.<p>* Quicksort: In-place quicksort is faster than copy quicksort. Every &quot;pure functional&quot; recursive &#x2F; copy quicksort has been... subpar... in my experience.<p>* C++11 created a &quot;destructive move&quot;, the entire R-value references system, because of the hugely more efficient concept of destructive &#x2F; mutating moves. Destroying the old data while copying the data to a new location (aka: std::move) is far more efficient than making a safe copy (aka: copy-constructor).<p>-------<p>Side note: The SIMD &quot;Mergepath&quot; Mergesort is absolutely brilliant. It uses absolutely no mutexes (and only uses thread-barriers) to guarantee that all writes are independent and correct. Furthermore, &quot;Mergepath&quot; mergesort parallelizes maximally (one-element per processor), while retaining O(n * log(n)) sort speeds.<p>Because thread-barriers are no-ops on a SIMD computer (like AVX512), the thread-barriers in the MergePath concept are maximally efficient. :-)<p>-------<p>What algorithms are you thinking of where copying is faster than mutating? At best, a copy ties mutation in speed. In a huge number of applications, mutation (aka: std::move) just faster.<p>But std::move cannot be done across multiple threads: that&#x27;s innately thread-unsafe and must be synchronized (at least for typical objects).<p>---------------<p>Or maybe the above is too abstract? Lets go down to a very simple, but specific, algorithm. The Fisher-Yates (aka: Knuth) Shuffle.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fisher%E2%80%93Yates_shuffle" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fisher%E2%80%93Yates_shuffle</a><p>As far as I know, there is no copy-based algorithm that can beat the Knuth Shuffle&#x27;s O(n) computation complexity. It is extremely difficult to write a O(n) speed shuffle without mutating the array in place.<p>The fastest &quot;copy&quot; methodologies for the Shuffle problem I&#x27;ve seen involved generating a random number for each location, then copy-sorting the results: O (n * log(n)), which is asymptotically more complex than the Fisher Yates shuffle (and therefore: work-inefficient. If you parallelize to O(n*log(n)), there will be a size where the Fisher Yates shuffle is faster).')