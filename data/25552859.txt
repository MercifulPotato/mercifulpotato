Item(by='zekrioca', descendants=None, kids=None, score=None, time=1609092155, title=None, item_type='comment', url=None, parent=25551023, text='You do not necessarily need to fully know the environment you are in, but you need to be able to evaluate how good the actions that you can take are in terms of an utility function. That’s how a RL algorithm can learn that going through a wall is a bad decision (reward(“ahead”) &lt;= “$0“), and then decides for something else such as turning right or left (reward(“Left” || “right”) &gt; “$0”).<p>I think the main problem with RL is deciding if an utility function — as precise as it may be — can fully capture&#x2F;estimate all nuances of an environment. Another problem is at adapting to the environment by having new actions added dynamically into your model and having it to converge as quickly as possible.')