Item(by='dragontamer', descendants=None, kids=None, score=None, time=1605900138, title=None, item_type='comment', url=None, parent=25159704, text='With over 600 reorder buffer registers in the Apple M1 executing deeply out-of-order code, this blogpost rehashes decades old arguments without actually discussing what makes the M1 so good.<p>The Apple M1 is the widest archtecture, with the thickest dispatch I&#x27;ve seen in a while. 2nd only to the POWER9 SMT8 (which had 12-uop dispatch), the Apple M1 dispatches 8-uops per clock cycle (while x86 only aim at 4-uops &#x2F; clock tick).<p>That&#x27;s where things start. From there, those 8-instructions dispatched enter a very wide set of superscalar pipelines and strongly branch-predicted &#x2F; out-of-order execution.<p>Rehashing old arguments about &quot;not enough registers&quot; just doesn&#x27;t match reality. x86-Skylake and x86-Zen have 200+ ROB registers (reorder-buffers), which the compiler has plenty of access to. The 32 ARM registers on M1 are similarly &quot;faked&quot;, just a glorified interface to the 600+ reorder buffers on the Apple M1.<p>The Apple M1 does NOT show off those 600+ registers in actuality, because it needs to remain compatible with old ARM code. But old ARM code compiled _CORRECTLY_ can still use those registers through a mechanism called dependency cutting. Same thing on x86 code. All modern assembly does this.<p>------<p>&quot;Hyperthreading&quot; is not a CISC concept. POWER9 SMT8 can push 8 threads onto one core, there are ARM chips with 4-threads on one core. Heck, GPUs (which are probably the simplest cores on the market) have 10 to 20+ wavefronts per execution unit (!!!).<p>Pipelining is NOT a RISC concept, not anymore. All chips today are pipelined: you can execute SIMD multiply-add instructions on x86 on both Zen3 and Intel Skylake multiple times per clock tick, despite having ~5 cycles (or was it 3 cycles? I forget...) of latency. All chips have pipelining.<p>-------<p>Skylake &#x2F; Zen have larger caches than M1 actually. I wouldn&#x27;t say M1 has the cache advantage, outside of L1. Loads&#x2F;stores in Skylake &#x2F; Zen to L2 cache can be issued once-per-clock tick, though at a higher latency than L1 cache. With 256kB or 512kB of L2 cache, Skylake&#x2F;Zen actually have ample cache.<p>The cache discussion needs to be around the latency characteristics of L1. By making L1 bigger, the M1 L1 cache is almost certainly higher latency than Skylake&#x2F;Zen (especially in absolute terms, because Skylake&#x2F;Zen clock at 4GHz+). But there&#x27;s probably power-consumption benefits to running the L1 cache wider at 2.8GHz instead.')