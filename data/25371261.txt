Item(by='mattlondon', descendants=None, kids=[25371884], score=None, time=1607589136, title=None, item_type='comment', url=None, parent=25368272, text='Is this really &quot;on&quot; the RPi though?  They mention inference on ARM Mali GPU (which is cool! But I don&#x27;t think the RPis use Mali right?) but it wasn&#x27;t clear to me if this was just using the RPi to take a picture and send it to an AWS server to do the actual inference, then return the results?<p>The last time I fiddled with inference on a RPi was several years ago when it took a couple seconds even for inference of a basic ImageNet CNN reading low-res images from the RPi camera (can&#x27;t remember specifics sorry - I think it was on a RPi 2 or 3).  FPS was something like 0.5-0.2FPS which made &quot;real time&quot; usage kinda difficult. I don&#x27;t know what performance would be like now on a RPi4, but GPU accelerated inference on the Broadcom GPU would be nice.')