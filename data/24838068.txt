Item(by='thom', descendants=None, kids=[24838111], score=None, time=1603205935, title=None, item_type='comment', url=None, parent=24837954, text='I still feel like there&#x27;s no simple platform for a use case where you&#x27;re doing stream processing, but you really care about being able to update old data. Obviously you can just rerun a big batch job, and maybe work out which caches need invalidating but that&#x27;s hard work. Streaming platforms with watermarks make it hard to deal with very late events or long term updates. Something like Kafka Streams does away with watermarks and so can keep aggregate data up to date, but if your logic involves a lot of stateful, sequential logic, it&#x27;s hard to know what to rollback and replay when updates come in. If and when Materialize supports window functions, a lot of these workloads become much simpler, I think. Obviously differential dataflow on its own can address some of this, but alas, not a Rust shop.')