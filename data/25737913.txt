Item(by='mehrdadn', descendants=None, kids=None, score=None, time=1610402276, title=None, item_type='comment', url=None, parent=25737455, text='It might be common practice but it shouldn&#x27;t be. There are <i>lots</i> of reasons this is a bad idea; here&#x27;s just a sampling:<p>1. &quot;My return type is whatever I happen to return&quot; circumvents the ability of the type checker to ensure correctness.<p>2. More generally, the purpose of a specification (a function declaration in this case) is to declare what is required of a compliant implementation, and to provide a way to check the validity of that implementation. But when you make the types all become auto-deduced, you&#x27;re basically reducing the specification to a ~ <i>shoulder shrug</i> &quot;it does whatever it does&quot; ~.<p>3. Moreover, as I alluded to in the comment, it quickly becomes near-impossible to meaningfully separate the definition from the declaration, whether that&#x27;s because you want to hide it or because you want to compile it separately. Simply put, you lose modularity. It seems like a minor thing when (as in the example) the return value doesn&#x27;t depend on types inferred from other callees&#x27; return values, but as soon as that ceases to be true, you suddenly tie together the implementations of multiple functions. At that point, your functions lose much of their power to abstract away anything, since as soon as you change the return expression for one function, it has the potential to break code (up to and including causing compilation errors) in the the entire chain of callers. (!)<p>4. Templates end up getting re-instantiated far more often than they need to be (which can slow down both the compilation and the runtime efficiency). You almost certainly don&#x27;t want &#x27;0&#x27; and &#x27;(size_t)0&#x27; to result in duplicate instantiations when dealing with sizes, for instance.<p>5. Issue #4 can also result warnings&#x2F;errors&#x2F;bugs, since now you have a function that returns a different concrete type than you likely intended, which can result in everything from spurious warnings (signed&#x2F;unsigned casts, for instance) to actual bugs (later truncation of other variables whose types were inferred incorrectly as a result).<p>6. The code becomes difficult for a human to read too. You now no longer have any idea what types some variables are supposed to be. Not only does this hamper your ability to cross-check the correctness of the implementation itself (just as with the declarations, in #1) but unless your function is trivial, this quickly makes it harder to even understand what the code <i>is doing</i> in the first place, never mind what it&#x27;s supposed to do.<p>7. Proxy types become impossible to implement, since they won&#x27;t undergo the intended conversions anymore.<p>All this just to reduce keystrokes might be a common trade-off, but a poor one.\nI can come up with more reasons, but hopefully this gets the point across.')