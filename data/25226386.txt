Item(by='cookiengineer', descendants=None, kids=None, score=None, time=1606463247, title=None, item_type='comment', url=None, parent=25223437, text='When comparing my ideas for stealth [1] with this, I found that a lot of people assume that a local browsing data cache makes them vulnerable.<p>But, I think that a browsing cache makes peer clients stronger, because they do not have to make so many (potentially trackable) requests to a web server anymore.<p>Any request shared is another tracking prevented.<p>When it comes to signalling from HTML content, I think the web is kind of broken. Sure, we have RSS (it was great!) and we have opensearchdescription, and dublin core as a metadata initiative.<p>But what I think is missing is a way to extract the real content from the website. Imagine a real working and defined &quot;reader mode&quot; that&#x27;s integrated as a standard, including all the metadata like topics, keywords etc. It would save so much computation time when thinking about all the SEO fraud that&#x27;s happening these days.<p>Of course, incentives are always clicks, traffic, and tracking. Therefore nobody will implement it until forced to by Google or Facebook.<p>I decided to focus primarily on automation of extraction, because I think it is a necessary step to solve in order to reach a higher plane of knowledge automation.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;tholian-network&#x2F;stealth" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;tholian-network&#x2F;stealth</a>')