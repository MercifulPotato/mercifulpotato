Item(by='lambdadmitry', descendants=None, kids=None, score=None, time=1601999801, title=None, item_type='comment', url=None, parent=24694374, text='My main problem with Celery is their cowboy handling of distributed computing combined with poor documentation. I&#x27;m not aware of any documentation making it clear what&#x27;s their choices for not-exactly-once result, for one. Failure modes aren&#x27;t obvious either. Do we need to make sure that tasks are idempotent? Is there any chance they&#x27;ll be retried if a worker dies suddenly? What exactly happens when a worker receives SIGKILL? How all of the above works with their Fabric (task orchestration) stuff?<p>I just can&#x27;t trust a product that doesn&#x27;t even discuss those issues prominently in the documentation. Distributed computing is inherent for a background task queue, and it&#x27;s one of the hardest problems out there, so their best effort patchwork of retries and checks doesn&#x27;t cut it for me. They seem to code and document for a happy case, which is a huge red flag.')