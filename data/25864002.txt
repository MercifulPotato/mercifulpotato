Item(by='tanelpoder', descendants=None, kids=[25869404], score=None, time=1611261930, title=None, item_type='comment', url=None, parent=25863783, text='When doing pointer chasing, then it&#x27;s gonna be more of a latency problem, there can be plenty of memory bandwidth available, but we don&#x27;t know which memory line we want to go to next, before the previous line (where the pointer resides) has been loaded. So, the CPUs spend a lot of time in &quot;stalled backend&quot; mode due to the big difference in CPU cycle latency vs RAM access latency.<p>Offloading some operations closer to the RAM would be a hardware solution (like the Oracle&#x2F;Sun SPARC DAX I mentioned in a separate comment).<p>Or you could design your software to rely more on the memory throughput (scanning through columnar structures) vs memory latency (pointer chasing).<p>Btw, even with pointer-chasing, you could optimize the application to work mostly from the CPU cache (assuming that the CPUs don&#x27;t do concurrent writes into these cache lines all the time), but this would require not only different application code, but different underlying data structures too. That&#x27;s pretty much what my article series is about - fancy CPU throuhgput features like SIMD would not be very helpful, if the underlying data (and memory) structures don&#x27;t support their way of thinking.')