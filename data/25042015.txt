Item(by='Veedrac', descendants=None, kids=None, score=None, time=1604972257, title=None, item_type='comment', url=None, parent=25040475, text='&gt; You can consult wikipedia or e.g. the calls for papers from major AI conferences, AAAI and IJCAI, if in doubt.<p>As to Wikipedia, see the second paragraph. The sections where it mentions, eg., symbolic or sub-symbolic approaches are prefixed with “Researchers in the 1960s and the 1970s” or “By the 1980s”. Kind&#x27;a telling.<p>Like, my point is not about whether you can find the odd person trying to solve intelligence with grammars, or what were GOFAI conferences still harbour GOFAI research in the corners, my point is that a) these approaches don&#x27;t work as a way to actually tackle AI, the problem, b) the vast majority of the field does not take them as seriously as a method of doing so, regardless of other uses, and c) therefore it&#x27;s natural, not ‘impossible’, to gain AI expertise without having much care for those parts of the field.<p>&gt; Further, I can certainly point you to successes of symbolic AI, which you say don&#x27;t exist. For one thing, the entire fields of automated theorem proving, planning, search, game playing, knowledge representation and reasoning, etc. that you say are &quot;not AI&quot;, but are like I say still active and still state of the art in their respective tasks.<p>Yes, but there&#x27;s a reason I suffixed that comment with “(again, in an AI context)”. GOFAI is great if you ignore the last two letters of the name, and how it failed almost all its major promises.<p>These used to be considered AI because it was thought that you could build a useful reasoning agent out of a combination of these techniques, given appropriate developments. Now (almost) nobody does that; Google Map&#x27;s pathfinding is just a pathfinder, not a general reasoner.<p>&gt; Below I&#x27;ve defined the problem in the format expected by Louise<p>Right, OK, I figured it&#x27;d be something like this, when you said it was trivial, but this is just another perspective on my original criticism. You wrote the program you wanted it to generate as the background knowledge.<p>It must be so, because your examples don&#x27;t specify, even roughly approximately, the program you wanted generated. Another valid solution would be (among many)<p><pre><code>    ordered(A,B,C):-shorter(A,B),shorter(A,C).\n</code></pre>\nand the only reason it didn&#x27;t choose this is because you gave it the program you wanted it to generate (obfuscated a little, yet still, there was only one application available). It didn&#x27;t ‘learn’ anything.<p>&gt; I should point out that there exists no neural net approach that can learn the same (or a similar) program from a single positive example- not least because neural nets cannot make use of background knowledge (i.e. a library of programs from which to build other programs).<p>This is not true, but as you wanted to prune, I&#x27;ll leave it there.')