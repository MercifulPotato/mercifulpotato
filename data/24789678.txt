Item(by='derefr', descendants=None, kids=[24789849], score=None, time=1602776098, title=None, item_type='comment', url=None, parent=24786376, text='Presuming your CPU 1. is pipelined, and 2. has a clock frequency higher than the memory bus speed, wouldn’t each memory fetch be guaranteed to take more than 1 CPU cycle (let’s say X cycles) to resolve? If the static CPU-side execute-phase overhead for each load instruction is M cycles, wouldn’t the total load time just be M+XN — because the static phase of each successive pipelined op is occurring <i>while</i> the previous ops are waiting around for RAM to get back to them?<p>Sort of like serially launching N async XHRs. The “serially” part doesn’t really matter, since the time of each task is dominated by the latency of the remote getting back to you; so you may as well think of it as launching them in parallel.<p>The only practical difference I can see is that LDM results in smaller code and so increases cache-coherency.')