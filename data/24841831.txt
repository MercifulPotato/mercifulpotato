Item(by='dragontamer', descendants=None, kids=[24842032, 24842200, 24842087], score=None, time=1603224399, title=None, item_type='comment', url=None, parent=24841780, text='Fork join by and large doesn&#x27;t use mutexes.<p>If you need to synchronize, wait for the next fork&#x2F;join cycle instead of doing explicit mutexes. The &quot;join&quot; provides your synchronization point.<p>If you have a complicated set of highly-synchronous calculations, then you don&#x27;t fork at all. You simply use the &quot;Single Thread&quot; to perform all those calculations (and therefore negate the need of cross-thread synchronization).<p>Fork-join has low-utilization, but its very easy to program. In some cases, fork-join remains efficient (ex: spawn a thread per pixel on the screen), because all pixels do NOT need to synchronize with each other (or call mutexes).<p>-----<p>If a sync point within the children are needed, you usually make due with a barrier instead of a mutex.<p>&gt; What does &#x27;Single Instruction Multiple Data&#x27; have to do with threads?<p>SIMD processors, such as GPUs, emulate a thread in their SIMD units. Its called a &quot;CUDA Thread&quot;. Its not a true thread in the sense of CPU-threads, but the performance by-and-large scales as if it were real threads. (With exception of the &quot;thread-divergence problem&quot;)<p>Ultimately, the fork-join model translates trivially to SIMD. Any practitioner of CUDA, OpenCL, ROCm, or ISPC can prove that to you easily.')