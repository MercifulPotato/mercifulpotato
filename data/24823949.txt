Item(by='popinman322', descendants=None, kids=[24825661, 24824256, 24825232], score=None, time=1603091403, title=None, item_type='comment', url=None, parent=24822258, text='IIRC these nets don&#x27;t actually build a knowledge base (though I may be wrong, it&#x27;s been a while). They&#x27;re still functioning in lossy continuous space.<p>This is probably fine with a low number of symbols and relations, but once you get to the level of a neural theorem prover you need to properly handle symbol binding.<p>If I&#x27;m working with integers and integer-valued variables, how do I represent the variables? How do I represent the operations? This gets more complex once you leave a closed domain, where all the operations and variables are defined up front, and you enter an open domain like theorem proving.<p>There are definitely good applications for small-scale symbolic work; you could possibly improve efficiency of warehouse robots, for example.<p>Highly (pro&#x2F;ef)ficient neural theorem provers would be amazingly useful, though. Not to mention reasoning over medical knowledge given only the source documents (journal articles).<p>In either of the two domains above you need to extract symbols and relations directly from text. I think symbol-identification and relation-identification, for unstructured documents, can likely be done with some of the state-of-the-art models (particularly thinking of Diffbot[0] here).<p>So use something like Diffbot to identify symbols+relations, then... how do you represent them? Once you have the symbols you can use traditional reasoning tech on them, but it&#x27;s going to be extremely slow for any reasonable unit of work. Which is exactly why you&#x27;d want to piggyback off of neural work.<p>---<p>Some work has been done on neural theorem proving (NTP). See [1][2]. There are justifications for replacing the existing graph search vs. providing better search heuristics, but I&#x27;m fuzzy on the details. Either approach should be eligible for reinforcement learning.<p>[0]: <a href="https:&#x2F;&#x2F;www.diffbot.com&#x2F;products&#x2F;natural-language&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.diffbot.com&#x2F;products&#x2F;natural-language&#x2F;</a>\n[1]: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1705.11040" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1705.11040</a>\n[2]: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1606.04442" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1606.04442</a>  (This is just for premise selection; it doesn&#x27;t replace the prover machinery)\n[3]: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1701.06972" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1701.06972</a>  (More guided search)')