Item(by='thu2111', descendants=None, kids=None, score=None, time=1606322089, title=None, item_type='comment', url=None, parent=25205334, text='But GCd languages don&#x27;t need to hit atomic ops constantly in the way ref-counted Objective C does, so making them faster (though still not as fast as regular non-atomic ops) is only reducing the perf bleeding from the decision to use RC in the first place. Indeed GC is generally your best choice for anything where performance matters a lot and RAM isn&#x27;t super tight, like on servers.<p>Kotlin&#x2F;Native lets us do this comparison somewhat directly. The current and initial versions used reference counting for memory management. K&#x2F;N binaries were far, far slower than the equivalent Kotlin programs running on the JVM and the developer had to deal with the hassle of RC (e.g. manually breaking cycles). They&#x27;re now switching to GC.<p>The notion that GC is less memory efficient than RC is also a canard. In both schemes your objects have a mark word of overhead. What does happen though, is GC lets you delay the work to deallocate from memory until you really need it. A lot of people find this quite confusing. They run an app on a machine with plenty of free RAM, and observe that it uses way more memory than it &quot;should&quot; be using. So they assume the language or runtime is really inefficient, when in reality what&#x27;s happened is that the runtime either didn&#x27;t collect at all, or it collected but didn&#x27;t bother giving the RAM back to the OS on the assumption it&#x27;s going to need it again soon and hey, the OS doesn&#x27;t seem to be under memory pressure.<p>These days on the JVM you can fix that by using the latest versions. The runtime will collect and release when the app is idle.')