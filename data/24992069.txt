Item(by='bonoboTP', descendants=None, kids=None, score=None, time=1604517292, title=None, item_type='comment', url=None, parent=24991226, text='There is a lot of work going on in many directions. Believe me, whenever the general public notices some &quot;obvious&quot; shortcomings or holes or missing research, there is usually already years of effort in the making and heaps of papers exploring it. It&#x27;s just that there is a huge delay to media and popular consciousness.<p>If you just read the &quot;AI&quot; comment sections on HN it may seem everybody is just training a cat&#x2F;dog classifier in Keras on ImageNet and nothing new is going on. In reality there&#x27;s tons of work in one-shot&#x2F;few-shot learning, unsupervised, self-supervised methods, combining modalities, quantifying uncertainty, robustness to attacks, etc.<p>Yes, robotics is still not at the stage where you could get a human-like dexterous dishwashing&#x2F;T-shirt folding machine. But people are working on it as well.<p>However, not all companies need it. The &quot;comfy well-funded bro-club corner&quot; (why so much envy in the phrasing?) probably does not need physical robots, they just do data analysis, like if you need to process videos uploaded to Youtube, or you program an intelligent tool for photo or video editing software, that&#x27;s also important and has nothing to do with robotic arms.<p>I think it&#x27;s the fault of the media that &quot;AI&quot; appears as this single conceptual blur, when it&#x27;s actually tons of different applications. It <i>is</i> capable of a lot more than 1-2 decades ago. But it&#x27;s not AGI, and not everyone needs to work on human-like&#x2F;conversational AGI in a humanoid body.<p>Image analysis, machine translation, speech recognition, all these <i>work</i> today at least to some extent and just a short time ago they just <i>did not</i> work at all outside extremely carefully crafted cases in prototypes that fell apart immediately when the researcher wasn&#x27;t there to keep it from collapsing (I mean this metaphorically: the predictions were extremely bad outside the scenario and dataset it was crafted for).')