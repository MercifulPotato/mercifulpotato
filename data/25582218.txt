Item(by='valenterry', descendants=None, kids=[25582295], score=None, time=1609340463, title=None, item_type='comment', url=None, parent=25581877, text='Your understanding is correct! It is inevitable that someFunction can only be called once someFuture has completed successfully. No language or technology can change that, but it is as much of a problem as the fact that in most languages lines are executed in sequence: pretty much no one thinks that this is a problem and I think we both agree on that.<p>So then...<p>&gt; Imagine someFunction comes from a library takes three values, and can run successfully with the first two completed values while the third completes. What would you write in someFuture.map(...) to do that?<p>That is a good example actually. I believe that the user (at the callsite) should both _know_ if the library operates in an async way and&#x2F;or runs code in parallel _and_ the user should be in control of choosing his desired behaviour.<p>Hence, with a library function that just expects 3 values, this is not possible and I would say the design isn&#x27;t great.<p>Here is how I would write it in scala-ish pseudocode:<p><pre><code>    &#x2F;&#x2F; library - two separate functions instead of one\n    def calcX(a, b): X\n    def calcY(x, c): Y\n    &#x2F;&#x2F; One &quot;combined&quot; synchronous function can be created easily if desired:\n    combinedCalc = calcX.andThen(calcY)\n    \n    &#x2F;&#x2F; all given values are (lazy) futures\n    aFuture = future(...)\n    aFuture = future(...)\n    aFuture = future(...)\n    \n    &#x2F;&#x2F; callsite - async but _no parallel execution_\n    xFuture = (aFuture, bFuture).mapN(calcX) &#x2F;&#x2F; This is actually valid Scala syntax. Returns a future\n    yFuture = (xFuture, cFuture).mapN(calcY)\n\n    &#x2F;&#x2F; alternative Scala syntax\n    yFuture = for {\n      a &lt;- aFuture\n      b &lt;- bFuture\n      x &lt;- calcX(a, b)\n      c &lt;- cFuture\n    } yield calcY(x, c)\n</code></pre>\nAs you can see, I could also change the order:<p><pre><code>    yFuture = for {\n      a &lt;- aFuture\n      c &lt;- cFuture\n      b &lt;- bFuture\n      x &lt;- calcX(a, b)\n    } yield calcY(x, c)\n</code></pre>\nThis is relevant because I might want to control when things get executed - but I can b sure they run one after each other and nothing runs while something else has already failed or was already started.<p>How to run it in parallel?<p><pre><code>    xFuture = (aFuture, bFuture).parMapN(calcX)\n    yFuture = (xFuture, cFuture).parMapN(calcY)\n</code></pre>\nNow everything runs in Parallel.<p>Sorry the wall of code, but it shows that the code can look rather short even without future or async specific syntax support from the language.<p>The important part here is that it allows me to have fine-grained control over the execution of my code. There are a lot of situations where I probably don&#x27;t care and it might be nice to have a way to say &quot;Hey compiler, I don&#x27;t care, just run that code in the way you think it&#x27;s best&quot;, similar to what an SQL planner does with my queries.<p>But often I want control. For instance, in your example: what happens if the library decides to always evaluate &quot;c&quot; eagerly even though &quot;a&quot; and &quot;b&quot; often fail and the whole calculation is aborted? That would be a waste of CPU. But worse: the library might change its behaviour any time and keep the same function signature.<p>While that might be not so bad for mere calculations, what if we start to think about actions? Such as database or file or network IO - or even in-memory transactions that should be atomic. How about _streams_ of these actions, such as running an action every second and then combining this with other streams of actions? Losing control over the fain grained execution will result in terrible hard to debug and fix bugs due to concurrency.')