Item(by='mjburgess', descendants=None, kids=None, score=None, time=1603262359, title=None, item_type='comment', url=None, parent=24844027, text='My intuition is this:<p>(1) decision surfaces are always linearly separable with enough dimensions<p>(2) NNs have enough dimensions<p>(3) NNs linear boundaries are coarse<p>(4) coarse boundaries in high dimensions are likely to approximate the low-loss true boundary (ie., given 1).<p>The idea behind (4) is just the linear regression idea: by (1) noise is gaussian and a straight-line is a good approximation.  With a coarse line, we do not fit to noise, and hence prob. have a good aprox.<p>The phrase &quot;neural network&quot; disguises the obviousness of this reasoning: a NN is just high-dimensional piece-wise linear regression.<p>The only thing to be explained is why, in high dimensions, datasets end up nearly piece-wise linear.<p>That isnt so hard to explain.')