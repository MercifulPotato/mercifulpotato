Item(by='chaboud', descendants=None, kids=[25517746, 25517599, 25517417, 25517366], score=None, time=1608728353, title=None, item_type='comment', url=None, parent=25516962, text='When I was young and (more) idealistic, my department chair pulled me aside after I’d been dogmatic about something and said “everything is political... The sooner you realize that, the better off you’ll be.”<p>It took 10 years for that to really sink in, but I knew that <i>every paper has an angle</i> well before that.  There’s a position of inevitability about AI around Google, and, to an extent, I agree. Unlike tobacco, alcohol, firearms, cars, fuel, AI is applied mathematics.  It’s virtually impossible to restrict functionally, requiring macro behavioral constraints on businesses and governments that are very difficult to enforce if you want to regulate it.  Furthermore, ceding the technological lead and removing the business incentive likely has defense (read: offense) implications on the global stage.<p>Some things are going to be hard to explain. Some skin tones, hair styles, accents, pitches, timbres, writing styles, etc. may have more&#x2F;less separable entropy, and that’s going to inevitably make models seem racist&#x2F;sexist for some applications. However, we’re pretty far from those edges. Instead, our model biases have likely been driven by our datasets, drawn from our coworkers, family, and friends.  In this industry, that’s currently a recipe for over sampling in some demographics and under sampling in others.')