Item(by='dhairya', descendants=None, kids=[24769883, 24771132], score=None, time=1602619227, title=None, item_type='comment', url=None, parent=24768723, text='&gt; As a starting point for establishing clarity, do you recognize&#x2F;understand that one of the core ideas of his theme is human agency? ... Eg, the question he discusses in the talk you link to: if AI could (someday) do everything (some very broad range of things), then what is the point of human life?<p>Yes, and I disagree with that framing of humanity. It is at best fundamentally nihilist and at worst reduces human value to its ability to do work and produce value (ironic given is Marxist interpretation of data annotators). AI is a threat in Jaron&#x27;s framing because is displaces humans ability to do work and therefore devalues human life. Existence in of itself is meaningful and I believe we define meaning for ourselves. I find his framing of humanity deeply problematic.<p>&gt;If your answers are going to emphasize convenience &amp; improvements and opportunities for better consumption, then you are ignoring the fundamental premise of the question... Are you saying youâ€™d prefer he stops asking inconvenient questions?<p>I don&#x27;t see why having a pragmatic critique of his position misses his point. I have critical theory background and its been valuable for framing the world and being self-reflexive in my work as an AI researcher.<p>The problem with his framing is that there is no space for engagement in the present. He seems resigned that world will overtaken by AI (he&#x27;s literally said that both in the talk above and elsewhere). I live the present and believe (perhaps naively) I have some agency to impact the future. I rather see critical conversations converge towards helping us create a better future (specifically have discussions on how to do AI research ethically).')