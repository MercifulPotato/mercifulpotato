Item(by='formerly_proven', descendants=None, kids=[24673031, 24673833, 24675197, 24672909], score=None, time=1601740468, title=None, item_type='comment', url=None, parent=24661231, text='Why is he discarding compsci literally in the introduction? Does he really think &quot;big O&quot; is all there is, presumably because those ivory tower compsci people have no clue about computers?<p>There are some good bits of advice in the article, too, though.<p>&gt; I conducted some simple benchmarks in Go to find how much data can be processed in 200 ms. A linear search can scan 13 million elements in less than 200 ms on a three-year-old MacBook laptop, and 13 million is no small feat.<p>It&#x27;s funny how slow languages have shifted perceptions. Scanning 13 million elements to find the biggest element among 32 bit ints in 200 ms is slow. That&#x27;s 250 MB&#x2F;s, or about 50 clock cycles per element. Even the most naive and portable C three-liner is almost 100x faster (there is a difference in single-threaded performance, if you assume a very generous 50 % difference, it&#x27;d still be 50x faster).<p><pre><code>   maximum = INT_MIN;\n   for(int i = 0; i &lt; N; i++)\n       maximum = elems[i] &gt; maximum ? elems[i] : maximum;\n</code></pre>\nSo, when you are using C&#x2F;C++, &quot;small&quot; for this problem is a billion elements.<p>Computers are super-fast. Next time you wait two seconds for some application to compute something, ask yourself: <i>is this problem really eight-billion clock cycles hard?</i>')