Item(by='mlthoughts2018', descendants=None, kids=None, score=None, time=1612132008, title=None, item_type='comment', url=None, parent=25978762, text='I don’t think so. In fact there is actual theory about all this.<p>- <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Aumann%27s_agreement_theorem" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Aumann%27s_agreement_theorem</a><p>- <a href="https:&#x2F;&#x2F;www.scottaaronson.com&#x2F;papers&#x2F;agree-econ.pdf" rel="nofollow">https:&#x2F;&#x2F;www.scottaaronson.com&#x2F;papers&#x2F;agree-econ.pdf</a><p>and in particular,<p>- <a href="https:&#x2F;&#x2F;mason.gmu.edu&#x2F;~rhanson&#x2F;prior.pdf" rel="nofollow">https:&#x2F;&#x2F;mason.gmu.edu&#x2F;~rhanson&#x2F;prior.pdf</a><p>If your goal is just to manipulate someone else into doing what you want, regardless of what the facts say nor what their beliefs say about the facts or about your beliefs, then sure, that is pure manipulation and not related to strategies for effective disagreement resolution.<p>It’s also not relevant or useful to bring up the fact that humans are not rational Bayesian actors, again because we’re talking about how best to achieve unified shared understanding of the true facts and to ensure we only derive beliefs from that (anything else can only be manipulation, not decision resolution, by definition). We may fall short of the best solution due to our flaws and limitations, but that doesn’t render the best solution any less the best, not make some other seemingly more attainable solution better or more worthwhile.')