Item(by='throwaway894345', descendants=None, kids=None, score=None, time=1603971634, title=None, item_type='comment', url=None, parent=24927766, text='&gt; Whenever we need more speed, we just pull the slow bits down into compiled languages, and scale them out to many cores with solutions like MPI.<p>This only works <i>sometimes</i>--for problems that allow you to do a relatively large amount of computation in the compiled language to justify the cost of marshalling Python data structures into native data structures. For matrices of scalar values, this works well. For many other problems (consider large graphs of arbitrarily-typed Python objects, or even a dataframe on which you need to invoke a Python callback on each element). If you rewrite a big enough piece of your Python codebase in the compiled language, then it will work, but now you&#x27;re maintaining a significant C&#x2F;C++&#x2F;etc code base <i>and</i> the bindings <i>and</i> the build&#x2F;packaging system that knows how to integrate the two on all of your target platforms. Python really doesn&#x27;t have a good answer for these kinds of problems, and these are by far the more common case (though perhaps not more common in data science specifically).')