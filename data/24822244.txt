Item(by='smt1', descendants=None, kids=None, score=None, time=1603066496, title=None, item_type='comment', url=None, parent=24821141, text='What&#x27;s more deep IMHO, is say, generaling things so you don&#x27;t think so rigidly. Remember, just by naming things, it creates a bias. It&#x27;s an implicit bias but a biased behavior to be sure. It creates a cultural bias just by knowing certain &quot;groups&quot; of people who know that name and associate with a sensation cause stuff to happen. A lot of modern day cognitive scientists and neurosciencts know about this. It causes a cultural bias. If you drop the rigidity of the &quot;names necessity&quot; semantic bias (just google or whatever thsa). Then it can lead to much better innovation and software&#x2F;hardware sensing. Remember in physics, despite Yangs-Mills theory, we still haven&#x27;t been able to use deformation mechanics and some unitary renormalization group but can apparently explain a lot of physical phenomoninon, but still can&#x27;t do a full integration despite flavors of the standard model. So local gauge theories which respect various local&#x2F;global laws that can easily encode symmetries in constructive D-G symmetries&#x2F;anti-symmetries to make things commute (reunify math) across boundaries to attach to enough new constructive cohomologies in comonadic space (you get full stack frames back cause a page fault if you imagine the second dimension as breaking the riemann hypothesis, a lot of problems are isomorphic to it). This basically allows you to perform reverse mathmatics in some eigen computation problem to solve decision problems reflexively by using any old applicative language. Just turn stuff and look the self-adjoint properties of any arbitrary graph and look at the compositional structure. I learned most of this stuff by just re-reading Edwin Thompson Jaynes ideas on mathmatical physics and probability theory. He clearly talks about joins and meets (lattices are just combinatorial 2-ary lattice structures) but you can generalize on arbitary distributive lattices these days and generalize the creation of artifical neural networks. You can just point to how to apply it to any higher order language like swift that has a SIL where differentiate could be defined to define big step small step semantics and then use say a language like rust to create a series of n-ary modules to define n-ary 1 order prepositional substructures with 2-ary levels of static type checking about memory and type safety. Remember, names are arbitrary and prevent creativity, make things you are talking in the right semantic codecs (shared language), once you can understand the digital (unicode) spectrum, you can just abstract stuff. It&#x27;s easier for me to talk in differential geometry rather than &quot;trivialized linear algebra&quot; which has been trivialized by non-linear optimization. You can talk about much larger invariants of spaces that can triangulate two indeo-differential systems of equations easily back to a simple 1-transversal span folded space bit which is too regular these days. Remember all the world sheets that physicists used to scan worldsheets over? The same thing applies in theory of computation. Remember convex optimization? Same things. In linear non-linear functions it&#x27;s all trivialized. You don&#x27;t even need FPGAs or ASICs anymore once you learn about discrete C<i>-algebras where </i> can be thought about gossip in cryptographically encrypted protocols.')