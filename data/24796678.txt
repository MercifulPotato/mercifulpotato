Item(by='maxkwallace', descendants=None, kids=None, score=None, time=1602814036, title=None, item_type='comment', url=None, parent=24793886, text='This is a special case of a general class of vulnerabilities in AI models, where an adversary can cause undesired output from the model by constructing input data not represented in the training set. However, it is legit much more concerning than, e.g. the issue of image classification models mis-identifying well-constructed noise as &quot;panda&quot;.<p>This is currently a research frontier for AI so us non-experts likely won&#x27;t be able to say a ton about it.<p>I thought this was a good talk on the issue:\n<a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=SS9DMr4VkbY" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=SS9DMr4VkbY</a>')