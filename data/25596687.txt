Item(by='jfrisby', descendants=None, kids=None, score=None, time=1609445925, title=None, item_type='comment', url=None, parent=25594472, text='I think  you&#x27;re crossing the streams a bit here.<p>Twitter designed _Snow_flake.  _Sony_flake is a reimplementation that changes the allocation of bits, and the author acknowledges that the maximum ID generation throughput ceiling is lower than that of Snowflake.<p>Snowflake uses a millisecond-precision timestamp, and had a 12-bit sequence number.  So 4,096,000 IDs per node-second.  At that point, the bottleneck won&#x27;t be the format of the IDs but the performance of the code, and IPC mechanism.  Which, in this case, is non-trivial since Snowflake uses a socket-based approach to communication.  Lower-overhead, native IPC mechanisms are certainly possible via JNI but would probably take some doing to implement.  For Sonyflake, I don&#x27;t imagine the socket overhead is all that much of an issue given the low throughput it&#x27;s capable of with its bit allocations.<p>Were I to design something like this again[1], I might start with something like Sonyflake (the self-assignment of host ID w&#x2F;out needing to coordinate via Zookeeper is nice), shave a couple bits from the top of the timestamp, maybe a couple from the top of the host ID, and pack the remainder at the top, leaving a few zero bits at the bottom.  That would essentially mean the value returned was the start of a _range_, and anything needing to generate IDs in large quantities can keep its own in-process counter.  Only one API call per N IDs generated by a given thread&#x2F;process.  And, of course, unix-domain socket or other lower-overhead approach to communication for when the API calls are needed.<p>[1] - A decade prior to Snowflake&#x27;s release, I wound up taking a very similar approach at one of my first startups, albeit much more crude&#x2F;inelegant and without nice properties like k-ordering.')