Item(by='notthemessiah', descendants=None, kids=[25752011, 25752402], score=None, time=1610478813, title=None, item_type='comment', url=None, parent=25751247, text='It&#x27;s pretty telling that &quot;64 percent of people who joined an extremist group on Facebook only did so because the companyâ€™s  algorithm recommended it to them&quot; according to facebook&#x27;s own research into divisiveness.\n<a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2020&#x2F;5&#x2F;26&#x2F;21270659&#x2F;facebook-division-news-feed-algorithms" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2020&#x2F;5&#x2F;26&#x2F;21270659&#x2F;facebook-divisio...</a><p>With all the discussion about Section 230, could such opaque algorithmic curation constitute a form of editorial control, not unlike that of a publisher? Could we reform Section 230 in a way that is pro-user, so if a website wishes to be a &quot;platform&quot; they would have to make their raw feed available to the user, or if they provide algorithmic curation, it&#x27;s transparent to the user how information is prioritized? Could we clarify the distinction between platform and publisher?')