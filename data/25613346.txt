Item(by='cxr', descendants=None, kids=[25613651], score=None, time=1609600691, title=None, item_type='comment', url=None, parent=25612832, text='I&#x27;ve been doing a lot of research that applies here.  The answer comes down to a few things:<p>1. using vector graphics wherever possible and then encoding it as SVG<p>2. if bitmap graphics are absolutely required and they can be procedurally generated, then do that<p>3. if large photographic data, video, or any other kind of data is required that can&#x27;t be handled using the above steps, then separate that data set as you normally would using the file system directories, place the data set subtree into a ZIP archive, write your code so it references items by file paths relative to the ZIP, and then put your page into the root of the ZIP file, too, e.g. as index.htmlâ€”your readers and reviewers follow along by using their system&#x27;s native ZIP support to explore the contents of the ZIP file so they can locate index.html and then double click it, and index.html opens up with an &quot;open dataset&quot; button which you use to then feed in its own parent ZIP archive<p>The last part might sound complicated, but it&#x27;s not much different from asking someone to use MS Office or VS Code or an IDE to open a file&#x2F;project.  (It&#x27;s just that instead of requiring then to already have that IDE installed, you&#x27;re <i>giving them</i> the IDE they need at the same time that they&#x27;re getting the document&#x2F;dataset they&#x27;re actually interested in).<p>These approaches are robust enough that they&#x27;re very unlikely to be broken by future browser changes. It&#x27;s not that the tech is lacking right now, it&#x27;s that human habits are lagging behind and we haven&#x27;t yet established this as a cultural norm&#x2F;protocol&#x2F;expectation.')