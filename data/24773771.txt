Item(by='andrewstuart2', descendants=None, kids=[24774149], score=None, time=1602657495, title=None, item_type='comment', url=None, parent=24773659, text='Maybe I&#x27;m just not up on the startup or smaller company scene, but isn&#x27;t it still pretty important to acquire those customers before you worry about whether or not they&#x27;ll take your systems down? I&#x27;d expect that to give you plenty of time to build the monolith, figure out if it&#x27;s too brittle, too unscaleable, etc, and maybe ground-up rewrite at low cost before you solidify too much by breaking things up<p>Even so, let&#x27;s say you need to scale very very quickly right away, it&#x27;s so much easier to profile and optimize a single process. I&#x27;ve been successful in optimizing e.g. a Go library from 100 KB&#x2F;s to 700MB&#x2F;s, with about two weeks of work (`pprof` and `go bench` are amazing tools), which then handled 20k tps in an application, and could have scaled out but didn&#x27;t actually need to. I&#x27;ve also gotten millions of rows in a postgres database to be full-text searchable in under 10ms, also with maybe only a week of work. I can&#x27;t readily think of a time (and I&#x27;ve had plenty of opportunity these days) where I&#x27;ve successfully diagnosed and optimized underperforming distributed systems, despite having spent months discussing and attempting to measure performance issues and trying various &quot;yeah maybe that could work&quot; fixes.<p>Granted, It&#x27;s almost certainly always been the case of microservices for the sake of microservices, but I always come back to the lack of tooling (no compiler to tell you that you broke some contract), the siren call of polyglot microservices that makes it a lot harder to build common tooling, and the temptation to prematurely send microservices to different teams (further adding to the lack of agility), as really solid reasons to stay smaller as long as possible.')