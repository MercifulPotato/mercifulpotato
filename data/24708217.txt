Item(by='Veedrac', descendants=None, kids=[24710663], score=None, time=1602078928, title=None, item_type='comment', url=None, parent=24705308, text='I had this discussion with Timo Schick, the first author, on Reddit. My final comment is copied below, with the relevant context.<p>Note that GPT-3&#x27;s approach to *GLUE involved no training on the task, just a good choice of prompt, whereas PET and iPET also use fine-tuning. Also, because distillation takes large amounts of training data, they use ensembles in the true few-shot regime, so their parameter efficiency is significantly worse than they advertise.<p><a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;slatestarcodex&#x2F;comments&#x2F;itrcac&#x2F;small_language_models_are_also_fewshot_learners&#x2F;g5p0dl5&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;slatestarcodex&#x2F;comments&#x2F;itrcac&#x2F;smal...</a><p>---<p>Timo Schick:<p>Finally, I do not really agree with your last two paragraphs, especially &quot;One is about semi-supervised learning, that says by exploiting task-specific architectures you can do fairly well with low amounts of labelled data.&quot;: If you leave out the final distillation step (which is not required for good performance), we use the exact same architecture for all tasks. In what sense is this more task-specific than GPT-3? I would not consider &quot;exploiting task-specific architectures&quot; to be a (fundamental) part of the paper.<p>My reply:<p>So what I mean here is that masked training and bidirectional transformer models like BERT have always been designed as a way to get good scores in analysis tasks like Q&amp;A, even if they are pretrained on general text, whereas unidirectional generative transformer models are now basically only relevant for generative tasks. You can say, well, both architectures can do both tasks, so is it really task specific?, but ultimately, yes, we&#x27;ve selected ALBERT because it&#x27;s better for Q&amp;A tasks, and we&#x27;ve selected unidirectional transformers in other things because they&#x27;re better for generative tasks.<p>So I guess the problem I have is with the merits of your thesis, “Can we achieve similar few-shot performance to GPT-3 without requiring billions of parameters?” OpenAI didn&#x27;t present few-shot learning as if it were an optimal method; their headline achievement was not “here&#x27;s the best way to...” but “I bet you never expected that this could...”. And so while it&#x27;s definitely true that a BERT-derived model will outperform a GPT-derived model even at lower parameter counts on these sort of tasks, nothing new or interesting is being said by it. Everyone already knows that a bidirectional GPT-3 would be better at Q&amp;A, and so that&#x27;s what a smaller bidirectional model should be competing against. GPT-3 is only interesting in this context because it&#x27;s not the optimal model (or training routine).<p>So while it&#x27;s also true that if your aim is SOTA in few-shot learning then you should definitely use a bidirectional transformer with all the new tricks, if your goal is to understand PET in a context that includes GPT-3, doing so merely makes it harder to see what&#x27;s going on.')