Item(by='ryan29', descendants=None, kids=[25690520, 25690646, 25691345, 25690558, 25690964, 25690553, 25690806], score=None, time=1610139036, title=None, item_type='comment', url=None, parent=25688627, text='I want to point out there really are two sides to Section 230.  On one hand, it&#x27;s absolutely crucial to have it if we want most of the online communications tools we&#x27;ve become accustomed to to exist.  On the other hand I think some companies, like Facebook specifically, have massively abused the protections of Section 230 to benefit themselves at the expense of the general public.  When you&#x27;re to the point of hiring psychologists to manipulate your users into &quot;engagement&quot; regardless of the impact to mental health and public discourse, I think that&#x27;s the point where everyone needs to recognize that _something_ needs to be done in terms of regulation.<p>When regulation _does_ happen, I hope lawmakers around the world give no consideration to the impact on Facebook just as Facebook&#x27;s given no consideration to the negatives they&#x27;re creating for society.  Let them fail if necessary IMO.<p>And finally, the best middle-ground I&#x27;ve seen for Section 230 was here on Hacker News.  I don&#x27;t remember which user said it, so I&#x27;m sorry I can&#x27;t attribute it, but the idea was solid.  Things like reverse chronological data feeds that a user is specifically asking for should be protected under Section 230.  Things like recommendation and engagement algorithms should be considered publishing and platforms should be liable for that content since they&#x27;re surfacing it and putting it in peoples&#x27; faces.<p>I&#x27;ve paraphrased that, but I really hope the general idea gains traction.  I&#x27;ve been very anti-censorship my whole life, but there&#x27;s no denying that social media can have a severe, negative impact if the platforms are susceptible to propaganda and misinformation, so I think it&#x27;s time to talk about moderation.')