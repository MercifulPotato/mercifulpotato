Item(by='gen220', descendants=None, kids=[25280895], score=None, time=1606938639, title=None, item_type='comment', url=None, parent=25279029, text='That&#x27;s a great description! Does materialize describe how they implement timely dataflow?<p>At my current company, we have built some systems like this. Where a downstream table is essentially a function of a dozen upstream tables.<p>Whenever one of the upstream tables changes, it&#x27;s primary key is published to a queue, some worker translates this upstream primary key into a set of downstream primary keys,\nand publishes these downstream primary keys to a compacted queue.<p>The compacted queue is read by another worker, that &quot;recomputes&quot; each dirty key, one-at-a-time, which involves fetching the latest-and-greatest version of each upstream table.<p>This last worker is the bottleneck, but it&#x27;s optimized by per-key caching, so we only fetch the latest-and-greatest version once per update. It can also be safely and arbitrarily parallelized, since the stream they read from is partitioned on key.')