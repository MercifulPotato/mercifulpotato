Item(by='sudosysgen', descendants=None, kids=[24807110], score=None, time=1602901391, title=None, item_type='comment', url=None, parent=24804359, text='There are two issues here.<p>First of all, not all value systems are rational and optimizable. The most relevant ones to humans simply aren&#x27;t. Building a rational system to maximize these value systems is an impossible task, it&#x27;s a category error. Like trying to run regression with a non-differentiable cost function.<p>Value systems are an &quot;ought&quot;. No rational, logical system can ever change them. Resolving contradictions in your values is a categorical error, because there is no such thing as having more than one value means inherent contradiction.<p>As a result, a purely rationalist perspective is ineffective. You can only achieve a certain level of rationality.<p>Which is already exactly what people have been doing for millenia, trying to find the most logical way to follow their values, and trying to phrase their inherent, base values into a set of explicit values that represent them as well as possible. It&#x27;s not anything different from what secular philosophy has done for over 4000 years now if you construe it that way.<p>Finally, it&#x27;s never possible to know that your system is without any contradiction, because that would be equivalent to solving the halting problem. So, do you have a notion that contradiction can be estimated? Measured? How do you come to the conclusion that your belief system, with that contradiction removed, is any less contradictory than before, knowing full well that you might have introduced a more complex, as of yet unknown contradiction, or ten thousand of them?<p>And so it seems that having soft contradictions is not actually necessarily a bad thing, and that jumping to resolve them should only be done if they actually are terminal, because balancing contradictions in your cognitive process is actually very doable and a good tool. It&#x27;s not just about information either, even with perfect knowledge it&#x27;s impossible to be sure of the absence of contradiction.<p>In other words, it&#x27;s never possible to prove a the consistency of a model in that model itself. You can try to prove it using the framework of another model, but how do you know that <i>that</i> model is consistent? You can&#x27;t.<p>This is why I personally try to ground the internal consistency of my though process in the material world -  a contradiction is only problematic if resolving it can materially improve the situation or understanding I derive from it.<p>But then again, Philosophical materialism vs idealism is a whole other can of worms, so il leave it to that very small facet of it.')