Item(by='apostacy', descendants=None, kids=[24705963], score=None, time=1602052728, title=None, item_type='comment', url=None, parent=24701327, text='This list presents an incredibly pessimistic and alarmist view on these technologies, assuming only worst case abuses. And I don&#x27;t know what solutions are advocated, so it feels like it is just against these technologies in general. And it is not fair to blame these mostly helpful tools for the awful things some people may use them for.<p>For example, they consider deep fakes in general to be awful, because of the potential for abuse. Should we just throw out deep fakes? Should we perhaps restrict their usage to licensed parties?<p>They also list Tay the chat bot as being awful because some trolls temporally hijacked it and got it to repeat back some racist stuff for a few weeks before it was re-calibrated. What does the author suggest? That Microsoft should never have made Tay public until they could 100% guarantee that no trolls would ever abuse it, even for a little bit?<p>Gender inference tools are written off as discrimination, because they could be used to discriminate against people. But they could just as well be used against AGAINST discrimination, by helping detect and document systemic discrimination. I think especially tools for analyzing populations present incredible benefits to help people, more so than potentials for abuse.<p>AI that can be used to detect genetic disease can save countless lives and reduce suffering. But it is bad because potential employers could maybe abuse it??<p>And a lot of these awful policies don&#x27;t use the AI directly, they merely use the AI as a justification for what they were going to do already anyway. Indeed, you could go back 50 years and find &quot;AI&quot; being used to justify problematic policies. I&#x27;m sure that Oil executives, criminal justice lobbyists, and climate change deniers have all been able to algorithm based evidence for their agendas. Don&#x27;t blame the algorithms, blame the people.')