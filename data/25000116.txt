Item(by='_8091149529', descendants=None, kids=None, score=None, time=1604597606, title=None, item_type='comment', url=None, parent=24996499, text='I think your question is excellently phrased. The answer for anything data science-y is &quot;no.&quot; The bottleneck will be transferring the input data onto the quantum CPU.<p>For algorithms like HHL that have superclassical performance, a complex superposition encoding the data needs to be created first. This state is subsequently &quot;consumed&quot; by the algorithm. The no-cloning theorem forbids creating copies of the encoded state, and hence the encoding step needs to be repeated every time the algorithm is run.<p>For another example, consider Grover&#x27;s search that is sub-linear in calls to an oracle function. If the oracle references a linear array of data, for example, it needs to work on superpositions of array indices. In other words, the entire dataset needs to fit in &quot;quantum&quot; memory.<p>Using a quantum cpu can only be sensible for computationally difficult problems where the hard problem instances can be specified by a relatively small number of bits.')