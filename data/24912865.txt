Item(by='GrimRe', descendants=None, kids=None, score=None, time=1603838387, title=None, item_type='comment', url=None, parent=24907886, text='A neural network that is trained via self supervision based on Sony IMX424 rccb sensor data can achieve per pixel depth estimation with equivalent precision as even the most expensive automotive LIDAR.<p>Not only that, having cm level localisation is wasted resolution. What good does +&#x2F;- 10cm get you in terms of safety? If the object is 30cm or 0cm away the vehicle trajectory output from the driving policy should be the same either way. At low speeds where that type of resolution is useful (e.g. parking) ultrasonics provided far better ranging than LIDAR and not to mention much, much cheaper.<p>The only defensible position of LIDAR is that when comparing a model trained using LIDAR input and one trained uses camera sensor input is that depth estimation recall is higher at .99 precision. This means that a non-LIDAR agent will sometimes detect and object that isn&#x27;t really there or will estimate the depth to be closer when its in reality further away. This can be resolved with improved self supervision techniques and ultimately higher quality and more varied sensor data in the training set.')