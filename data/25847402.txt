Item(by='gwern', descendants=None, kids=[25849839], score=None, time=1611155994, title=None, item_type='comment', url=None, parent=25843193, text='If you don&#x27;t have TFRC access, this is out of the question as a hobbyist. It&#x27;s &gt;32 GPU-months. Sorry. However, you can still transfer learn this particular model with &lt;1 GPU-month, if you have some anime or artwork dataset you want (eg a specific character).<p>The good news is that there&#x27;s been huge progress in GAN efficiency over the past few years, and we are rapidly approaching the point where ImageNet-scale datasets can be reasonably trained with 1 GPU-month or less.<p>Worth noting in that vein are VQ-GAN <a href="https:&#x2F;&#x2F;compvis.github.io&#x2F;taming-transformers&#x2F;" rel="nofollow">https:&#x2F;&#x2F;compvis.github.io&#x2F;taming-transformers&#x2F;</a> and not-so-BigGAN <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2009.04433" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2009.04433</a> . There&#x27;s also a resurgence of VAE work which is relatively efficient: VD-VAE <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2011.10650#openai" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2011.10650#openai</a> and NVAE <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2007.03898#nvidia" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2007.03898#nvidia</a> ; DALL-E <a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;dall-e&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;dall-e&#x2F;</a> also appears to be surprisingly lightweight on the VAE side.<p>So, if you feel left out, don&#x27;t worry. In the near future, between the RTX GPUs and optimization and new VAE&#x2F;GANs, I expect things like Danbooru2020 <a href="https:&#x2F;&#x2F;www.gwern.net&#x2F;Danbooru2020" rel="nofollow">https:&#x2F;&#x2F;www.gwern.net&#x2F;Danbooru2020</a> to be totally doable on hobbyist hardware.')