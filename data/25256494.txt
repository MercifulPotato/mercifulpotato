Item(by='Retric', descendants=None, kids=[25257806], score=None, time=1606758161, title=None, item_type='comment', url=None, parent=25253859, text='&gt; Maybe it&#x27;s that I came to data science from a theory-driven science point, but I don&#x27;t really understand why you wouldn&#x27;t want to be able to interpret your model.<p>Because it limits your model to doing things you could understand, which thus makes it less powerful.  In other words it’s a useful property only so far as you get it for free.  A self driving car AI being understandable isn’t worth it killing more people in the field.')