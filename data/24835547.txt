Item(by='codethief', descendants=None, kids=None, score=None, time=1603187563, title=None, item_type='comment', url=None, parent=24833546, text='I think we need to agree on a common threat model because right now I&#x27;m getting the impression that you and I are assessing things from very different angles. If any of the 3-letter agencies decide to target John Doe specifically and expend significant resources on this task, I think we can agree that chances are they will succeed. Neither a centralized or a federated approach will protect John from that because, unless John is a security expert and very paranoid and careful in everything he does online, there will be many other attack vectors.<p>Signal&#x27;s goal, however, is to protect the masses and, thus, society as a whole, by protecting as many people&#x27;s privacy as possible. The things that are at stake here are not the data and the social graph of a handful of individuals, but the data and social graph of society as a whole. (I&#x27;m sure I don&#x27;t have to mention the implications for democracy and social order.)<p>My perspective, therefore, was that of an average user. The reason I mentioned my personal situation and the fact that I myself spend quite a bit of time on making sure my systems are safe, was to emphasize that if the situation is already overly complicated for me, it will be much worse for the average user.<p>&gt; In general, you should only have to trust a particular host with communications going to the specific contact that uses it.<p>I don&#x27;t think the word &quot;only&quot; is appropriate here. Let&#x27;s say John Doe has roughly ~1000 contacts. This means that, in the worst case, he would have to research ~1000 hosts and their privacy policies. Now the &quot;accumulation effect&quot; I mentioned previously will reduce that number quite a bit but there are still going to be dozens of different hosts. I doubt we could expect John to look into each and everyone of them before he gets in touch with his contacts. (Note that this gets even worse when people can freely switch between hosts, as suggested e.g. by other replies to my comment, as John will then have to repeatedly do the checking.) Therefore, I think it is reasonable to expect that a significant number (millions, if not billions) of users will end up residing on insecure and untrustworthy hosts and their social graph and metadata – and possibly even their data (see below) – won&#x27;t be protected at all.<p>&gt; With a centralized model, you generally have to unconditionally trust the central authority.<p>In the federated model, John has to do that, too. Sure, he can self-host but how many people are actually going to do that? Put differently, the vast majority of all acts of communication in the network is going to get routed not through self-hosted nodes but through the servers of providers whose trustworthiness is at least questionable. I hope you will agree that, for society as a whole, this <i>exacerbates</i> the trust problem you mentioned.<p>&gt; A federated system offers much more flexibility. Metadata is likely to be spread piecemeal across multiple hosts and network paths, making it much more difficult for an adversary to analyze in the general case.<p>A federated system also makes it much easier for adversaries to enter the game, as they don&#x27;t have to compromise a well-known provider like Signal that is under the close scrutiny of the public. Instead, they can just create new hosts (just like they do in the case of the Tor network). What&#x27;s worse, in this case they won&#x27;t just be able to access their user&#x27;s social graphs but very likely also the content of their messages, as the key discovery problem is usually solved by hosts distributing their users&#x27; public keys.')