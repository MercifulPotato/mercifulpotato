Item(by='smcleod', descendants=None, kids=None, score=None, time=1606426209, title=None, item_type='comment', url=None, parent=25222367, text='You can do pretty amazing things with well designed (onprem) networked storage with NVMe drives&#x2F;arrays.<p>I replaced the company I was working with at the time&#x27;s traditional &quot;enterprise&quot; HPE SANs with standard linux servers running a mix of NVMe and SATA SSDs that provided highly available, low latency and decent throughput iSCSI via network.<p>Gen 1 back in 2014&#x2F;2015 did something like 70K random 4k read&#x2F;write IOP&#x2F;s per VM (running on Xen back then) and would just keep scaling till you hit the clusters 4M~ IOP&#x2F;s limit (minus some overhead obviously).<p>Gen 2 provided between 100K and 200K random 4k to each VM to a limit of about 8M~ on the underlying units (which again were very affordable and low maintenance).<p>This provided very good storage performance (latency, throughput and fast &#x2F; minimally if at all disruptive fail-over and recovery) for our apps, some of them were written in highly blocking Python code and needed to be rewritten async to get the most out of it, but it made a _huge_ (business changing) difference and saved us an insane amount of money.<p>These days I&#x27;ve moved into consulting and all the work I do is on GCP and AWS but I do miss the hands on high performing gear like that.<p>Old stuff now but the links are <a href="https:&#x2F;&#x2F;www.dropbox.com&#x2F;s&#x2F;rdojhb399639e4k&#x2F;lightning_san.pdf?dl=0" rel="nofollow">https:&#x2F;&#x2F;www.dropbox.com&#x2F;s&#x2F;rdojhb399639e4k&#x2F;lightning_san.pdf?...</a> and <a href="https:&#x2F;&#x2F;smcleod.net&#x2F;tech&#x2F;2015&#x2F;07&#x2F;24&#x2F;scsi-benchmarking&#x2F;" rel="nofollow">https:&#x2F;&#x2F;smcleod.net&#x2F;tech&#x2F;2015&#x2F;07&#x2F;24&#x2F;scsi-benchmarking&#x2F;</a> and there&#x27;s a few other now quite dated posts on there.')