Item(by='subtypefiddler', descendants=None, kids=[25017265], score=None, time=1604770925, title=None, item_type='comment', url=None, parent=25016536, text='Whilst I agree with the general sentiment, in this particular instance it has to do with the depth of network that could be trained efficiently thanks to hardware advances. LeNet was 7 layers deep, Dan&#x27;s 9, VGG&#x27;s 13, GoogleNet&#x27;s 22, etc.<p>There is theory w.r.t to thick networks as well (e.g the link to Gaussian processes require infinite width).<p>Deep makes sense here.')