Item(by='twic', descendants=None, kids=None, score=None, time=1609542225, title=None, item_type='comment', url=None, parent=25607648, text='&gt; Do you have a multicast group for each service, and have each client tasks leave and join it when interested?<p>That&#x27;s what i was thinking, yes.<p>&gt; I&#x27;m not a multicast expert but I don&#x27;t think switches can handle that.<p>As in it&#x27;s impossible, or that&#x27;s too much load? That would be 10 000 groups, each with 100 senders and some number of hundreds of receivers, but with membership changing relatively slowly. There would be lots of packets to move, but not a lot of IGMP to snoop, i think.<p>The total number of load messages sent is fewer in this model than in the model in the article, i think, because each backend sends a single multicast message, instead of N unicast TCP messages. The total number of messages delivered will be much higher - maybe about a hundred times higher?<p>&gt; Maybe you&#x27;d have all the backend tasks on a machine report their load to a machine-level aggregator (rather than a cluster-wide one), which broadcasts it to all the other machines in the cluster, and then fans out from there to all the interested clients on that machine.<p>Service mesh style? I think the main effect is to bundle the messages into bigger packets, using a single group, since you still need to deliver the same set of messages to every machine. You actually end up delivering more messages, since there isn&#x27;t any selectivity. I honestly don&#x27;t know how this pans out!<p>&gt; They mention using power of two choices to decrease the amount of state (&quot;contentious data structures&quot;) a client has to deal with. I think mostly they mean not doing O(backend_tasks) operations on the RPC hot path or contending on a lock ever taken by operations that take O(backend_tasks), but even for less frequent load updates I&#x27;m not sure they want to be touching this state at all, or doing it in a lockless way, and ideally not maintaining it in RAM at all.<p>I was a bit confused by this, because i don&#x27;t think it&#x27;s a lot of state (one number per backend), so it doesn&#x27;t seem like it would be hard to maintain and access. Particularly relative to the cost of doing an RPC call.<p>&gt; So if you had perfect information for the load of all the servers, not just the ones in your current subset, what would you do with it anyway?<p>As i said, you keep a set of connections open, distribute requests between them using P2C or a weighted random choice, but also periodically update the set according to load statistics. This means you&#x27;re not stuck with a static set of backends.')