Item(by='bobthechef', descendants=None, kids=[25742258, 25742529, 25742152, 25742814], score=None, time=1610423955, title=None, item_type='comment', url=None, parent=25738779, text='&gt; It&#x27;s not even clear exactly how our brains work so its hard to imagine that they couldn&#x27;t be implemented with a sufficiently powerful computer<p>We don&#x27;t need to know. It suffices to expand &quot;reason&quot; to include not just inference, but properly those things which inference depends on, namely, conceptualization+abstraction and judgement. You could never infer that &quot;all triangles have angles adding to 180 degrees&quot; unless you were in possession of the signified concepts. And here is where the temptation to frame brains in terms of computers becomes plainly, let&#x27;s say, problematic. Concepts like &quot;triangularity&quot; or &quot;the color green&quot; are abstract in that they do not exist as concrete things in their own right. You can have concrete green triangular objects in the world, but not triangularity or green as such...except in a mind that is able to abstract universals from particulars. So images (including the vulgarized CS sense) won&#x27;t help you because they&#x27;re always concrete impressions (one green triangle at the expense of all other possible green triangles). Formal structures expressed in what amounts to some notation won&#x27;t help you either because they only get their meaning from an interpreting mind. Often, it seems attributions of intelligence to computers stem from a tacit failure to remove ourselves from the picture, projecting our capacities onto a hunk of cleverly arranged metal.<p>&gt; If silicon chips prove an insufficient mechanism there is no particular reason we couldn&#x27;t somehow use a biological substrate or indeed even one we haven&#x27;t thought of.<p>Computation is a formalism independent of substrate. You can implement a Turing machine using anything that can maintain the appropriate interpretive correspondence. But even then, a computer is not an objective kind of thing like a tree. Unlike a tree, a computer is only a computer because the observer has chosen to interpret it as such, or to use it as such. (The naive materialists in the room might try to expand that claim to encompass anything, but in the very act they&#x27;ve made things worse. The mind&#x27;s capacity to comprehend the world is severely crippled if not destroyed, and now you have to explain this mind that somehow can entertain the existence of wondrous things like trees and elephants that the rest of the universe is unable to evince, thus making the mind even more mysterious than it was before the reductionist took to his hatchet.) So if substrate makes a difference, then it&#x27;s the substrate that matters, not some correspondence with a computational formalism.<p>&gt; You need to start by proving that brains and all idealized computers we can build are inherently on different levels.<p>The burden of proof is on those claiming minds and computers are the same thing.')