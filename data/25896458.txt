Item(by='Animats', descendants=None, kids=[25898746, 25898788], score=None, time=1611524840, title=None, item_type='comment', url=None, parent=25895391, text='<i>&quot;I watched a few hours of early unedited footage posted by Tesla owners who received the new software. The software made a number of mistakes, including two incidents where a Tesla seemed to be on the verge of colliding with another vehicle before the driver intervened.&quot;</i><p>What, Tesla <i>still</i> can&#x27;t detect big, obvious obstacles reliably? That&#x27;s pathetic. A half-dozen cases of running into stationary obstacles at full speed should have taught them something.<p>Running into obstacles at full speed, with no braking, is quite rare for human drivers. Usually, there&#x27;s braking, but too late. Mercedes once did a study showing that over half of accidents would not have occurred if braking started about 100ms earlier.<p>Tesla&#x27;s approach means the driver has nothing to do until something goes wrong. Then they have to react in under a second. That just doesn&#x27;t work. That&#x27;s been known for decades.<p>Great video on cockpit automation: &quot;Children of the Magenta&quot; (1997).[1]  It&#x27;s an American Airlines chief pilot talking to his pilots about automation-induced accidents. The aviation industry started dealing with over-reliance on imperfect automation a long time ago.<p>[1] <a href="https:&#x2F;&#x2F;vimeo.com&#x2F;159496346" rel="nofollow">https:&#x2F;&#x2F;vimeo.com&#x2F;159496346</a>')