Item(by='adamisom', descendants=None, kids=[24769347], score=None, time=1602615543, title=None, item_type='comment', url=None, parent=24766243, text='In the past, when a construct like &#x27;intelligence&#x27; has been hard to pin down, science moves on--leaves it to &#x27;philosophy&#x27; and works with formal definitions.<p>Would you say that&#x27;s one part of your point? Just to clarify, I am <i>only</i> responding to that part of your point.<p>By way of example, behaviorists declared a strict subset of the human experience to be in the purview of scientific study--and that may even have been just fine for that era.<p>You seem to be sweeping something important under the rug <i>because</i> it&#x27;s hard to pin down, and saying that this is what science has <i>done</i> in the past--and if so, you&#x27;re right.<p>But there&#x27;s an assumption--an assumption that it is <i>safe</i> to sweep things under the rug like that. That assumption may prove false, and if it does, we&#x27;re screwed.<p>Convinced that AGI is not something to worry about? Fine--but surely you agree there&#x27;s such a thing as an information hazard? That is, information that can be deadly in the wrong hands: like how to create the next COVID, or how to make a nuclear bomb. In past eras of human history, knowledge was not as powerful. Today and ever more so in the future, whether humanity can Get Things Right will <i>matter</i>.<p>So from my perspective, it doesn&#x27;t matter that whatever &#x27;intelligence&#x27; is, is hard to pin down: it&#x27;s still <i>got</i> to be figured out, whether or not it&#x27;s difficult.')