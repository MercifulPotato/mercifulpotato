Item(by='alevskaya', descendants=None, kids=[25469655], score=None, time=1608304251, title=None, item_type='comment', url=None, parent=25466498, text='JAX and Pytorch have somewhat different scopes though... JAX is concerned about much more than the kinds of neural nets we write today.  It&#x27;s a general system for expressing and transforming numerical programs, and the devs are as genuinely excited about e.g. scientific programming, probabilistic modeling, etc. as they are about NNs.<p>A technical reason for &quot;why not pytorch&quot; is that JAX was also built in part to expose and leverage the power of the XLA compiler, which is at least for the moment a pretty uniquely powerful tool for producing efficient, highly-scalable accelerator code.<p>I should underline that this is a friendly community of peers though: there is a lot of respect for Pytorch, which in turn was certainly influenced by the original Autograd that many of the JAX devs also worked on.  JAX (and its fancier sibling Dex) beyond being useful tools are also still research projects in and of themselves seeking to advance our ideas on how to write expressive, powerful numerical code on modern architectures.')