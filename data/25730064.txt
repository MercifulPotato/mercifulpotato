Item(by='josephmosby', descendants=None, kids=[25730249, 25730142, 25731843, 25731817, 25740616], score=None, time=1610378502, title=None, item_type='comment', url=None, parent=25728198, text='(source for everything following: I recently hired entry-level data engineers)<p>The experience required differs dramatically between [semi]structured transactional data moving into data warehouses versus highly unstructured data that the data engineer has to do a lot of munging on.<p>If you&#x27;re working in an environment where the data is mostly structured, you will be primarily working in SQL. A LOT of SQL. You&#x27;ll also need to know a lot about a particular database stack and how to squeeze it. In this scenario, you&#x27;re probably going to be thinking a lot about job-scheduling workflows, query optimization, data quality. It is a very operations-heavy workflow. There are a lot of tools available to help make this process easier.<p>If you&#x27;re working in a highly unstructured data environment, you&#x27;re going to be munging a lot of this data yourself. The &quot;operations&quot; focus is still useful, but at the entry level data engineer, you&#x27;re going to be spending a lot more time thinking about writing parsers and basic jobs. If you&#x27;re focusing your practice time on writing scripts that move data in Structure A in Place X to Structure B in Place Y, you&#x27;re setting yourself up for success.<p>I agree with a few other commentators here that Hadoop&#x2F;Spark isn&#x27;t being used a lot in their production environments - but - there are a lot of useful concepts in Hadoop&#x2F;Spark that are helpful for data engineers to be familiar with. While you might not be using those tools on a day-to-day basis, chances are your hiring manager used them when she was in your position and it will give you an opportunity you know a few tools at a deeper level.')