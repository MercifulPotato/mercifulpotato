Item(by='dhairya', descendants=None, kids=[24768844, 24768723, 24768418, 24768576], score=None, time=1602613212, title=None, item_type='comment', url=None, parent=24753664, text='Jaron Lanier is a frustrating thinker. In general he&#x27;s a pessimist and highly critical of AI and technology. I was at talk of his and asked him about open source AI models and suggestions for ethical frameworks to guide AI research. He gave a rambling answer about we need to pay all the human annotators ever involved in producing a model and that AI is fundamentally anti-human. His justification was as an odd anecdote about an elementary student asking what&#x27;s the point of human life if robots will do everything in the future. Jaron doesn&#x27;t provide a meaningful way to engage with his critique and it seems the logical conclusion of his view is that we abandon technology all together.<p>I do agree with the underlying claim that modern AI research erases the human effort (everything from Mturkers to exploited labor) in producing the annotations that most AI system rely on. It&#x27;s also fair the critique the proliferation of surveillance states and authoritarian governments that build upon and fund current AI research.<p>There is isn&#x27;t good ethical guidance and frameworks to help researchers navigate doing research and in understanding the implications of their works. I&#x27;d prefer critiques of AI help guide some sort ethical framework for understanding, developing, and deploying these technologies responsibly. I don&#x27;t think we can just stick our heads in the sand and pretend the problem goes away or abandoning AI in liberal democracies somehow stops authoritarian regimes from building even worse things.')