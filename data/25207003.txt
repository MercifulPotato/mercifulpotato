Item(by='throwaway189262', descendants=None, kids=[25207594], score=None, time=1606292219, title=None, item_type='comment', url=None, parent=25195636, text=' API spam is a big problem in Google Analytics too, you might just be big enough now to have become a target. I think the answer is to build a spam filter. You could take the ones made for email and adapt them for analytics requests possibly. This seems like a real place where ML pattern recognition models would shine. Any realistic spam filter will involve sampling a fraction of traffic for deep analysis and IP banning badly behaving subnets for ~24h. And it&#x27;s definitely better to shadow ban, but smart assholes will have an account to see if their spam is getting through as well.<p>I wouldn&#x27;t worry about short-term IP caching. AWS&#x27;s upstream load balancers and your own servers are probably doing it anyways to maintain TCP state tables. Linux kernel&#x27;s &quot;conntrack&quot;. If you don&#x27;t want to cache IP&#x27;s you can you a probabilistic data structure like a bloom filter synched between instances. If has a small false positive rate but is very fast and doesn&#x27;t store whole IP. Bloom filter based IP filtering is used in every big DDOS prevention system I know of.<p>As much as you like lambda, I would ditch it. And the queues. My general advice is that any time you need to add a work queue to something, it&#x27;s not fast enough.<p>Your analytics endpoint data ingestion should be something lightning fast like Go, Rust, or an async Java back end. Analytics is a lossy process, you lose traces because of browser behavior and plugins all the time anyways so I wouldn&#x27;t prioritize 100% accuracy.<p>I would focus on power&#x2F;dollar over reliability. If I was you, my ingest boxes would be load balanced with DNS round robin and sitting at various Colocation providers. Get a fat 40 gig unlimited data pipe. Build some stupid fast Rust&#x2F;Go&#x2F;Java backend that can saturate that pipe. And do all your filtering&#x2F;spam analysis here.<p>I don&#x27;t think lambda, SQS queues, PHP are the best technologies for this kind of mass data ingestion. I don&#x27;t even think your ingestion layer should be on AWS. I would follow the lead of other companies doing mass data ingestion and build your own machines. That&#x27;s how CloudFlare, Netflix etc are able to handle so much traffic without going bankrupt.<p>I would consider yourself lucky that your first DDOS was so small. 10k requests&#x2F;sec is tiny. ~400k&#x2F;sec can be generated on a regular desktop with fiber internet connection. Right now, a single user could knock you offline by messing around with JMeter. I think it&#x27;s a wake up call that you&#x27;re in the infrastructure business whether you like it or not, and you need to massively beef up your data ingestion layer. Realistically, you should be able to handle ~50 gigabit attack with 10 million requests&#x2F;sec. I think that&#x27;s achievable with a couple boxes colocated on 40 gig lines running fast software')