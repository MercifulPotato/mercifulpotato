Item(by='cujo', descendants=None, kids=None, score=None, time=1610223998, title=None, item_type='comment', url=None, parent=25702093, text='&gt; So where would I set the bar? I would set it at the level that a company isn&#x27;t at fault if their platform has the right kind or amount of moderation that the bad event that happened was unusual or couldn&#x27;t have been expected. If someone gets hurt because Facebook didn&#x27;t police an openly Nazi group, they should be liable. If someone gets hurt because Facebook has decent moderation procedures in place but the Nazi group was sneaky and posed as a sports fan club and used coded messages, then I think Facebook would have a pretty easy defense even without Section 230.<p>I like this idea in theory.  How does this work if the platform promises no moderation?  Is that allowed?  I&#x27;m thinking of a mastodon-type setup where a setup can choose not to do any type of filtering&#x2F;moderation.')