Item(by='Veedrac', descendants=None, kids=[25031530], score=None, time=1604896464, title=None, item_type='comment', url=None, parent=25028797, text='While I know I&#x27;m just attracting downvotes, your points, in order:<p>1)<p>a: It&#x27;s really not that hard to think of ways to solve backdoor problems with a mix of technical and social approaches. For example, having shared keys burned onto silicon, making physical access mandatory, and split between both the law enforcement and the company, so that both parties must knowingly engage.<p>b: <i>Most</i> software already practically backdoored already, and it&#x27;s really not that big a deal. Microsoft can push whatever updates they want whenever they want. They already have the keys to the kingdom! Google doesn&#x27;t store everything E2E encrypted. They also already have the keys to the kingdom! Things have mostly worked out regardless.<p>2) That a measure will be imperfect is not an argument that it will be ineffectual. In fact it&#x27;s pretty obviously false; making abuse harder on mainstream platforms will make abuse less mainstream.<p>3) This is like arguing governments shouldn&#x27;t be allowed to regulate weapons, because it would be hypocritical, given they own weapons themselves, and it might normalize other countries taking away their citizens&#x27; weapons, which might prevent them fighting back. That seems like an obviously bad argument.<p>4) Yes, your platform that makes oversight impossible is not compatible with regulations requiring oversight. That&#x27;s not an accident, in either direction.<p>The idea later in the post seems not really honestly engaging with the topic, that it&#x27;s not about ‘someone who believes birthday cake is undesirable’, but about networks which are systematically and <i>in actuality</i> doing things like trafficking children for sexual abuse, and that there is a moral imperative for governments to deal with this beyond just letting people choose not to engage.')