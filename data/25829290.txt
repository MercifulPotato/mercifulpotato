Item(by='Gatsky', descendants=None, kids=[25829520], score=None, time=1611023254, title=None, item_type='comment', url=None, parent=25826835, text='This article was posted before several years ago. The whole premise is bumptious - &quot;I can copy data out of a bunch of papers [which I am in no position to screen for quality or relevance], run a canned &#x27;gold standard&#x27; analysis in R [the idea that there is one true way to generate valid data is ridiculous], and then go tell the professionals what they are doing wrong.&quot; He even brags that his meta-analysis for depression had more papers than the published one, as if this was a valid metric. The Cipriani meta-analysis he cites was publised in February 2018. His meta-analysis was done in July 2018, and had 324 more papers - what explains this difference, other than obviously sloppy methodology. A proper meta-analysis is a lot of work, researchers spend years on one meta-analysis. The whole concept is ill conceived, and the author is too caught up in themselves to even realise why.<p>Meta-analyses are a good idea, but the mere presence of a meta-analysis does not denote a useful undertaking. The literature is polluted with thousands of meta-analyses. As far as I can see this is mainly because there is software available which lets almost anyone do it, and once someone else has done a meta-analysis it is much easier to do another one because they have already found all the papers for you. The publication rate of meta-analyses far outstrips the publication rate of all papers, and shows some unusual geographic variation (Fig 2) [1].<p>[1] <a href="https:&#x2F;&#x2F;systematicreviewsjournal.biomedcentral.com&#x2F;articles&#x2F;10.1186&#x2F;s13643-018-0819-1" rel="nofollow">https:&#x2F;&#x2F;systematicreviewsjournal.biomedcentral.com&#x2F;articles&#x2F;...</a>')