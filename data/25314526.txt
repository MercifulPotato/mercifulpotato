Item(by='dakial1', descendants=None, kids=None, score=None, time=1607176029, title=None, item_type='comment', url=None, parent=25313792, text='There is an interesting ethics discussion here, because FB could, for example, tune their algorithms to avoid polarization by presenting users with extreme views content that wouldn&#x27;t validade those views, but show them a more moderate view and bring them to a more moderate, fact based, scientifically sound and politically correct view.\nBut would it be ethical? Who would be the one to choose what &quot;the correct view&quot; is? \nRight now FB is doing harm because it is being somewhat fair by showing people what &quot;they want to see&quot;, so their behaviors are telling the algorithms want they want, not a third party, even if what they want is wrong&#x2F;toxic.')