Item(by='svat', descendants=None, kids=None, score=None, time=1607373133, title=None, item_type='comment', url=None, parent=25328874, text='While the name “Rewriting LaTeX in Pure Rust” is very exciting, there are two problems:<p>• “LaTeX” is a set of macros (ab)using the macro&#x2F;text-expansion feature of an underlying TeX engine (LuaTeX, XeTeX, pdTeX, original Knuth TeX, or this one), to provide things like cross-references, section numbering, etc. When you as a typical user use “LaTeX”, you&#x27;re actually using these macros, along with a huge variety of macro “packages” written by many authors, that together add up to orders of magnitude more lines of code than the TeX engine itself (about 25000 lines originally: <a href="https:&#x2F;&#x2F;tex.stackexchange.com&#x2F;a&#x2F;505664" rel="nofollow">https:&#x2F;&#x2F;tex.stackexchange.com&#x2F;a&#x2F;505664</a>). Most of the incompatibilities and error messages a typical user encounters when using LaTeX are caused not by the TeX engine but by these packages or LaTeX, which this project doesn&#x27;t touch.<p>• This project comes about as:<p>•— tex.web, Knuth&#x27;s original source code, written in his literate-programming system WEB (a preprocessor on top of Pascal),<p>•— extended to xetex.web (XeTeX), to provide Unicode support etc,<p>•— automatically tangled to Pascal code (macros expanded and constants replaced),<p>•— automatically translated to C code,<p>•— now automatically translated to Rust code, by wrapping the C code in `unsafe` Rust blocks.<p>So it has gone through multiple rounds of machine translation. Actually, I&#x27;m impressed that this project has made many improvements in undoing and restoring some of the WEB macros, since the last time this was mentioned here. (Compare a random comparison from 1 year ago: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;627399d0150e66d211a264bc05b33beb" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;627399d0150e66d211a264bc05b33beb</a> with the same comparison today: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;71e47f2276f9c6c030efe0e3357ef3bf" rel="nofollow">https:&#x2F;&#x2F;gist.github.com&#x2F;71e47f2276f9c6c030efe0e3357ef3bf</a>) — two of the four differences I had pointed out in my comment then (<a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21177367" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21177367</a>) are gone, and the only ones to mention are:<p>• The comments from the original are gone.<p>• Something like “cur_if:=subtype(p);” becomes “ cur_if = MEM[p].b16.s0 as i16;”<p>So there&#x27;s still a long way to go. But even with all that, what would be more useful IMO are (in order of difficulty):<p>• Translate directly from WEB (xetex.web) to Rust. The original uses only a subset of Pascal so IMO it should be possible to write an automatic translator that preserves more of the original. Something along these lines has been done for translating WEB to CWEB by Martin Ruckert (see <a href="https:&#x2F;&#x2F;w3-o.cs.hm.edu&#x2F;users&#x2F;ruckert&#x2F;public_html&#x2F;web2w&#x2F;index.html" rel="nofollow">https:&#x2F;&#x2F;w3-o.cs.hm.edu&#x2F;users&#x2F;ruckert&#x2F;public_html&#x2F;web2w&#x2F;index...</a> and <a href="http:&#x2F;&#x2F;tug.org&#x2F;TUGboat&#x2F;Contents&#x2F;listauthor.html#Ruckert,Martin" rel="nofollow">http:&#x2F;&#x2F;tug.org&#x2F;TUGboat&#x2F;Contents&#x2F;listauthor.html#Ruckert,Mart...</a> and his demo from TUG 2020). Alternatively, one could give up on XeTeX and start with the LuaTeX source code (in C).<p>• Understand how the TeX program is written&#x2F;works, and write a more idiomatic translation in Rust: something along these lines is in progress as a one-person hobby project by Emily Eisenberg (one of the original developers of KaTeX): see <a href="https:&#x2F;&#x2F;github.com&#x2F;xymostech&#x2F;XymosTeX" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;xymostech&#x2F;XymosTeX</a> This one is most exciting to me, as I also have (not very useful so far) grand plans to understand TeX and to make it more understandable for everybody (<a href="https:&#x2F;&#x2F;shreevatsa.net&#x2F;tex&#x2F;program" rel="nofollow">https:&#x2F;&#x2F;shreevatsa.net&#x2F;tex&#x2F;program</a>).<p>• As most of the code a user deals with is in the macro&#x2F;LaTeX layer, modify TeX macro expansion to make it more “debuggable” (<a href="https:&#x2F;&#x2F;tex.stackexchange.com&#x2F;a&#x2F;384881" rel="nofollow">https:&#x2F;&#x2F;tex.stackexchange.com&#x2F;a&#x2F;384881</a>, <a href="https:&#x2F;&#x2F;cstheory.stackexchange.com&#x2F;a&#x2F;40282" rel="nofollow">https:&#x2F;&#x2F;cstheory.stackexchange.com&#x2F;a&#x2F;40282</a>): show full stack traces beyond what one gets with \\errorcontextlines=\\maxdimen (so file names and line numbers, by tracking the provenance of token lists), show arguments scanned (“passed in”) and expected&#x2F;found types thereof, cleanly separate the macro expansion layer from the typesetting (line-breaking &#x2F; page-breaking) layer, maybe even (JIT?) “compile” some of the lower-level or frequently-used macros — the eventual goal would be for the user to completely understand what is going on when they compile their LaTeX document, so that (1) they are less surprised by errors and know what to do, (2) they may be induced (if they&#x27;re programmers) to do less in the (unsuitable) macro layer of the TeX engine and do more at the appropriate layer: either do it in a preprocessor that runs on the .tex file, or do it at the typesetting layer via something like LuaTeX&#x27;s hooks (pre_linebreak_filter etc).<p>Anyway, this project could still end up getting there, so let&#x27;s see! Interacting with the TeX community (the TeX StackExchange, mailing lists, write an article for TUGboat, etc) might also be useful.')