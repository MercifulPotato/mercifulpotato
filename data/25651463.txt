Item(by='karmasimida', descendants=None, kids=None, score=None, time=1609882560, title=None, item_type='comment', url=None, parent=25651385, text='I think it is safe to say that learning a joint distribution of vision + language, is fully possible at this stage, demonstrating by this work.<p>But &#x27;understanding&#x27; itself needs to be further specified, in order to be tested even.<p>What strikes me most is the fidelity of those generated images, matching the SOTA from GAN literature with much more variety, without using the GAN objective.<p>It seems Transformer model might be the best neural construct we have right now, to learn any distribution, assuming more than enough data.')