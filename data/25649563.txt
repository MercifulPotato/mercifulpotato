Item(by='rossnordby', descendants=None, kids=[25649943], score=None, time=1609873727, title=None, item_type='comment', url=None, parent=25648845, text='I&#x27;m not yrimaxi, and I&#x27;m very much in the EA camp, but I suspect a lot of people bounce off the implication that there isn&#x27;t really such a thing as supererogation.<p>A lot of EA messaging tries to work around this by trying to avoid guilt trips or <i>demanding</i> that you do everything you possibly can, since asking too much is a good way to end up with nothing. See Giving What We Can and similar.<p>But a lot of the justifications for this kind of approach can very easily imply a much higher bar than anyone can meet. Taking global health as an example- millions of preventable deaths a year, and if you work yourself to the bone for years, you can only hope to <i>partially</i> mitigate it.<p>Even if the messaging says, &quot;hey, just do what you can sustainably and don&#x27;t worry about being perfect, because that&#x27;s way better than nothing,&quot; the logic behind it is based on nothing more than observations of actions and their consequences. There&#x27;s not a specific threshold where your job is <i>actually</i> done, and &#x27;failure&#x27; to meet the impossible bar generally means mass death.<p>For someone outside EA, it is very easy to go from that observation to &quot;these people are telling me I am basically a mass murderer for not helping, and even if I help, I&#x27;ll still in practice be a mass murderer because I&#x27;ll help suboptimally, gee thanks.&quot;<p>Even if very few identifying with the EA community would endorse that phrasing or the implied moral judgment, I can see how people could end up feeling that way. Not sure what to do about it.')