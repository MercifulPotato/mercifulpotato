Item(by='jrockway', descendants=None, kids=[25817952], score=None, time=1610939434, title=None, item_type='comment', url=None, parent=25816802, text='I wrote a program that ran on that type of computer once.  It was real-time log analysis.  There was a lot of data coming in, and there was a need for a globally-consistent datastore for the results. Solution?  Put it all in RAM.  If the single replica crashes, you can just read all the inputs again. \n Some extra capacity existed for that, and some other system already stored the raw logs to disk durably.  The terabyte of in-memory data just made queries tolerable enough to run every few seconds and display in alert&#x2F;chart form.<p>I didn&#x27;t keep the system in this state for very long, but for version 1.0 it was just the thing -- idea to production in a short period of time.  Eventually it did move to a more distributed system, as log volume (and usefulness) increased, and we had more time to deal with the details.  It was mostly nice to not have to reprocess data after releases -- I could do them in the middle of the day without anyone caring.<p>My biggest worry when writing this was that 40Gbps of network bandwidth wouldn&#x27;t be enough, but it was fine in the early stages.  40Gbps is a lot of data.<p>I&#x27;m not sure I&#x27;d say it&#x27;s a great sign that you need a single beefy machine to run something, but it&#x27;s a tradeoff worth considering.  I found the distributed system version easier to operate, but it did constrain what sort of features you could add.  I think we got it right, but it&#x27;s easy to code yourself into a corner when you have encoded assumptions deep into the system.  Best to avoid that until you&#x27;re sure your assumptions are right.<p>Avery wrote up some details of the system: <a href="https:&#x2F;&#x2F;apenwarr.ca&#x2F;log&#x2F;20190216" rel="nofollow">https:&#x2F;&#x2F;apenwarr.ca&#x2F;log&#x2F;20190216</a>  His idea, but I wrote most of the code ;)')