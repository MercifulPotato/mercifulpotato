Item(by='cromwellian', descendants=None, kids=[25110269], score=None, time=1605498158, title=None, item_type='comment', url=None, parent=25106768, text='Wait, you&#x27;re comparing M1&#x27;s neural engine with Ampere&#x27;s tensorcores? Apple is talking TOPS, not TFLOPS, that means M1&#x27;s 11 TOPs are for inference only, not training.  By contrast, a tensorcore on Ampere does ~20 TFLOPS FP64, 78 TFLOPS FP16&#x2F;BF16, and with GPU boost clock, up to 312 TFLOPs @ BF16.<p>If you want to talk TOPS, an A100 does up to 1.2 <i>exa-ops</i> INT8, and 2.4 exa-tops INT4.  That is, an A100 is more than 1000 times more powerful than the M1 at inferencing, while also supporting up to FP32&#x2F;FP64 weights, and a 3080 is more than 500 times more powerful than the M1 neural engine.')