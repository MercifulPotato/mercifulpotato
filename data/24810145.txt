Item(by='londons_explore', descendants=None, kids=[24810915, 24810466, 24810539], score=None, time=1602944360, title=None, item_type='comment', url=None, parent=24786778, text='Too many people focus on &quot;properly&quot; putting ML into production...<p>I&#x27;d like to propose an alternative...   Build a model (once) on your dev machine.   Copy it to S3.  Do CPU inference in some microservice.   Get the production system to query your microservice, and if it doesn&#x27;t reply in some (very short) timeout, fallback to whatever behaviour your company was using before ML came along.<p>If the results of yor ML can be saved (eg. a per-customer score), save the output values for each customer and don&#x27;t even run the ML realtime at all!<p>Don&#x27;t handle retraining the model.  Don&#x27;t bother with high reliability or failover.  Don&#x27;t page anyone if it breaks.<p>By doing this, you get rid of 80% of the effort required to deploy an ML system, yet still get 80% of the gains.   Sure, retraining the model hourly might be optimal, but for most businesses the gains simply don&#x27;t pay for the complexity and ongoing maintenance.<p>Insider knowledge says some very big companies deploy the above strategy very successfully...')