Item(by='mrfox321', descendants=None, kids=[25353973], score=None, time=1607462183, title=None, item_type='comment', url=None, parent=25351357, text='I would argue that input scaling is not fundamental to Transformers.<p>Recurrent neural network size is also independent of input sequence length.<p>The successful removal of inductive bias is really what differentiates this from previous sequence-to-sequence neural networks.')