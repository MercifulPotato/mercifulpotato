Item(by='bacon_blood', descendants=None, kids=[25467966], score=None, time=1608301964, title=None, item_type='comment', url=None, parent=25467221, text='Most machine learning is using _NVIDIA_ GPUs, which themselves have a neural engine (tensor cores) for the last two generations. An NVIDIA A100 has around 19 Teraflops but 156 &quot;tensor flops&quot; (312 if you use sparse matrices).<p>In addition to being useful for training and inference, the consumer cards use tensor cores for things like mic filtering (RTX Voice) and neural upscaling (DLSS) in games.<p>General purpose GPU hardware is way more wasteful for matrix math, like maybe &gt;10x waste on power and equally worse performance, than tensor cores.')