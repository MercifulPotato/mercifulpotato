Item(by='curiousllama', descendants=None, kids=None, score=None, time=1602040135, title=None, item_type='comment', url=None, parent=24704362, text='You&#x27;re right, of course: &quot;human beings cant take the truth and consequences.&quot; &quot;That is exactly accurate [...] That&#x27;s a fact&quot; - both true. I think the issue is less truth and more action, as in &quot;I believe it to be immoral to act upon that fact in manner X.&quot;<p>I can come up with a dozen logical statements that are equally correct and immoral to act upon in certain ways.  If an ML algorithm had come up with them, they would be no less correct and no less immoral. For example, &quot;If a woman applicant is pregnant, she will take maternity leave and be less productive year 1.  Therefore, we should not hire her.&quot; &lt;- likely correct, definitely immoral (imo).<p>COMPAS drew a number of objective conclusions and ties them to specific recommendations in its intended use:\n (1) if you&#x27;re poor, you&#x27;re more likely to recidivate.  Therefore, you should get a longer sentence.\n (2) if you live in a black community, you&#x27;re more likely to recidivate.  Therefore, you should get a longer sentence\n (3) if you&#x27;re related to a gang member (not just one yourself - even if your estranged brother joined a gang a decade ago), you&#x27;re more likely to recidivate.  Therefore, you should get a longer sentence.<p>Notice: the &quot;you should get a longer sentence&quot; bit is actually part of the tool. That was the intervention it was designed to suggest. There&#x27;s a number of critiques of that connection (mathematical, legal, moral), but it&#x27;s not mine, nor is it the &quot;AI&#x27;s&quot;; it&#x27;s Northpointe&#x27;s.  And ultimately that&#x27;s the scandal &amp; intrigue: the math is right logically, but even so, the tool&#x27;s recommendation is wrong ethically.')