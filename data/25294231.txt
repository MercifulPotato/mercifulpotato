Item(by='dpezely', descendants=None, kids=[25298966], score=None, time=1607026984, title=None, item_type='comment', url=None, parent=25290908, text='Have you considered using Common Crawl [1], and if so, what was your assessment when compared to having your own spyders?<p>Long-term, a combination of theirs and your own could be optimal.<p>There are strengths and weaknesses with using their dumps: on one hand, benefits include them having crawled and having dealt with being throttled, etc.  They offer monthly dumps for general content and daily dumps for news [2].<p>On the other hand, it&#x27;s a huge pile of data to wade through, and their index format might not be your preferred method.  The archive and index reside officially at AWS, so that may decide where to process it.  (Not sure whether other providers maintain a copy as well or not.)<p>By &quot;huge&quot;, specifically:<p>&gt; October 2020 [...] contains 2.71 billion web pages or 280 TiB of uncompressed content.<p>From our analysis a few years ago, that was to be the approach for the now-defunct Snagz.net [3] (which never fully launched because co-founders were unable to join due to extenuating circumstances).<p>[1] <a href="https:&#x2F;&#x2F;CommonCrawl.org" rel="nofollow">https:&#x2F;&#x2F;CommonCrawl.org</a><p>[2] <a href="https:&#x2F;&#x2F;commoncrawl.org&#x2F;2016&#x2F;10&#x2F;news-dataset-available&#x2F;" rel="nofollow">https:&#x2F;&#x2F;commoncrawl.org&#x2F;2016&#x2F;10&#x2F;news-dataset-available&#x2F;</a> - this one can be hard to find unless you know to look for it<p>[3] <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20180320001756&#x2F;http:&#x2F;&#x2F;snagz.net&#x2F;" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20180320001756&#x2F;http:&#x2F;&#x2F;snagz.net&#x2F;</a>')