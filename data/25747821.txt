Item(by='shripadk', descendants=None, kids=None, score=None, time=1610464038, title=None, item_type='comment', url=None, parent=25747588, text='&gt; But for example what about hate speech or holocaust denial? Neither is illegal in the US. Would Twitter be legally required to host content inciting racial hatred on their site even if they don&#x27;t want to? Would it be illegal for Twitter to show any posts made by users in the United States to users who are in the UK or Germany (if the content is ambiguous I don&#x27;t see how they could determine whether it&#x27;s illegal in the target court without requesting it&#x27;s courts to review it)?<p>Yes. If hate speech or holocaust denial is not illegal then Twitter is legally required to host such content. If you strongly feel this should not be the case then take the help of your representatives and codify it into law. Then Twitter will be forced to take it down.<p>Let me ask a counter question. There are countries where blasphemy is illegal and attracts a death sentence. In America you can get away with criticizing a religion. You can&#x27;t do that in say Pakistan or Saudi Arabia. Now, what should Twitter&#x2F;Facebook do? Should it ban such content or keep such content? If you are a US citizen and indulge in blasphemy of a religion, will your post be shown to a Pakistani or should it not be shown?<p>&gt; Would it be illegal for Twitter to show any posts made by users in the United States to users who are in the UK or Germany (if the content is ambiguous I don&#x27;t see how they could determine whether it&#x27;s illegal in the target court without requesting it&#x27;s courts to review it)?<p>Yes it would be illegal for Twitter to show posts by users in US to users in UK and Germany if content is illegal. If content is ambiguous they can always decide to keep the content up and get a court review on the content. It isn&#x27;t that hard to determine if content is illegal or not. They already have tools that flag such content. The only difference would be that they would first check if the content is actually violating any policies before removing it rather than just blanket removing it and making the user go through an appeals process. The worst part of the automated system that they have as of now removes a lot of false positive posts for hate speech while refusing to remove actual offending accounts. They are heavily reliant on algorithms that have a 40-50% success rate.<p>&gt; If the content is not explicit and open to interpretation can Twitter just declare that it&#x27;s illegal and remove it?<p>If content is not explicit and open to interpretation Twitter can decide not to do anything with it until a court order is produced to take it down. Section 230 and similar regulations give Twitter that protection from being liable. Twitter is not a judge. It can always ask you to get a court order for removal of that offending content and Twitter will happily remove it.<p>In fact this is not something alien to Big Tech. Do you know that you can request removal of content from Google SERPs indexed by other websites? Google asks for a court order for the same. If it is your content Google will happily remove it. For removing another user&#x27;s content a court order is required if the content is open to interpretation and Google cannot decide if it is illegal or not.<p>Google form to legally remove content from Google Search Index that you don&#x27;t own: <a href="https:&#x2F;&#x2F;support.google.com&#x2F;legal&#x2F;troubleshooter&#x2F;1114905#ts=9814647%2C1115655" rel="nofollow">https:&#x2F;&#x2F;support.google.com&#x2F;legal&#x2F;troubleshooter&#x2F;1114905#ts=9...</a><p>Let me ask you another question:<p>Can we have a court system which only looks at issues related to social media and fast track such cases (like in Poland where you get a verdict in 7 days time)? Every country can have one. Just like we have international laws that every country ratifies, we can have countries ratify a court system that only fast tracks cases pertaining to online abuse&#x2F;hate speech&#x2F;violations etc. The court in each country is setup according to the Constitution of that country.<p>All social media companies forward complaints to that court through an API. The court is the final arbiter. If it is a criminal case the court forwards it to a criminal court. If it is a civil case the court forwards it to a civil court. If it feels it can resolve the case on their own they&#x27;ll resolve it. Any verdict is passed back to the social media companies through an API call as well. That way all social media companies don&#x27;t have to rely on creating their own rules and regulations and setting up support teams to handle such cases and instead offload that job to this special court system. Users are happy too as they won&#x27;t be confused about conflicting rules and regulations. A user will know his own country&#x27;s laws better than rules and regulations of a tech site online. It makes matters worse if he is signed up with dozens of services (which is the norm today) and has to remember rules in all services. It is too much to ask for from a user. Every citizen of every country has sworn allegiance to his&#x2F;her own Constitution. Following the rules&#x2F;regulations laid down in that Constitution is more than sufficient. Why should citizens be expected to learn rules set by private companies that are by themselves ephemeral?')