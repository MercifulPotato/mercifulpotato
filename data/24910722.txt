Item(by='bendee983', descendants=0, kids=None, score=1, time=1603825918, title='Discussion: GPUs vs. FPGAs on ML/DL?', item_type='story', url=None, parent=None, text='Hi,<p>I&#x27;m the editor of TechTalks (and an ML practitioner). A while ago, I was pitched an idea about the failures of GPUs in machine learning systems. The key arguments are:<p>1- GPUs quickly break down under environmental factors<p>2- Have a very short life span<p>3- produce a lot of heat and require extra electricity to cool down<p>4- maintenance, repair, replacement is a nightmare<p>All of these factors make it difficult to use GPUs in use cases where AI is deployed at the edge (SDCs, surveillance cameras, smart farming, etc.)<p>Meanwhile, all of these problems are solved in FPGAs. They&#x27;re rugged, they produce less heat, require less energy, and have a longer lifespan.<p>In general the reasoning is sound, but coming from an FPGA vendor, I took it with a grain of salt. Does anyone have experience in using FPGA in production use cases of ML&#x2F;DL? How does it compare to GPUs in the above areas?<p>Thanks')