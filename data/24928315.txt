Item(by='red2awn', descendants=0, kids=[24928450], score=1, time=1603959607, title='Ask HN: Why not extended grapheme cluster as character type?', item_type='story', url=None, parent=None, text='Among the most popular programming languages with native support for unicode (Go, Java, Rust, .NET, etc), why do most of them define a character as an unicode codepoint&#x2F;scalar value instead of an extended grapheme cluster? Swift is the only exception I know of.<p>My assumption is that most programs would want to deal with user perceived characters instead of individual codepoints. Is this decision for performance reasons or something else?')