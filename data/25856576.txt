Item(by='gremlinsinc', descendants=None, kids=None, score=None, time=1611215921, title=None, item_type='comment', url=None, parent=25854468, text='Very interesting points, lead me to your twitter account. I&#x27;ve been thinking a LOT about the intersections of thought police, censorship, big tech, the polarization of America, and more.<p>I saw your tweet here: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;metaviv&#x2F;status&#x2F;1349073861476823040?s=20" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;metaviv&#x2F;status&#x2F;1349073861476823040?s=20</a><p>It got me to thinking. Cumulatively, reddit seems pretty high up on a lot of the scores. So, say you were to create a new hypothetical social network and use reddit as a base.<p>Some of the lower points it gets is for safety, encouraging humanization of others, strengthening local ties, show reliable information...<p>I&#x27;d say being able to network with people you know, while remaining anonymous in certain &quot;contexts&quot;, like for example sharing a story in &#x2F;r&#x2F;askredditafterdark it may not be a real shit post, or anything bad but it could be embarrassing.<p>Having one verified account, with aliases&#x2F;contexts you can switch to for different purposes would be a way to have better safety.<p>Encouraging humanization of others. What if instead of moderation teams, there was some reward mechanism like steem or hive, and everyone who wanted to be rewarded could randomly be on &quot;jury duty&quot;. Every post would be randomly juried by members of a sub, and it&#x27;d simply ask the questions:<p>* If this is news, does it seem factual? \n* Does this represent hate speech? \n* Does this belong in this sub?<p>That last one, might be something everyone can answer and an algorithm would choose what to allow or prune.<p>Alternatively, there could be opportunities for people to flag content. Which would all get put in a weekly mega-thread, where there&#x27;s no commenting just voting on flagged content, whether to redeem it, or Perma-ban the post from the sub. If someone else reposts, it&#x27;ll automatically just be banned.<p>On your account profile you can choose to put your location. This allows you to filter and see only content people within certain radii of your location, or your specific city or state or province. Essentially, you can jump into a &quot;nearby users&quot; context.<p>Subs also would have marketplaces built in, and that and ads would be the way it&#x27;s monetized. However, no tracking cookies just topical&#x2F;sub-Reddit ads. These could feature local or shipped goods&#x2F;items or event tickets.<p>Another thought is what if you created something like Wikipedia meets archive.org. Essentially every news&#x2F;blog post gets archived per revision. Then there&#x27;d be an API to essentially &quot;characterize&quot; links. Give them context and a single source of truth that other social networks, federated instances, etc. Could use, whether something is &quot;fake news&quot;, etc.<p>The biggest issue I see with that is how you convince people from either side of the political spectrum to &quot;believe&quot; the fact-checking of said sites. The best would probably be allow pros&#x2F;cons for each link with descriptions, then the user can follow a footnote and see why 60% say it&#x27;s true, and 40% say it&#x27;s fake. Say Pat Robertson says it&#x27;s &quot;fake news&quot; and &quot;Paul Graham&quot; and some Nobel prize winning scientist says it&#x27;s true.<p>Could have professional scores as well to a link like 65% of athletes say true, 85% of scientists, 75% of actors, 33% of theologians, 55% of politicians, 65% of news anchors, 75% with a college degree, etc... Could use AI too, maybe to give it a base score like: Article appears to lean 55&#x2F;45 left:right.<p>All that data for these &quot;painted links&quot; could be used when new submissions come in to determine things like does it fit the category, etc... The problem with misinformation I think is not enough context. Having more and more context on the information that&#x27;s out there can help combat the misinformation.')