Item(by='Someone', descendants=None, kids=[25648187], score=None, time=1609867211, title=None, item_type='comment', url=None, parent=25641234, text='<i>“You have a few options for getting a great picture of how your system performs:<p>• Good old analysis.”</i><p>I’ve been trying to do that (because it seemed the only realistic method for figuring out how to cost optimize a cloud setup (should we have more smaller API servers or a few big ones? One or two databases? (When) should we scale down instances in less busy times? ...), but didn’t get far.<p>Being mathematically schooled, I went for queueing theory. That isn’t simple, but not the main stumbling block. The complexity of cloud infrastructure is. Figuring out how many simultaneous requests AWS load balancers&#x2F;Kubernetes can handle, what delays they introduce, how they route calls (round-robin&#x2F;random&#x2F;...) how large their queues are, how Kubernetes scales down&#x2F;up instances is quite a challenge.<p>So, has anybody collected ballpark numbers for these kinds of things, or hints on what can be ignored in the setup? How do people handle cost optimization of cloud instances?<p>Or do people just bring up variations on the infrastructure, benchmark them, and, when getting bored&#x2F;running out of time&#x2F;having found something that isn’t too expensive, stick to the best configuration found?')