Item(by='austincheney', descendants=None, kids=None, score=None, time=1605932472, title=None, item_type='comment', url=None, parent=25165752, text='&gt; A lot of tech discussion these days is focused around scaling web app infrastructures to handle huge traffic.<p>It most cases this the wrong way of thinking.  It isn&#x27;t that its bad or wrong, but rather that it&#x27;s dated and expensive.  This is the 2000 era .bomb logic of <i>get big fast</i> and <i>data is king</i>. It&#x27;s like thinking in terms of Facebook instead of BitTorrent.  At this point if you are not already established or working on something extremely original you have probably missed your shot and crowded out from the incumbents.<p>Current programming paradigms indicate two paths forward of which one is substantially less expensive than the other: distribution and concurrency.<p>In the distribution model most of your costs are up front in the application.  This is a service oriented approach but without a central service, rather a pool of nodes that intelligently communicate task, file, and event queues.  The cost to scale is divested from the cost of application, which is the biggest difference between this approach and thinking in terms of <i>huge traffic</i> or <i>server&#x2F;data hoarding</i>.  Since the application is divested from cost to scale all that is required to compete with the large incumbents, at scale, is market penetration.  Marketing is cheaper than a data center.<p>The concurrency model requires a central service but does not operate as a central server.  Each connection&#x2F;session is a parallel child processing unit, such as an event loop.  This approach requires less costs up front since there is still a central connection point to manage, but there is still a cost to scale even though much of that cost is offloaded from data management to increased processing overhead.')