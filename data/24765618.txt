Item(by='stereolambda', descendants=None, kids=None, score=None, time=1602597762, title=None, item_type='comment', url=None, parent=24753664, text='The hostility here to this article is interesting. To me, a reasonable interpretation is that it criticizes the way we understand&#x2F;conceptualize some areas of modern technology. Indeed, if for some legal or practical reason research labs wouldn&#x27;t have access to the data generated by the public (i.e. humans), many breakthroughs wouldn&#x27;t happen. This is the other side to emphasizing the progress in algorithms (which is of course hard to deny).<p>You can&#x27;t fully extricate technology from the societies where it exists, and things like naming, branding, institutions, and of course ideologies. There is a tendency to treat some areas of technology like some kinds of ancient gods or idols that have their own &quot;needs&quot; and &quot;mandates&quot; to force on their environment no matter what.<p>I happen to like[1] some their political proposals, like forcing the barter &quot;data for services&quot; to some fully disclosed monetary form. Also, coming up with some method of using these technologies that is compatible with individual freedom is a big concern. Even from purely practical standpoint, people trying and doing what they want has obvious value compared to everything having to be accepted by some (always to some extent self-interested and narrow-minded) authority. Shifting the language to talking about how we can enable and shape &quot;AIs&quot; as humans and societies seems reasonable: emphasizes that we have natural agency in all this.<p>[1] Liking doesn&#x27;t necessarily mean supporting yet.')