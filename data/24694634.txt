Item(by='namelosw', descendants=None, kids=None, score=None, time=1601957787, title=None, item_type='comment', url=None, parent=24689230, text='I was a self-taught programmer and when I first learned to program, I found the concept of &#x27;reference&#x27; is very counter-intuitive to me. I assume people have no CS background may find the same - why is this 5 and another 5 is the same, but not people with the same name and social security numbers?<p>Traditionally people use mutable struct or objects for non-primitive data structures, which implicitly allocate addresses in computer memories - that is a very implementation-wised approach, more specifically, a very Von Neumann approach.<p>For example, there are many systems having entities in the databases, like Person { id, name }. But if there&#x27;s no database, in many programming languages people would write Person { name } only. If people write the in-memory version first, they have to re-write their models. Systems with mutable references inconsistently force the referencing system on people by default, instead of just giving people only they ask for.<p>In modern days, a lot of computing goes beyond a single computer, there are many distributed systems, a lot of serialization is going on, and the reference in one computer&#x27;s memory doesn&#x27;t mean anything to another.<p>If we try to loosen the definition of the computer, we can think of many systems as bizarre computers. If we take a look at data processing systems like Spark or Flink, conceptually they also look like computers - bunches of hardware and &#x27;operating systems&#x27; sit on top of them, but in the form of clusters instead of single computers. In such cases, there are no shared memories, and the memories are implementation details - users won&#x27;t aware of them like they have to realize there are underlying memory systems in Von Neumann computers. In such kind of systems, people only care about computing which is more substitution based instead of mutable references. While at most, they only need to aware of nodes as a whole in the cluster.<p>It&#x27;s close to the &#x27;substitution model&#x27; vs the &#x27;environment model&#x27;, or the &#x27;functional&#x27; vs the &#x27;object-oriented&#x27; described in the SICP. Where I found conceptually the &#x27;substitution model&#x27; is more fundamental, and simpler - it&#x27;s basically elementary or middle school maths.<p>&gt; The problem here is that data isn&#x27;t actually immutable (generally) and mutability isn&#x27;t actually the problem. The problem is unmanaged references or other dependencies on the mutable data.<p>So another novel way to look at it, is if you don&#x27;t have mutable references, you don&#x27;t have to manage it, then the problem is eliminated as a whole. Like Haskell, Erlang, or Spark as we just mentioned. At the end of the day, you can have references in outer worlds, be it ST monads, processes, database, or just our real world, sometimes the processing part of the program don&#x27;t have to care about them.')