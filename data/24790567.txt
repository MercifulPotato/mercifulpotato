Item(by='andersource', descendants=None, kids=None, score=None, time=1602779902, title=None, item_type='comment', url=None, parent=24790427, text='Model explainability is a very active area of research. For the example of an individual neural network prediction you could use SHAP values[0].<p>Explainability is far from a solved problem but there are certainly tools available to provide at least some transparency. I guess the website could provide references but that doesn&#x27;t really seem to be the resolution being aimed for.<p>[0] <a href="https:&#x2F;&#x2F;www.kaggle.com&#x2F;dansbecker&#x2F;shap-values" rel="nofollow">https:&#x2F;&#x2F;www.kaggle.com&#x2F;dansbecker&#x2F;shap-values</a>.')