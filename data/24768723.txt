Item(by='ssivark', descendants=None, kids=[24769677], score=None, time=1602614745, title=None, item_type='comment', url=None, parent=24768325, text='&gt; <i>Jaron doesn&#x27;t provide a meaningful way to engage with his critique and it seems the logical conclusion of his view is that we abandon technology all together.</i><p>While it may appear that way, I wonder whether he might be speaking past many people involved in applying ML on human data.<p>As a starting point for establishing clarity, do you recognize&#x2F;understand that one of the core ideas of his theme is <i>human agency</i>? And what he means by “humanity” (our sense of purpose&#x2F;meaning tied closely with competence &amp; judgement) and why he fears it might be overwhelmed by AI? Since human nature is “reflexive”, being infantilized or treated with certain biases by algorithms will push humans to become like that. The technical way to phrase this is that statistical modeling assumes static distributions, but the actual distribution of human behavior responds&#x2F;adapts to these assumed models (“distribution shifts”). Pause and think about that for a moment.<p>Eg, the question he discusses in the talk you link to: if AI could (someday) do everything (some very broad range of things), then what is the point of human life?<p>If your answers are going to emphasize convenience &amp; improvements and opportunities for better consumption, then you are ignoring the fundamental premise of the question. He’s pointing out a perspective that is deeply at odds with the assumptions which drive today’s computing&#x2F;ML related industry. Are you saying you’d prefer he stops asking inconvenient questions?')