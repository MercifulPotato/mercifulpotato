Item(by='SpaceManNabs', descendants=None, kids=None, score=None, time=1606081171, title=None, item_type='comment', url=None, parent=25180778, text='This paper extends a lot of the ideas in &quot;A Unified Approach to Interpreting Model Predictions&quot; (reference 19). The term unified is also used in the OP paper.<p>That reference paper is unifying in the sense that it could tie together a lot of frameworks such as LIME, QII, and others.<p>The paper in OP is unifying in the sense of the explanation games&#x2F;game formulations (while also referencing QII).<p>The perspective of using contrastive explanations is very intuitive and becoming more common in different aspects of ML. My only wish is that I could try this FAE stuff myself. The authors of SHAP have a pretty immediately accessible python library. Could not find the one for this novel framework. It is not that I doubt the results. My point is a lot of good ideas like the ones presented in the paper often don&#x27;t take off unless the authors also give easily pip-able libraries.<p>edit: I found the code[1], but it is not an easily conda-able library.<p>[1]: <a href="https:&#x2F;&#x2F;github.com&#x2F;fiddler-labs&#x2F;the-explanation-game-supplemental" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;fiddler-labs&#x2F;the-explanation-game-supplem...</a>')