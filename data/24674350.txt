Item(by='geofft', descendants=None, kids=[24677326], score=None, time=1601755719, title=None, item_type='comment', url=None, parent=24674161, text='The principle of least privilege&#x2F;authority has been around for a while, and the reason we don&#x27;t see much adoption of it in real-world systems is not because it&#x27;s unknown.<p>The first question is overhead: it&#x27;s true that the majority of libraries are purely computational, but that means that there&#x27;s frequent interaction between code written by the end developer and code from the library. If every call to, say, lodash&#x27;s _.filter goes through a process to marshal the programmer&#x27;s list, send it to a separate execution environment, and then marshal it right back in the other direction to call the predicate, people would choose not to use it. I do agree that the proposal in the post you link to seems to be on the right track - directly run the code in the current execution environment if it can be statically demonstrated that the code has no access to dangerous capabilities.<p>The second question is making the policy decision about whether to grant privileges. You might be familiar with this from your mobile phone: the security architecture is miles better than that of your desktop OS, but still, most people do say &quot;yes&quot; when asked to let Facebook, Twitter, Slack, etc. access their photos and their camera and their microphone, because they intentionally want those apps to have <i>some</i> access. What do you do in the above model when, say, the &quot;request&quot; library wants access to the network? Now it can exfiltrate all of your data. (The capability-based model is that you pass into the library a capability to access the specific host it should talk to, instead of giving it direct access, but again, if it did this, people would choose not to use it - the whole point of these libraries is to make writing code more convenient.)<p>The other problem, and perhaps the most important, is that <i>purely-computational libraries can still be dangerous</i>. Yes, _.filter (and perhaps all of lodash) is purely computational, but if you&#x27;re using it to, say, restrict which user records are visible on a website, and someone malicious takes over lodash, they can edit the filter function to say, &quot;if the username is me, don&#x27;t filter anything at all.&quot; Or if you had a capability-based HTTP client that only talked to a single server, the library could still lie about the results that it got from the server.<p>I think the way to think about it is that the principle of least privilege is a mitigation strategy, like ASLR or filtering out things that look like SQL statements from web requests. ASLR mitigates not being able to guarantee that your code is memory-safe; if you could, you wouldn&#x27;t need it. SQL filtering mitigates making mistakes with string interpolation (but it comes with a significant cost, so you really want to avoid it if you can). Least privilege mitigates the reality that you cannot code-review all of your code and its dependencies to ensure that it&#x27;s free of bugs. But, on the other hand, <i>a mitigation is not a license to stop doing the thing you can&#x27;t do perfectly</i> - it&#x27;s just a safety measure. You can still have serious security bugs from buffer overflows even with ASLR; you just have fewer. You should not use ASLR as an excuse to write memory-unsafe code. You can still have SQL injection attacks from people being clever about smuggling strings. You should not use a WAF as an excuse to not use parametrization in SQL queries. And you can still have malicious dependencies cause problems even in a least-privilege situation, because they still have <i>some</i> privilege. You should not use it as a reason to run dependencies you don&#x27;t trust.')