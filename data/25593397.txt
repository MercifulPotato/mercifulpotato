Item(by='gizmo686', descendants=None, kids=None, score=None, time=1609427877, title=None, item_type='comment', url=None, parent=25592839, text='AlphaFold got attention by participating in the standard competition for protein folding, and scoring a decisive victory over the competition[0], who were all domain experts in protein folding. It is true that AlphaFold hasn&#x27;t really made progress towards &quot;solving&quot; protein folding; but that is because AI (at least as it is currently conceived) doesn&#x27;t actually &quot;solve&quot; problems; it makes predictions about about the solution to particular instances of problems.<p>Even suggesting that AlphaFold should be judged by its ability to &quot;solve protein folding&quot; in the sense of solving an NP-hard problems shows a fundamental misunderstanding of the types of problems that it set out to solve. Granted; even by the standards of the problem that AlphaFold did set out to solve, there is still room for improvement.<p>From the article the author cites to &quot;diffuse the hype&quot;:<p>&gt; Firstly, there is no doubt that DeepMind have made a big step forward. Of all the teams competing against one another they are so far ahead of the pack that the other computational modellers may be thinking about giving up. But we are not yet at the point where we can say that protein folding is ‘solved’. For one thing, only two-thirds of DeepMind’s solutions were comparable to the experimentally determined structure of the protein. This is impressive but you have to bear in mind that they didn’t know exactly which two-thirds of their predictions were closest to correct until the comparison with experimental solutions was made.<p>I would hardly becoming the state-of-the-art in a problem a &quot;dumpster fire&quot;. Granted, DeepMind got there (at least in part) by throwing tons of money at the problem. Perhaps other methods would have done even better if given the same resources.<p>Speaking of which, lets look at the other methods. I can&#x27;t links to actual papers on the CASP site, but by looking at the predictors [1], I believe I was able to find some of the papers by searching.<p>Second place was the BAKER group by Ivan Anishchenko, Minkyung Baek, and Hahnbeom Park.<p>&gt; With the recent developments in deep-learning, single-model quality assessment methods have been also advanced, primarily through the use of 2D and 3D convolutional deep neural networks. Here we explore an alternative approach and train a graph convolutional network with nodes representing protein atoms and edges connecting spatially adjacent atom pairs on the dataset Rosetta-300k which contains a set of 300k conformations from 2,897 proteins [2]<p>This group also got the 3rd place submission as well.<p>4th place goes to Michael Feig, and Lim Heo<p>&gt; Here we show that combining machine-learning based models from AlphaFold with state-of-the-art physics-based refinement via molecular dynamics simulations further improves predictions to outperform any other prediction method tested during the latest round of CASP [3]<p>At least they incorporate some actual knowledge about physics, but their approach still involves a significant amount of AI.<p>The field of protein folding is dominated by AI even without AlphaFold. What AlphaFold showed is that a well funded team of AI experts can outperform protein folding domain experts. This isn&#x27;t that groundbreaking of a claim (although certainly speaks well to the generality of current AI methods), but if you want to critize AI methods in general, you should be comparing AlphaFold to the state of the art in non AI methods to protein folding; and I don&#x27;t even know where to look to find what those methods are.<p>[0] <a href="https:&#x2F;&#x2F;predictioncenter.org&#x2F;casp14&#x2F;zscores_final.cgi" rel="nofollow">https:&#x2F;&#x2F;predictioncenter.org&#x2F;casp14&#x2F;zscores_final.cgi</a><p>[1] <a href="https:&#x2F;&#x2F;predictioncenter.org&#x2F;casp14&#x2F;docs.cgi?view=groupsbyname" rel="nofollow">https:&#x2F;&#x2F;predictioncenter.org&#x2F;casp14&#x2F;docs.cgi?view=groupsbyna...</a><p>[2] <a href="https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;biorxiv&#x2F;early&#x2F;2020&#x2F;04&#x2F;07&#x2F;2020.04.06.028266.full.pdf" rel="nofollow">https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;biorxiv&#x2F;early&#x2F;2020&#x2F;04&#x2F;07&#x2F;202...</a><p>[3] <a href="https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;biorxiv&#x2F;early&#x2F;2019&#x2F;08&#x2F;10&#x2F;731521.full.pdf" rel="nofollow">https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;biorxiv&#x2F;early&#x2F;2019&#x2F;08&#x2F;10&#x2F;731...</a>')