Item(by='DanielBMarkham', descendants=None, kids=None, score=None, time=1607769782, title=None, item_type='comment', url=None, parent=25395742, text='The two that are conflated according to this author: Machine intelligence in general, and A specific bundle of technologies.<p>But the goal is specifically to conflate these two, isn&#x27;t it? If I create a machine that beats a chess grandmaster, does it matter whether or not the machine &quot;knows&quot; how to play chess? If I create an app that takes you to a great restaurant for the mood you&#x27;re in, does it matter whether or not it understands &quot;mood&quot; or &quot;restaurant&quot;? At some point, the stringing together of specific bundles of technologies becomes indistinguishable to the average person from real intelligence. (This probably happens far, far sooner for the average person than it does tech folks and researchers)<p>At that point, we&#x27;ve created something that for a specific domain _is_ intelligent: it reasons about things in an internal way that is opaque to us and provides what we perceive to be interactive value. Then, that thing just becomes another bundled to be assembled in an even larger chain. True AGI would be able to create and assemble the bundles.<p>But even then, the same end-state occurs: at some point whatever we&#x27;re calling AGI will be able to do things with bundles of technologies that we perceive to provide interactive value. Will it matter at that point whether or not the machine is &quot;truly&quot; intelligent? (Apologies for the scare quotes, but many of these terms are quite suspect in this conversation and are used in all sorts of ways by authors)<p>To put it bluntly, the goal of AI work is to do cool stuff for reasons we&#x27;re not exactly sure about. Otherwise it&#x27;d just be programming. We are using a lot of programming tools, like NN, to do this. At some point, various groups will fake themselves out and stop working in that area. Whether or not that&#x27;s intelligence or not, whether or not anything new will ever happen in that field, is beside the point and not in the (commercial) scope of work. Aside from all the formal work and really cool stuff happening, in the end, when it gets used somewhere, this is a &quot;looks good enough to me&quot; situation. We&#x27;re not looking to create intelligence, we&#x27;re looking to create an uber-duber supreme version of Eliza for some given problem. The we find other, more complex and interesting problems. Then if we need to we&#x27;ll join them together (There is a lot of detail that I have ignored, including how GANs play into my argument)')