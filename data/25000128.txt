Item(by='baetheus', descendants=None, kids=None, score=None, time=1604597704, title=None, item_type='comment', url=None, parent=24997194, text='I agree! At the most fundamental level (that I know of) all bits are two ranges of voltage, light, or magnetism in a system (although I am aware of deeper understandings based in physics). We have decided to give the meanings of 0 and 1 to those ranges. We have also given meaning to collections of bits by calling them pointers or ints. We have given meaning to other collections of bits by encoding various symbols in them and a logic based on those symbols.<p>My point here isn&#x27;t to be pedantic but to argue this point: The fundamental quality of computing is that it abstracts a physical system to a logical one. In this light the realness of a data type is the same realness of a bit, since they are both structures that give way to a more defined logical system, one built on the next.<p>To speak to the OP&#x27;s claim of a category mistake I think he misses this valuable insight. The &quot;realness&quot; of programming objects and the semantics of moving them and copying them is the same &quot;realness&quot; of the bit or the data type. This is to say that the category that programming objects are contained within is, for lack of a better phrase, &quot;the category of logical abstractions built on physical systems&quot;. The reuse of &quot;move&quot; and &quot;copy&quot; to represent similar processes to those we use with physical systems is a &quot;logical encoding&quot;, not an error. In fact, the op makes the categorical mistake by saying that we mean &quot;physically move&quot; when we mean &quot;logically move&quot;.<p>That said, this was an interesting read in spite of my disagreements with some assertions.')