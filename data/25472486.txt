Item(by='coder543', descendants=None, kids=[25472530], score=None, time=1608328173, title=None, item_type='comment', url=None, parent=25472416, text='Sure, I agree it&#x27;s a lot of bandwidth.<p>But for that bandwidth to be used efficiently, the processes on each NUMA node need to almost exclusively limit themselves to memory attached to their node -- at which point, well-written software could probably do just as good spread out over several machines that are connected by multiple 100Gb network links, and then you saved two or three bajillion dollars.<p>If you&#x27;re heavily using the bandwidth over the NUMA interconnect, then you&#x27;re not going to be using the memory bandwidth very effectively (and likely not really using the processor cores effectively), and that&#x27;s when NVDIMMs like Optane Persistent Memory could give you large amounts of bulk memory storage on a smaller system.<p>Or just use a number of Intel&#x27;s new PCIe 4.0 Optane SSDs in a single machine in place of the extra memory and memory channels... the latency isn&#x27;t the same as RAM, but it&#x27;s much closer than traditional SSDs, and the bandwidth per SSD is like 7GB&#x2F;s, which is impressive.<p>It all depends on the application at hand, but there are solutions that cost a lot less than the Platinum machines for virtually every problem, in my opinion.<p>I don&#x27;t know... perhaps I&#x27;m too cynical of these cost-ineffective systems that just happen to be large, and I should be more impressed.<p>&gt; NUMA scales better than RDMA &#x2F; Ethernet &#x2F; Infiniband. A lot, lot, LOT better.<p>Disagree.')