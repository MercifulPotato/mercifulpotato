Item(by='dragontamer', descendants=None, kids=None, score=None, time=1603133285, title=None, item_type='comment', url=None, parent=24829309, text='Its not really about CUDA or OpenCL. Its about the choice to support FP16 matrix-multiplication at the assembly level of NVidia chips.<p>When you build a processor that literally has &quot;do 4x4 matrix multiplication&quot; as an assembly statement, you&#x27;ll get far superior ML performance compared to everyone else. (Except Google&#x27;s TPUs, which have larger matrix-multiplication arrays)')