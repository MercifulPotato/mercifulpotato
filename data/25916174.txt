Item(by='StreamBright', descendants=None, kids=None, score=None, time=1611671835, title=None, item_type='comment', url=None, parent=25915023, text='&gt;&gt; A single PostgreSQL instance can easily do hundreds of thousands of transactions per second<p>For example, on my (pretty average) workstation, I can do ca. 25k simple read transactions per 1 CPU core on an “in memory” pgbench dataset…with the default config for Postgres v13! With some tuning (by the way, tuning reads is much harder in Postgres than tuning writes!) I was able to increase it to ~32k TPS per core, meaning: a top-notch, dedicated hardware server can do about 1 million short reads! With reads, you can also usually employ replicas – so multiply that by 10 if needed! You then need to somehow solve the query routing problem, but there are tools for that. In some cases, the new standard LibPQ connection string syntax (target_session_attrs) can be used – with some shuffling. By the way, Postgres doesn’t limit the number of replicas, though I personally have never witnessed more than 10 replicas. With some cascading, I’m sure you could run dozens without bigger issues.<p>This sort of hand-wavy &quot;benchmark&quot; is not really good for anybody other then the author&#x27;s satisfaction. Real world scenarios are not like that.')