Item(by='theamk', descendants=None, kids=None, score=None, time=1609716766, title=None, item_type='comment', url=None, parent=25619902, text='Um, are we talking about the same &quot;asymptotic analysis&quot;? The one I am talking, the &quot;Big O&quot; notation [0], specifically ignores constant factors. So a naive matrix multiplication algorithm will always be O(n^3) in standard notation, no matter if this is binary or ternary or even ENIAC-style BCD bytes. This means <i></i>you cannot reason about ternary vs binary using asymptotic notation<i></i>.<p>And the Laundauer limit seems completely unrelated. Your link says, &quot;Modern computers use millions of times as much energy per second&quot; -- so we can have 1000x more efficient computer and still be well under the limit.<p>So the only way to compare the binary vs ternary is in the context of a specific implementation, because that&#x27;s how you can evaluate the speedup. &quot;All other conditions being equal&quot; is never true -- for example, binary machines can run faster because they need less voltage swing (and thus less bit charge), while ternary machines are faster because balanced adders do not need ripple carry. Which one has more effect? This depends on technology.<p>Here is a made-up example: let&#x27;s say we have a small amount of ancient transistors and diodes, and we want to sum up numbers, with range from -5000 to 5000. The transistor switches in 0.1 mS. How do we do it?<p>In binary, we&#x27;d need 14 bit word. Assuming we do ripple-carry adder (it is smallest part count, but slowest), in the worst case we&#x27;ll need to propagate carry across all bits, and this means we&#x27;d need at least 20 mS per operation, getting performance of at most 50 addition&#x2F;second.<p>In ternary, we&#x27;d need 9-trit word. Ternary adders do not propagate, so we could add the numbers in 2 mS. Here, the ternary is going to be much faster, at 500 addition&#x2F;sec.<p>This is a very contrived example (who makes wide ripple-carry adders anyways?) but hopefully this illustrates my point. You cannot use asymptotic analysis for this, and there are times when you can totally perform more computation for the same cost.<p>[0] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Time_complexity" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Time_complexity</a>')