Item(by='YeGoblynQueenne', descendants=None, kids=None, score=None, time=1611744915, title=None, item_type='comment', url=None, parent=25922830, text='The problem I&#x27;m describing is formally known as &quot;catastrophic forgetting&quot;.\nQuoting from wikipedia:<p><i>Catastrophic interference, also known as catastrophic forgetting, is the\ntendency of an artificial neural network to completely and abruptly forget\npreviously learned information upon learning new information.</i><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Catastrophic_interference" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Catastrophic_interference</a><p>Of course neural nets can update their weights as they are trained, but the\nproblem is that weight updates are destructive: the new weights replace the old\nweights and the old state of the network cannot be recalled.<p>Transfer learning, online learning and (deep) reinforcement learning are as\nsusceptible to this problem as any neural network techniques.<p>This is a widely recognised limitation of neural network systems, old and new,\nand overcomging it is an active area of research. Many approaches have been\nproposed over the years but it remains an open problem.')