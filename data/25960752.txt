Item(by='radford-neal', descendants=None, kids=None, score=None, time=1611945779, title=None, item_type='comment', url=None, parent=25954992, text='This rant is rather misguided.<p>For easy problems, it doesn&#x27;t much matter what you do, as long as you don&#x27;t limit your computation time to some unnecessarily-small amount.  So let&#x27;s assume you&#x27;re trying to sample from some complicated distribution that you don&#x27;t know much about, and for which you don&#x27;t know how well your Markov Chain mixes.<p>It is then highly likely that <i>whatever</i> point you start at, regardless of good intentions, is not representative of the distribution (saying it&#x27;s a <i>possible</i> point is obtuse).  You don&#x27;t want to include that point in your estimates.  Hence you want to discard burn-in.<p>By the way, a kernel of truth in the rant (though not actually mentioned) is that if you are using just one chain, you should not discard more than about 20% as burn in.  If you are tempted to discard 50%, then you don&#x27;t really know that the chain has come close to convergence.  You may say, &quot;this function of state is near 20 for the first half, then drops to around 10 for the second half, so I&#x27;ll discard the first half as burn-in&quot;. But you&#x27;re fooling yourself. For all you know, if you ran the chain longer, it might go back to a state where the value is 20, moving back and forth between these two modes, and by discarding the first half, you&#x27;re throwing out half the distribution, getting drastically wrong results. (The longer the chain stays at around 10, the less chance of this being true, which is why discarding 20% as burn-in could make sense.) An exception would be if you had good prior reason to think the first 50% couldn&#x27;t be representative of the distribution, but in that case too you&#x27;d be better off running for longer (if at all possible) to make sure the second half isn&#x27;t also unrepresentative.<p>However, if you&#x27;re trying to be as sure as you can that you&#x27;re getting the right result, you should be running more than one chain, even though they&#x27;ll have to be shorter (given a fixed budget).  Geyer rants against this too, on the basis that using all your computational budget for one run gives the greatest chance of convergence, but this makes no practical sense.  At a minimum, along with your long run, you&#x27;d want to to do a few extra short runs to see if they end up going to radically different values that are never visited in the long run - in which case you&#x27;ll have to rethink the whole thing. A good general guide would be to run something like 5 to 10 chains, for equal time, and checking whether they seem to have converged to the same distribution.  (If not, you need a better Markov chain, or a faster computer.)  Of course, doing a huge number of short runs is also bad. Moderation is good.')