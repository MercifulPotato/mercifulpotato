Item(by='rektide', descendants=None, kids=[24684754], score=None, time=1601866269, title=None, item_type='comment', url=None, parent=24683971, text='Let&#x27;s dive in a little to how Serverless &amp; FastCGI might be related.<p>The thing that fastcgi brought over cgi-bin was that an application process could be left open to communicate with the server, where-as cgi-bin model required spawning a new process for each request.<p>If one reads the AWS Lambda docs, they&#x27;ll see the execution context[1] has a similar behavior. AWS will spin up new instances, but these instances will serve multiple requests, via a fairly custom &quot;function&quot; interface defined for various runtimes (but which is actually, typically an http interface). There is a standard HTTP api for runtimes to use to retrieve function invocations[2].<p>With FastCGI the front end server uses a socket to push request messages to app servers, which replies in order. Where-as with Lambda &amp; it&#x27;s above mentioned runtime API, the runtime is retrieving requests from Amazon at it&#x27;s pacing, &amp; fulfilling them as it can. So there&#x27;s a push vs pull model, but in both cases, the application server is talking a fairly custom protocol to the front-end server.<p>Also though, there are some cgi-bin like behaviors seen in some serverless systems. Serverless is a big umbrella with a lot of different implementation strategies. One optimization is use of checkpoint-restore. With checkpoint restore, an app server is brought up to a &quot;ready to serve&quot; state, then the host operating system takes a &quot;snapshot&quot; of the process. When new instances of the process are needed, the serverless system can &quot;restore&quot; this memory mapped process &amp; the resources it was using, bringing it up in a ready-to-serve state quickly. This behavior is more cgi-bin like, in that it&#x27;s a technique for spawning new serving processes quickly, although few serverless systems go as far as cgi-bin went with a per-request process. None-the-less, openwhisk for example has was showing off start times decreasing from 0.9-0.5s for node, python, java app servers down to .09s-0.7s startup times using these checkpoint restore capabilities of the OS.<p>[1] <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;lambda&#x2F;latest&#x2F;dg&#x2F;runtimes-context.html" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;lambda&#x2F;latest&#x2F;dg&#x2F;runtimes-contex...</a><p>[2] <a href="https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;en_us&#x2F;lambda&#x2F;latest&#x2F;dg&#x2F;runtimes-api.html#runtimes-api-next" rel="nofollow">https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;en_us&#x2F;lambda&#x2F;latest&#x2F;dg&#x2F;runtimes-...</a><p>[3] <a href="https:&#x2F;&#x2F;events19.linuxfoundation.org&#x2F;wp-content&#x2F;uploads&#x2F;2017&#x2F;12&#x2F;kill-or-checkpoint_Mike-Rappaport.pdf" rel="nofollow">https:&#x2F;&#x2F;events19.linuxfoundation.org&#x2F;wp-content&#x2F;uploads&#x2F;2017...</a>')