Item(by='jiggawatts', descendants=None, kids=None, score=None, time=1605407507, title=None, item_type='comment', url=None, parent=25091964, text='An analogy I like to use is prime vs zoom lenses on DSLR cameras.<p>A common observation by professionals is that when they have a zoom lens attached to their camera, the pictures tend to be either one extreme zoom or the other. That is, they wanted &quot;as much as possible&quot; and just set the zoom range to the maximum in that direction.<p>Which means that most of the zoom range is (almost) never utilised.<p>The big advantage of prime lenses is that by sacrificing the ability to zoom, the quality can be better. A 35-50mm zoom is <i>never</i> going to be as good as two separate 35mm and 50mm prime lenses.<p>So if you want to maximise quality, get primes.<p>But then your camera bag will be heavier, and your wallet lighter.<p>Also, you now cannot have any intermediate zoom range in those rare times that you do need it.<p>So there&#x27;s <i>always</i> some trade-off being made.<p>Languages like C++ are like zoom lenses. They allow almost any programming paradigm, and various mixes too. You can have a procedural program with memory safety, with functional bits thrown in, and call out to unsafe C code if you want.<p>Languages like Haskell or JavaScript are like a prime lens, with a lot of decisions fixed at one extreme or another.<p>I suspect that what&#x27;s needed is the zoom-like flexibility of languages like C++, but with defined subsets that work more like a &quot;prime&quot; language. With physical lenses, this is impossible. You can&#x27;t take the zoom bits out, leaving the prime behind. With software... I think it can be done.<p>This isn&#x27;t that unusual an idea. Mainstream languages are already slowly converging on this concept. For example, C# has a project-level &quot;unsafe&quot; flag, which turns a set of language features on or off.')