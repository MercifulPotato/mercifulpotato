Item(by='55873445216111', descendants=None, kids=[25877004, 25869317], score=None, time=1611260586, title=None, item_type='comment', url=None, parent=25863428, text='There are some memories supporting basic in-memory operations.  For example: <a href="https:&#x2F;&#x2F;mosys.com&#x2F;products&#x2F;blazar-family&#x2F;be3rmw-bandwidth-engine-3-rmw&#x2F;" rel="nofollow">https:&#x2F;&#x2F;mosys.com&#x2F;products&#x2F;blazar-family&#x2F;be3rmw-bandwidth-en...</a>. This supports operations like read-modify-write within the memory device itself. (I have no affiliation with this company.)<p>The barrier to adoption of this is not technical, it&#x27;s economic. Memory industry has focused on making the highest capacity and lowest cost&#x2F;bit products. This drives high manufacturing volume which drives economies of scale. Memory products with integrated functions are inherently niche, and therefore do not have anywhere near the market size and economy of scale. Designers have decided (historically) that it is cheaper at the system level to keep the logic operations within the CPU and use a &quot;dumb&quot; commodity memory, even though this necessitates more bandwidth usage. (It&#x27;s a complex engineering trade-off.)<p>With logic performance continuing to scale faster than memory bandwidth, at some point an architecture that reduces the required memory bandwidth (such as computing in-memory) might start to make sense economically.')