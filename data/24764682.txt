Item(by='OliverJones', descendants=None, kids=None, score=None, time=1602590394, title=None, item_type='comment', url=None, parent=24753664, text='For a long time, &quot;AI&quot; meant &quot;unsolved hard problem&quot; to hackers like us. Speech synthesis and recognition was AI. Text recognition was AI. Some compiler optimization was AI. Search was AI. Now, those things are, well, those things. They work.<p>Things are a little different now. The feasibility of neural networks trained up on vast data sets means we have non-human systems with hunches. That is, we have AIs capable of delivering results without explanations.<p>Take a look at Neal Stephenson&#x27;s recent &quot;Fall&quot; for a social network that uses AI to generate &quot;news&quot; stories where the training metric is engagement.  The consequence is the construction of an alternate social universe, and the kind of dystopia only Stephenson can dream up.  <a href="https:&#x2F;&#x2F;www.worldcat.org&#x2F;title&#x2F;fall-or-dodge-in-hell&#x2F;oclc&#x2F;1148063262" rel="nofollow">https:&#x2F;&#x2F;www.worldcat.org&#x2F;title&#x2F;fall-or-dodge-in-hell&#x2F;oclc&#x2F;11...</a><p>Human hunches are often accompanied by a sense of ethics. The agricultural savant who sexes hatchling baby chickens knows the success of the farm depends on a low error rate. The judge sentencing a culprit knows the consequence of making mistakes.<p>I wonder how hard it would be to add a sense of ethics to neural network results? Maybe it&#x27;s just a matter of managing the error rates. But this article suggests otherwise.')