Item(by='pron', descendants=None, kids=[24959748, 24962366, 24964023, 24963020], score=None, time=1604239809, title=None, item_type='comment', url=None, parent=24959456, text='You&#x27;re asking the wrong question. Unless your program is very small or the property you wish to check is very simple, <i>nothing</i> can fully &quot;validate&quot; it. The question should be, is TLA+ more beneficial than just testing in improving program correctness?<p>Humanity currently lacks the means to verify &quot;deep&quot; properties of code at any reasonable scale. <i>Any</i> tool that works at the code level either focuses on very simple properties (memory safety), complex but local properties of a small code-unit (Ada SPARK, Java&#x27;s OpenJML), or deep properties of tiny programs (like seL4 and CompCert). These can be very important, but none truly offer the ability to &quot;verify code&quot; with some repeatable process at a generally-interesting scale. TLA+ could be used to do the same -- e.g. there is a C to TLA+ compiler -- but then it suffers from the same scale&#x2F;depth&#x2F;cost limitation of all code-level tools.<p>So given that we <i>can&#x27;t</i> just choose to verify a program, the question we want to answer is a different one: what is a good way, in a cost&#x2F;benefit sense to achieve the correctness we want. Then you can ask whether TLA+ can offer such a way that is &quot;better&quot; in that sense than what you do now, which is likely testing. Those who have tried it, including myself, have come to the conclusion that in cases where the algorithm&#x2F;design is sufficiently interesting or subtle, the answer is absolutely yes. The way TLA+ achieves it better than code level tools is that it allows you to describe your system at the level appropriate for answering your most important questions about it, and that level can be a much higher one than the code.<p>So, to answer your question, the mere act of precisely expressing your system and correctness criteria in some chosen level of detail using very simple mathematics (high-school or first-year-college level), and then model-checking some interesting instances, is a good way (in the cost&#x2F;benefit sense) to find bugs and make your program more correct. You compare it to the code by inspection. No, it does not give you 100% guarantees, but nothing else can, either. It is still worthwhile to do in addition to testing, as overall it can easier and cheaper in many cases to detect certain rare-yet-catstrophic bugs.<p>Having said that, there are various techniques being explored that can check whether your program matches the TLA+ specification more mechanically than just by inspection, that might not be sound (i.e. give a 100% guarantee) but increase confidence while being cheap.')