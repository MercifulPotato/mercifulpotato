Item(by='jillesvangurp', descendants=None, kids=None, score=None, time=1605811818, title=None, item_type='comment', url=None, parent=25152390, text='Sounds like that would be an easy use case for elasticsearch indeed. I&#x27;ve seen it handle much bigger data sets. Solr would work as well. There are probably a few other options on the market but elasticsearch would probably do pretty well on this even without a lot of tuning.<p>For reference, I once threw the entirity of open streetmaps at it before it even hit 1.0 to implement a simple reveres geocoding thing. Basically a couple hundred million street segments, some polygons, etc. At the time the geospatial support wasn&#x27;t great and very new and very CPU intensive. I got away with indexing all of that and running it on a single node cluster with a xeon and 32G of RAM and spinning disk (RAID 1, no SSD). It worked great. Very responsive. Indexing only took about 50 minutes or so. Most of that was my parsing logic. That&#x27;s not comparable of course, I&#x27;d expect this to be faster on the same hardware with a current version of Elasticsearch. They&#x27;ve made a lot of leaps with improving performance, memory usage, cpu usage, disk usage, robustness, etc. in the 7 major versions since then.')