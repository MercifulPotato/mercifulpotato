Item(by='fulafel', descendants=None, kids=None, score=None, time=1605948609, title=None, item_type='comment', url=None, parent=25165261, text='&gt; Almost every application multiplies and divides all the time anyway<p>This is the crux of the RISC philosophy: Most things happen &quot;all the time&quot; in processors since they do a lot of things very fast, but what really matters is how often. The quantitative approach is actually looking at what instruction mix and its fastest implementation given to a reasonably competent compiler prouduces fastests overall results (given that simpler chips could be clocked faster, have shorter pipelines so better branching, leave more space for cache, etc).<p>The thing about multiplicationsan divisions, besides being slow in silicon, is that you can actually cover a surprisingly big part of application code multiplies with just a couple of shifts and adds. This is especially true for constant multiply or a known smallish range of multipliers, which optimizers are good at discovering.<p>But of course the transistor budgets and tradeoffs were different in the days of early RISC. Still, even the relatively recent RISC-V elided multiply and divide from the base instruction set.')