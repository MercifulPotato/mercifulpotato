Item(by='dragontamer', descendants=None, kids=[24842280, 24842294], score=None, time=1603226861, title=None, item_type='comment', url=None, parent=24842200, text='&gt; Sounds like what you are saying that fork join model translates easely by the compiler to these SIMD instructions?<p>Why do you think CUDA has become so popular recently? That&#x27;s exactly what CUDA, OpenCL, and ISPC does.<p>&gt; Some compilers can also vectorize plain loops, but you would advocate for fork join?<p>CUDA style &#x2F; OpenCL style fork-join is clearly easier than reading compiler output, trying to debug why your loop failed to vectorize. That&#x27;s the thing about auto-vectorizers, you end up having to grok through tons of compiler output, or check out the assembly, to make sure it works.<p>ALL fork-join style CUDA &#x2F; OpenCL code automagically compiles into SIMD instructions. Ditto with ISPC. Heck, GPU programmers have been doing this since DirectX 7 HLSL &#x2F; OpenGL decades ago.<p>There&#x27;s no &quot;failed to vectorize&quot;. There&#x27;s no looking up SIMD-instructions or registers or intrinsics. (Well... GPU-assembly is allowed but not necessary). It just works.<p>-------<p>If you&#x27;ve never tried it, really try one of those languages. CUDA is for NVidia GPUs. OpenCL for AMD. ISPC for Intel CPUs (instead of SIMD intrinsics, ISPC was developed for an OpenCL-like fork-join SIMD programming environment).<p>And of course, Julia and Python have some CUDA plugins.')