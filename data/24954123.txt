Item(by='tsimionescu', descendants=None, kids=[24962275, 24954185], score=None, time=1604170044, title=None, item_type='comment', url=None, parent=24951897, text='&gt;  if I have a credible belief that I can save some number of future humans, what is the acceptable moral number of current humans to place at risk and&#x2F;or kill?<p>&gt; Imho, that&#x27;s a grave, serious decision, but not one to which the morally absolute is &quot;zero, always.&quot;<p>I think that what we&#x27;ve learned throughout human history is that no one should be trusted and given the power to make such decisions. It has invariably led to disasters. The very idea that someone can decide to put someone else&#x27;s life in danger for potential future advances gives too many perverse incentives - chief of which, rationalization that &quot;more people will be saved&quot; even as the experiment crashes and burns.')