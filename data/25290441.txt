Item(by='tzs', descendants=None, kids=None, score=None, time=1607012452, title=None, item_type='comment', url=None, parent=25286446, text='&gt; LeCun mentioned that there would have been opposite problem if it were trained on a dataset from Senegal. But why wasn&#x27;t it trained on a dataset from Senegal? Why do we always see these errors where white-centric datasets produce white-centric results?<p>Probably because it was a research AI not a production AI. Having a very diverse dataset at that stage doesnâ€™t help with your research, so it is fine to use whatever is easily available.<p>At that stage, you are trying to show that your approach can work in some cases. Once you&#x27;ve got that, it is time to expand the research with a wider range of inputs to find out what the limits of your approach are.<p>For example, if I were trying to make a US English speech to text transcription system, I might start with recordings of assorted NPR programs, because NRP often makes the recording available online along with they transcripts.<p>That would be great for determining if my basic approach has promise. Once I have determined that, so know that the whole endeavor is not just a waste of time, I could go looking for data that includes speech that has characteristics that would be missing from the NPR data, such as heavy regional accents.')