Item(by='benibela', descendants=None, kids=None, score=None, time=1611754179, title=None, item_type='comment', url=None, parent=25924675, text='&gt;The data architecture I use combines, in order of importance: (1) borg, for incremental deduplicated backups onsite and offsite; (2) syncthing, for duplication and synchronization across devices; (3) fim, for managing file integrity; (4) rsync, local copy to another drive for convenient restores; and (5) git, in places where commit history is actually useful, like code or dotfiles.<p>That looks overly complicated<p>Why is there no single tool that can do all of those?<p>I think one tool could be much more efficient. Especially since they could reuse the databases. With one database of hashes of each file, it could find the changed files and then incrementally only backup those. No need to have one program to search changed files to copy them, and then again  have one program to search changed files to hash them<p>I mostly use rsync. Occasionally I destroy my backups by calling it wrongly, like missing a trailing slash. That could not happen if the copying and file integrity checking was combined in one tool<p>&gt;fim combined with incremental backup solves this problem, is filesystem agnostic and painless to migrate around, and is for some reason completely unknown and obscure: <a href="https:&#x2F;&#x2F;evrignaud.github.io&#x2F;fim&#x2F;" rel="nofollow">https:&#x2F;&#x2F;evrignaud.github.io&#x2F;fim&#x2F;</a><p>That looks very useful<p>But it stores the database as json? That is a bad format to store file names. And written in Java it is probably going to be slow       \n(I have over a million files in ~, and multiple copies of it in the backups, so I care a lot about performance)<p>So many emojis in the commit log. Is that really necessary nowadays?')