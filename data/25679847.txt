Item(by='danielpadkins', descendants=None, kids=None, score=None, time=1610066980, title=None, item_type='comment', url=None, parent=25653494, text='I don&#x27;t think the goal is for them to &quot;decide what&#x27;s good for the world&quot;. You can classify disruptiveness&#x2F;risk of a piece of tech fairly objectively.<p>Delaying release is to give others (most clearly social media) time to adjust and ensure safety within their own platforms&#x2F;institutions (of which they are the arbiters). It also gives researchers and entrepreneurs a strong motivation of &quot;we have to solve these risk points before this technology starts being used&quot;. While there are clearly incentive issues and gatekeeping in the research&#x2F;startup community, this is a form of decentralized decision-making.<p>I don&#x27;t see a strong case for why access should be open-sourced at announcement time, especially if it&#x27;s reproducible. Issues will arise when their tech reaches billions of dollars to train, making it impossible to reproduce for 99.99% of labs&#x2F;users. At that point, OpenAI will have sole ownership and discretion over their tech, which is an extremely dangerous world. GPT-3 is the first omen of this.')