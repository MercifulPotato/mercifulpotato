Item(by='fxtentacle', descendants=None, kids=[25301588], score=None, time=1607081075, title=None, item_type='comment', url=None, parent=25300283, text='In a similar vein to what you described, I recently evaluated multiple deep learning based image synthesis techniques for their viability for filling in parts of real-time games. Turns out, it&#x27;s just not useful. GPUs are just fine with rendering mind-boggling amounts of geometry, as long as overdraw is low. In other words, using <i>deep</i> learning is using up exactly the resource that&#x27;s rare already.<p>Also kind of related, the new UE5 game engine is introducing a novel in-GPU compression method which will allow them to handle more geometry. Not only for games, but also for photogrammetry, memory tends to be one of the scarcest resources.<p>In summary, unless the AI uses relatively few memory and unless it&#x27;s relatively few layers, it won&#x27;t stand a chance against traditional ways of handling geometry.<p>That said, the promise that I see with NeRF and related methods is their ability to make up plausible things. For everyday objects, these techniques can learn to predict how an apple would look like if you would rotate it reasonably well. That is valuable for robotics, where you need to make sure that you still recognize your environment even after you drive around a corner.')