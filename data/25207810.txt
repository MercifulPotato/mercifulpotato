Item(by='Const-me', descendants=None, kids=None, score=None, time=1606300813, title=None, item_type='comment', url=None, parent=25207375, text='An extremely rough estimate, FFT (prolly the most expensive one of what you mentioned) needs 5N*Log2(N) operations.<p>If you have 1M source floats and want 60 FPS, translates to only 6 GFlops.<p>On Pi4, on paper the GPU can do 32 GFlops. Again on paper, the CPU can do 8 FLOPs&#x2F;cycle which translates (4 cores at 1.5 GHz) to 48 GFlops. That’s assuming you know what you’re doing, writing manually-vectorized C++ <a href="http:&#x2F;&#x2F;const.me&#x2F;articles&#x2F;simd&#x2F;NEON.pdf" rel="nofollow">http:&#x2F;&#x2F;const.me&#x2F;articles&#x2F;simd&#x2F;NEON.pdf</a> abusing FMA, using OpenMP or similar for parallelism, and have a heat sink and ideally a fan.<p>So you’re probably good with both CPU and GPU. Personally, I would have started with NEON for that. C++ compilers have really good support for a decade now. These Vulkan drivers are brand new, and GLES 3.1 which added GPGPU is not much older, I would expect bugs in both compiler and runtime, these can get very expensive to workaround.<p>While I don’t have any experience with Jetson, on paper it’s awesome, with 472 GFlops. Despite the community is way smaller, nVidia is doing better job supplying libraries, CUDA toolkit has lots of good stuff, see e.g. cuFFT piece (I did use CUDA, cuFFT and other parts, just not on Jetson).')