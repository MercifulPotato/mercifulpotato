Item(by='sebasv_', descendants=None, kids=None, score=None, time=1607283737, title=None, item_type='comment', url=None, parent=25325084, text='Finding the right architecture, or more in general the right model, is very much still the main problem.<p>You should be careful with the meaning you ascribe to the word &#x27;universal&#x27;. The list of universal approximators is massive, and the sub-list of universal approximators that can be trained with OLS is still substantial. Still these models can differ significantly:<p>- How efficient are they (in #parameters required for a certain error) for specific tasks?  There is a known &#x27;maximum efficiency&#x27; for general tasks, but in high dimensions this efficiency is terrible, such that many models will fail terribly on high-dimensional data. Hence, you should pick a model that is exceptionally good for a specific task, although it might be less efficient for other tasks.<p>- How well can the model cope with noise? If your dependent variable is severely distorted (think financial data) then you need a model that can balance between interpolating datapoints and averaging out the noise.<p>Just to name my two favorite properties. The first one is _kind of_ related to learnability, since an inefficient model is often pretty much impossible to learn.')