Item(by='blackbear_', descendants=None, kids=None, score=None, time=1602675247, title=None, item_type='comment', url=None, parent=24773576, text='&gt; Gradient descents are a special case of associative learning rules assuming all data points the same importance.<p>No. Gradient descent is an optimization method that has nothing to do with learning. It is used to optimize parameterized functions that are said to be &quot;learning&quot;, but it&#x27;s not the only approach. It is also trivially easy, and not uncommon, to use different weights for different data points.<p>Can you clarify what you mean with associative learning?')