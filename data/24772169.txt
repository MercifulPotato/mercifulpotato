Item(by='motohagiography', descendants=None, kids=[24772210], score=None, time=1602637915, title=None, item_type='comment', url=None, parent=24771056, text='Odd to see an article about forecasting without mentioning DeMesquita and Smith&#x27;s predictioneer models and stakeholder salience models. Also without Charlie Munger&#x27;s comments on incentives, which have had a better track record than pretty much anyone.<p>There was much point scoring done after the 2016 U.S. election about polling and predictions being wrong, particularly against Fivethirtyeight, but where I think critics got it wrong was, when someone says there&#x27;s a %95 chance of an event going in one way, it&#x27;s not valuable as a prediction, but it certainly is as an accurate assessment of the impact of the results. In 2016, if you told people that the %95 implied probability of winning translated to what felt like paying out a 19&#x2F;1 loss, a lot of people would have agreed with you.<p>You can reliably bet on the effect of the upset being inversely proportional to the predicted probabilities.  When I see election predictions that are 60:40 I think the 2nd order impacts of the result will be slightly lopsided, but within the realms of expectations. In this sense, %54 chance of winning close races may be better for stability than perceived polarized %95 ones because of how people perceive the results of a loss.')