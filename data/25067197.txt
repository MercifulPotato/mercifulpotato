Item(by='Arcuru', descendants=None, kids=[25067346], score=None, time=1605164044, title=None, item_type='comment', url=None, parent=25060762, text='Instead of wall time, the cycle counts should be a little less noisy as they will actually account for the threads getting switched out. In this case they show a relatively similar reduction from a quick glance.<p>&gt; One plausible explanation would be that PGO improves instruction cache utilization, something which makes a difference for execution time but would not be reflected in the amount of instructions executed.<p>Yes, this is a big reason why PGO is useful. It places the hot code together for improved ICache performance, while keeping the colder basic blocks separate (though there are likely some strategies here I don&#x27;t know about). You could show the ICache miss counter and prove that this is the case.<p>&gt; I also don&#x27;t know how branch mispredictions factor into instruction counts -- branch prediction being another aspect explicitly targeted by PGO.<p>Branch mispredictions won&#x27;t show up directly in the instruction counts, but they will show up indirectly through lower CPI or you can explicitly look at the counters for branch misses and compare between the two runs. If you were asking about whether speculative instructions from the missed branch are counted, they are not. Instructions are only counted once they are retired. (Intels counter for this is specifically named &quot;Instructions Retired&quot; to clarify that distinction).<p>&gt; In order to make the collected data as useful as possible, we should try to exercise all the common code paths within the compiler. I typically use the &quot;standard&quot; rustc-perf benchmark suite for this purpose<p>This is not correct, though maybe just misstated. You need to exercise the code with inputs that are representative of the code you want to optimize for. Mozilla does this with the Firefox build (presumably) by using the Firefox build itself as an input since it is small enough. That&#x27;s a perfect 1:1, so their performance gains are as good as possible.<p>This post does the same thing, using the same Benchmark suite as training data and for testing, but the goal is to use this optimized rustc to compile other Rust programs. It would probably be better to show the results on a separate set of benchmarks to see how well PGO does for the general use case of &quot;compiling Rust code&quot; instead of &quot;compiling the training data&quot;.<p>Source: Did a lot of performance analysis (with a heavy use of counters) at my last job at Microsoft. They were very useful when we needed to do detailed analysis between x86 and ARM, among other things. I didn&#x27;t work on PGO but a sibling team did, it was used extensively for the Windows builds. It was an interesting job, but unfortunately moving further up the stack to be a low level code monkey working on boring backend development at a colorful cloud company pays significantly better.')