Item(by='dooferlad', descendants=None, kids=None, score=None, time=1609102006, title=None, item_type='comment', url=None, parent=25550495, text='(microelectronics graduate in 2001, turned software engineer, I have worked for ARM and Imagination Technologies on simulations of CPUs, GPUs, networking products and other bits of SoCs)<p>Yield wouldn&#x27;t be that bad - ARM CPUs are small in comparison to their x86 cousins. I would expect that you would get to 32 CPUs the same way everyone else does - build a 32 core design and blow enable fuses on bad CPUs, then badge as appropriate.<p>To get a desktop class GPU they will need to address memory bandwidth. I am assuming they are using a tile based rendering process so memory bandwidth is less of an issue in comparison to scan line rendering (do desktop GPUs still do that?) I would assume that they are enjoying the benefits of the system level cache with the CPU and GPU sharing. I would expect there to be some careful benchmarking of increasing GPU cores, memory speed, memory size and system cache size going on at Apple.<p>There isn&#x27;t anything stopping Apple from supporting external GPUs, but it would require a new SoC with more PCIe lanes. External buses are much more power hungry and take up space on the die. I don&#x27;t have a mental model of how much space plonking a PCIe x16 interconnect would cost in terms of area or power (taking into account you need to get that data across the chip too), but my gut reaction is that it isn&#x27;t likely unless there is a customer use case they can&#x27;t solve on chip.')