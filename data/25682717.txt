Item(by='psykotic', descendants=None, kids=None, score=None, time=1610094027, title=None, item_type='comment', url=None, parent=25682375, text='&gt; I think it&#x27;s bimodal: either TCO is a defining feature of the language, or a best-effort optimization that nobody should rely on.<p>I have some C code which is an uncomfortable challenge to this dichotomy (which mirrors my own feelings on TCO). It&#x27;s heavily micro-optimized and only uses 16 bytes of stack per recursion even when not running on -O2 with TCO disabled. I can statically bound the stack usage relative to another fixed resource limit in the program that would be hit (and detected) before a stack overflow assuming it runs well within a typical main thread stack size, so the user will see a nice error rather than a crash. You&#x27;ll have to take my word for it that writing this particular code with a trampoline or state machine switch would defeat the point; even if I did, hitting the other resource limit would be non-recoverable and lead to program termination. And in practice it&#x27;s going to run with -O2. So, it will run safely even without TCO under those stack size preconditions, but realistically I wouldn&#x27;t have written the code this way if not for the possibility of TCO on optimized builds since the entire goal is performance.<p>On the other hand, the guarantees are better than most recursive-descent parsers you&#x27;ll find in shipping compilers in terms of blowing the stack if the input is too deeply nested. Every non-tail recursive C program with a recursion depth that is linear in the input size has latent stack overflows unless it does explicit depth checking with conservative cutoffs (it might hide those stack overflows behind a pretty-looking error by using signal handlers). You&#x27;re probably only safe from that in practice with worst-case log-depth recursion relative to the input size.')