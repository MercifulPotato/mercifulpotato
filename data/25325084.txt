Item(by='GlenTheMachine', descendants=None, kids=[25327039, 25326045, 25325103, 25331278, 25325414, 25325694], score=None, time=1607276504, title=None, item_type='comment', url=None, parent=25314830, text='I&#x27;m confused by findings like this one, and I&#x27;m hoping someone here can educated me.<p>There are many known universal approximations. Deep networks are one. SVMs are one. Heck, cubic splines are one, and they&#x27;ve been in use for nearly a hundred years IIRC.<p>The problem has never been one of finding a sufficiently powerful approximator. It has been training that approximator. My understanding of the significant advancement made by deep learning is that we finally figured out how to train a specific kind of universal approximator in a way such that it finds very good separation surfaces for what used to be impossible-to-solve classification problems.<p>But it should be no surprise to anyone that there exist, in theory, other universal approximations that approximately reproduce the same separation surfaces, should it? I&#x27;d expect <i>any</i> universal approximator to be powerful enough to reproduce the separation surfaces, hence the meaning of the word &quot;universal&quot;. The problem was always finding the right weights, not finding the right approximator architecture.<p>Am I missing something?')