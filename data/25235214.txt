Item(by='GeekyBear', descendants=None, kids=[25235494, 25235970, 25235798, 25236783], score=None, time=1606536884, title=None, item_type='comment', url=None, parent=25233554, text='Anandtech has already posted a list of ways that Apple&#x27;s big ARM core implementation (in the iPhone version of the chip) differs from industry norms, ARM and x86.<p>Some examples<p>&gt;Decode:<p>What really defines Apple’s Firestorm CPU core from other designs in the industry is just the sheer width of the microarchitecture. Featuring an 8-wide decode block, Apple’s Firestorm is by far the current widest commercialized design in the industry.<p>Re-order Buffer:<p>A +-630 deep ROB is an immensely huge out-of-order window for Apple’s new core, as it vastly outclasses any other design in the industry. Intel’s Sunny Cove and Willow Cove cores are the second-most “deep” OOO designs out there with a 352 ROB structure, while AMD’s newest Zen3 core makes due with 256 entries, and recent Arm designs such as the Cortex-X1 feature a 224 structure.<p>Execution Units:<p>On the Integer side, we find at least 7 execution ports for actual arithmetic operations. These include 4 simple ALUs capable of ADD instructions, 2 complex units which feature also MUL (multiply) capabilities, and what appears to be a dedicated integer division unit.<p>On the floating point and vector execution side of things, the new Firestorm cores are actually more impressive as they a 33% increase in capabilities, enabled by Apple’s addition of a fourth execution pipeline. The FP rename registers here seem to land at 384 entries, which is again comparatively massive. The four 128-bit NEON pipelines thus on paper match the current throughput capabilities of desktop cores from AMD and Intel, albeit with smaller vectors.<p>Cache:<p>Apple’s designs are monstrous, and the A14 Firestorm cores continue this trend. Last year we had speculated that the A13 had 128KB L1 Instruction cache, similar to the 128KB L1 Data cache for which we can test for, however following Darwin kernel source dumps Apple has confirmed that it’s actually a massive 192KB instruction cache. That’s absolutely enormous and is 3x larger than the competing Arm designs, and 6x larger than current x86 designs, which yet again might explain why Apple does extremely well in very high instruction pressure workloads, such as the popular JavaScript benchmarks.<p>The huge caches also appear to be extremely fast – the L1D lands in at a 3-cycle load-use latency. AMD has a 32KB 4-cycle cache, whilst Intel’s latest Sunny Cove saw a regression to 5 cycles when they grew the size to 48KB.<p><a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;16226&#x2F;apple-silicon-m1-a14-deep-dive&#x2F;2" rel="nofollow">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;16226&#x2F;apple-silicon-m1-a14-de...</a><p>There are plenty of other details in the piece, although bear in mind that the M1 is more beefy than the A14 detailed here (more i&#x2F;o bandwidth, larger system cache, etc.).')