Item(by='nkurz', descendants=None, kids=[25668489], score=None, time=1609982248, title=None, item_type='comment', url=None, parent=25661840, text='One could argue that it&#x27;s not &quot;fundamental&quot;, but it&#x27;s definitely a functional limitation of the current Intel cores.  The memory bandwidth of a single core is hardware limited by the number &quot;Line Fill Buffers&quot;.   Each buffer keeps track of one outstanding L1 cacheline miss, thus the number of LFB&#x27;s limits the memory level parallelism (MLP).  &quot;Little&#x27;s Law&quot; gives the relationship between the latency, outstanding requests, and throughput.   With 10 LFB&#x27;s and the current latency of memory, it&#x27;s physically impossible for a single core to use all available memory bandwidth, especially on machines with more than 2 memory channels.<p>The M1 chip allows higher MLP, presumably because it has more LFB&#x27;s per core (or maybe they are using  different approach where the LFB&#x27;s are not per-core?).  I apologize for using so many abbreviations.  I searched to try to find a better intro, but didn&#x27;t find anything perfect.  I did come across this thread that (apparently) I started several years ago at the point where I was trying to understand what was happening: <a href="https:&#x2F;&#x2F;community.intel.com&#x2F;t5&#x2F;Software-Tuning-Performance&#x2F;Single-Threaded-Memory-Bandwidth-on-Sandy-Bridge&#x2F;td-p&#x2F;959584" rel="nofollow">https:&#x2F;&#x2F;community.intel.com&#x2F;t5&#x2F;Software-Tuning-Performance&#x2F;S...</a>.')