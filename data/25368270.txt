Item(by='loser777', descendants=None, kids=None, score=None, time=1607563188, title=None, item_type='comment', url=None, parent=25367393, text='At a few hundred microseconds per step, the benchmark steps  start to approach the overhead of GPU kernel invocation and memory allocation.\n1875 training steps means a batch size of 32, which is hardly optimal given the extremely small model size here.\nThe same effect is the reason why CPUs remain latency competitive for batch size 1 inference, especially for small models.')