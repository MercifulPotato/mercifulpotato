Item(by='jasomill', descendants=None, kids=None, score=None, time=1610811941, title=None, item_type='comment', url=None, parent=25794616, text='SDR? Sure. But unless something has changed recently,  4K Netflix on PC requires a particular flavor of Windows DRM that is only supported by NVIDIA GPUs starting with Pascal and Intel integrated graphics starting with Kaby Lake‡.<p>On a more technical related note, I&#x27;d imagine 4K SDR variants of all Netflix HDR productions are generated on the back-end as an output of the same post-production process used to produce SDR prints at lower resolutions for reasons of both creative control an delivery efficiency; HEVC is just a compression algorithm, after all, and mostly orthogonal to matters of colorspace conversion and tone mapping.<p>See, e.g.,<p><a href="https:&#x2F;&#x2F;partnerhelp.netflixstudios.com&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;360000588548-Color-Pipeline" rel="nofollow">https:&#x2F;&#x2F;partnerhelp.netflixstudios.com&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;360...</a><p>and observe that the example Dolby Vision workflow yields three distinct masters,<p>1. Dolby Vision (HDR + SDR tone mapping metadata)<p>2. SDR (generated automatically from the Dolby Vision source)<p>3. DCI-P3 (for potential theatrical exhibition)<p>I therefore assume the requirements for 4K SDR playback of SDR and HDR titles are identical.<p>‡ If and only if said Kaby Lake iGPU is connected to a video output.<p>I mention this because I can only watch 4K Netflix on my Hades Canyon NUC with the help of a Pascal eGPU, because, while the Kaby Lake iGPU is present and fully functional, all video outputs connect to the NUC&#x27;s discrete AMD Polaris GPU, which Netflix doesn&#x27;t support.<p>DRM sucks.')