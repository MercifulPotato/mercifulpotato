Item(by='onurcel', descendants=None, kids=None, score=None, time=1603421888, title=None, item_type='comment', url=None, parent=24864877, text='Exactly. I work on Laser2, the approach is the same as Laser [0], Laser2 performs better on some low resource languages.<p>A more ELI5 explanation would be something like this: Laser is an encoder&#x2F;decoder architecture trained as a translation task from language X to english&#x2F;spanish, with the particularity of having only one vector between the encoder and decoder. Once this system is trained (with public translation datasets), the vector that the encoder gives you for an input sentence represents the &quot;meaning&quot; of that sentence, since the decoder relies only on that information to generate a translation. And this vector representation is the same for any language the system was trained on.<p>So we use that system to mine data from commoncrawl: giving any language pair (say romanian-nepali), having two vectors close to each other in that latent space means the sentences have the same meaning.<p>We use fastText&#x27;s language classifier [1] to filter from commoncrawl, compute the vector representations with Laser, and find close vectors thanks to Faiss [2].<p>[0] <a href="https:&#x2F;&#x2F;engineering.fb.com&#x2F;ai-research&#x2F;laser-multilingual-sentence-embeddings&#x2F;" rel="nofollow">https:&#x2F;&#x2F;engineering.fb.com&#x2F;ai-research&#x2F;laser-multilingual-se...</a><p>[1] <a href="https:&#x2F;&#x2F;fasttext.cc&#x2F;docs&#x2F;en&#x2F;language-identification.html" rel="nofollow">https:&#x2F;&#x2F;fasttext.cc&#x2F;docs&#x2F;en&#x2F;language-identification.html</a><p>[2] <a href="https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;faiss" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;facebookresearch&#x2F;faiss</a>')