Item(by='benlwalker', descendants=None, kids=None, score=None, time=1611952259, title=None, item_type='comment', url=None, parent=25961675, text='Whether you get more IOPs with smaller I&#x2F;Os depends on a number of things. Most drives these days are natively 4KiB blocks and are emulating 512B sectors for backward compatibility. This emulation means that 512B writes are often quite slow - probably slower than writing 4KiB (with 4KiB alignment). But 512B reads are typically very fast. On Optane drives this may not be true because the media works entirely differently - those may be able to do native 512B writes. Talk to the device vendor to get the real answer.<p>For at least reads, if you don&#x27;t hit a CPU limit you&#x27;ll get 8x more IOPS with 512B than you will with 4KiB with SPDK. It&#x27;s more or less perfect scaling. There&#x27;s some additional hardware overheads in the MMU and PCIe subsystems with 512B because you&#x27;re sending more messages for the same bandwidth, but my experience has been that it is mostly negligible.<p>The benchmark builds to build&#x2F;examples&#x2F;perf and you can just run it with -h to get the help output. Random 4KiB reads at 32 QD to all available NVMe devices (all devices unbound from the kernel and rebound to vfio-pci) for 60 seconds would be something like:<p>perf -q 32 -o 4096 -w randread -t 60<p>You can specify only test specific devices with the -r parameter (by BUS:DEVICE:FUNCTION essentially). The tool can also benchmark kernel devices. Using -R will turn on io_uring (otherwise it uses libaio), and you simply list the block devices on the command line after the base options like this:<p>perf -q 32 -o 4096 -w randread -t 60 -R &#x2F;dev&#x2F;nvme0n1<p>You can get ahold of help from the SPDK community at <a href="https:&#x2F;&#x2F;spdk.io&#x2F;community" rel="nofollow">https:&#x2F;&#x2F;spdk.io&#x2F;community</a>. There will be lots of people willing to help.<p>Excellent post by the way. I really enjoyed it.')