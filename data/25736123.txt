Item(by='dragontamer', descendants=None, kids=[25741856], score=None, time=1610396892, title=None, item_type='comment', url=None, parent=25735065, text='&gt; The AVX512 fanboi contingent<p>Just so you know... I&#x27;m an AMD Threadripper fanboy, if anything. Since that&#x27;s my personal computer. More importantly though, I&#x27;m a technologist. I experiment and play with many technologies, including SIMD compute, when I can.<p>Either way, I don&#x27;t think flamebait comments like that are very helpful for discussion. But I&#x27;ll try to focus on the crux of your argument instead...<p>&gt; Meanwhile Apple and AMD are eating Intel&#x27;s lunch with no 512 bit SIMD instruction units at all<p>Apple has 4x 128-bit Multiply-and-accumulate per-clock-tick on its M1. AMD has 2+2 multiply and add x 256-bit SIMD.<p>Those processors are actually very beefy in terms of SIMD-implementation.<p>There&#x27;s also the Fujitsu A64Fx, which is an ARM-implementation of 512-bit SVE. In fact, 512-bit ARM-SVE is about to be widely-deployed on Neoverse.<p>SIMD-units are universally expanding across the industry. One of AMD Threadripper&#x27;s biggest leaps forward from Zen1 -&gt; Zen2 was the upgrade from 2+2 128-bit SIMD to 2+2 256-SIMD (doubling its throughput).<p>Intel is trying to stay ahead of the curve with 512, and they&#x27;re really not that far ahead. Indeed: ARM&#x27;s SVE is already caught up.<p>-------<p>NVidia&#x27;s 32-wide SIMT is basically a 1024-bit implementation, while AMD&#x27;s 64-wide SIMD is 2048-bit SIMD. With all of the &quot;Deep Learning&quot; going on, its actually a very important workload for a number of companies.<p>Linus is pretty much saying that Deep Learning &#x2F; Tensorflow &#x2F; etc. etc. isn&#x27;t important. Which is... backwards thinking methinks. I think that deep learning is overhyped, but still I see the benefits of general SIMD compute in every-day coding situations.')