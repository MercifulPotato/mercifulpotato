Item(by='xxpor', descendants=None, kids=[24944020, 24944469, 24944139, 24944911, 24944795, 24944815], score=None, time=1604075544, title=None, item_type='comment', url=None, parent=24943829, text='&gt;which human drivers often don&#x27;t do (and may not expect other vehicles to do).<p>This presents an interesting problem. It&#x27;s obviously easier to program something to follow the law, given it&#x27;s unambiguous. But the question is what are we optimizing for? The fewest crashes? That&#x27;s probably the right thing to do given crashes are bad. In that case, isn&#x27;t it better to do what people would expect other cars to do? But are Waymo constrained by the fact that if a self-driving car is programmed to get a ticket they could be held liable? Probably.<p>I think the moral side of self-driving cars is just as hard or a harder problem than the technical side, and we haven&#x27;t made the decisions as a society that we need to. If the government doesn&#x27;t step up soon to lay out how this is going to work, the corporations will. And guess what: they&#x27;ll choose whatever costs them the least amount of money. Not what&#x27;s best for society.')