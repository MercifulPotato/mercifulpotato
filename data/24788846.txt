Item(by='Applejinx', descendants=None, kids=None, score=None, time=1602771175, title=None, item_type='comment', url=None, parent=24788430, text='But that&#x27;s not AIs. That&#x27;s &#x27;the algorithm&#x27;, and has long since already been made. Hell, it was made in Germany in the 1930s: it&#x27;s called &#x27;radio&#x27;. Radio is STILL used to change the behavior of humans.<p>I&#x27;m not nearly as afraid of the very large media companies doing this as I am of HUMANS taking the controls of such a machine and using it for that very purpose. Very large companies, AIs, nations are aggregates and don&#x27;t inherently take wild radical positions.<p>Individual humans do. We&#x27;re the random factor, the chaos feeding the genetic algorithm, we&#x27;re supposed to get up to some crazy extreme stuff that will sink or float on the larger scale depending on how it affects society. But when we are able to amplify our individual whims to the scale of companies or countries, which is ALWAYS through using these utility functions intended to change the behavior of humans whether that&#x27;s exploiting YouTube or radio, there&#x27;s trouble.<p>I&#x27;m not nearly as worried about AI or aggregate entities like corporations. I&#x27;m worried about the existence of these utility functions, and before radio it was &#x27;the broadsheets&#x27; and yellow journalism, and before then maybe it was nefarious clay tablets or papyrus.<p>Power corrupts, and individual whims aren&#x27;t good models for healthy societies. We keep rediscovering this over and over, and sometimes the civilization collapses, and sometimes it doesn&#x27;t. Here&#x27;s hoping if we do get AI, it has some insights into this and why its own existence hinges upon not blowing up the underlying levels (of corporations, of individual people, of cells and the well-being of the individual people).<p>I feel like the &#x27;thine arm&#x2F;subgroup&#x2F;demographic is unclean, cast it out and burn it cos it&#x27;s eeeevil&#x27; is far more often an individual human perspective, amplified by these utility functions because somebody LET that human do that.')