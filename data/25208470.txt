Item(by='segfaultbuserr', descendants=None, kids=None, score=None, time=1606307117, title=None, item_type='comment', url=None, parent=25208050, text='It&#x27;s said that GPT-3 shows rudimentary hints of &quot;general intelligence&quot;-like behaviors, it can really &quot;solve&quot; (not just memorizing answers) many puzzles without fine-tuning it by domain-specific training data, although the performance is limited without doing it.<p>David Chalmers [0] wrote,<p>&gt; When I was a graduate student in Douglas Hofstadter’s AI lab, we used letterstring analogy puzzles (if abc goes to abd, what does iijjkk go to?) as a testbed for intelligence. My fellow student Melanie Mitchell devised a program, Copycat, that was quite good at solving these puzzles. Copycat took years to write. Now Mitchell has tested GPT-3 on the same puzzles, and has found that it does a reasonable job on them (e.g. giving the answer iijjll). It is not perfect by any means and not as good as Copycat, but its results are still remarkable in a program with no fine-tuning for this domain.<p>&gt; What fascinates me about GPT-3 is that it suggests a potential mindless path to artificial general intelligence (or AGI). GPT-3’s training is mindless. It is just analyzing statistics of language. But to do this really well, some capacities of general intelligence are needed, and GPT-3 develops glimmers of them.<p>[0] <a href="https:&#x2F;&#x2F;dailynous.com&#x2F;2020&#x2F;07&#x2F;30&#x2F;philosophers-gpt-3" rel="nofollow">https:&#x2F;&#x2F;dailynous.com&#x2F;2020&#x2F;07&#x2F;30&#x2F;philosophers-gpt-3</a>')