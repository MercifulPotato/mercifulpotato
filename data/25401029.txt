Item(by='agallego', descendants=None, kids=[25401338], score=None, time=1607802694, title=None, item_type='comment', url=None, parent=25400801, text='Indeed. I think you have different saturation points the wider the use cases you hit. One example w&#x2F; a single-core (which btw, agreed whole heartedly for io) is checksumming + decoding.<p>For kafka, we have multiple indexes - a time index and an offset index which are simple metadata. the trouble becomes on how you handle decompression+checksumming+compression for supporting compacted topics.  ( <a href="https:&#x2F;&#x2F;github.com&#x2F;vectorizedio&#x2F;redpanda&#x2F;blob&#x2F;dev&#x2F;src&#x2F;v&#x2F;storage&#x2F;spill_key_index.cc" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;vectorizedio&#x2F;redpanda&#x2F;blob&#x2F;dev&#x2F;src&#x2F;v&#x2F;stor...</a> )<p>So single core starts to get saturated while doing both fore-ground and background requests.<p>.....<p>Now assume that you handle that with correct priorities for IO and CPU scheduling.... the next bottleneck will be keeping up w&#x2F; background tasks.<p>So then you start to add more threads. but as you mentioned and what I tried to highligiht in that article was that the cost of implicit or simple synchronization is very expensive (as noted by you intuition)<p>The thread-per-core buffer management with defer destructors is really handy at doing 3 things explicitly<p>1. your cross core communication is <i>explicit</i> - that is you give it shares as part of a quota so that you understand how your system priorities are working across the system for any kind of workload. This is helpful to prioritize foreground and background work.<p>2. there is effectively a const memory addresses once you parse it - so you treat it is largely immutable and you can add hooks (say crash if modified on a remote core)<p>3. makes memory accounting fast. i.e.: instead of pushing a global barrier for the allocator you simply send a message back to the originating core for allocator accounting. This becomes hugely important as you start to increase the number of cores.')