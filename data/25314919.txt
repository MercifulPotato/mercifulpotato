Item(by='qsort', descendants=None, kids=[25315129, 25315398], score=None, time=1607179751, title=None, item_type='comment', url=None, parent=25314788, text='Playing the devil&#x27;s advocate here, I&#x27;m with you that half of AI ethics is obvious and the other half is wrong, but is&#x27;t it the goal of the field to try and give meaning to things that aren&#x27;t obviously well defined?<p>To make an example that&#x27;s <i>en vogue</i> right now, AI explainability. Nobody even has a definition of what it means for a model to be explainable (is a linear regression &quot;more explainable&quot; than ML? isn&#x27;t Google search far <i>less</i> explainable than any model of anything ever?), but a reasonable framework for that concept could certainly be interesting.<p>Obviously, serious frameworks are done with definitions and math, not with words and storytelling, but all the air around those things seems to me more the fault of politicians, crap journalists and freaking idiots on social media (the current term is &#x27;influencer&#x27;, I reckon) rather than an issue with the field itself.')