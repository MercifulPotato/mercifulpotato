Item(by='dragontamer', descendants=None, kids=[25258652, 25260992, 25258490], score=None, time=1606767090, title=None, item_type='comment', url=None, parent=25258236, text='&gt; Moving high bandwidth RAM<p>Its just LPDDR4. HBM is a different thing. You can tell because HBM has 1024-bits bus per chip, but LPDDR4 is just 128-bits per chip.<p>There&#x27;s almost nothing special about the RAM, aside from it being locked to the chip and unable to be upgraded. It seems like the clockrate to the LPDDR4 is a bit higher than average, but its nothing extravagant.<p>&gt; How do they manage even larger amounts of RAM? Perhaps they will have external RAM in addition to the on chip RAM, with perhaps 32GB of onboard memory and the external RAM being used as swap? This takes a bit away from the super-efficient design they have currently.<p>They COULD just support a DIMM stick like everyone else. But Apple doesn&#x27;t want to do that strategy and prefers packaging the RAM and CPU together for higher prices.<p>This isn&#x27;t a 1024-bit bus (that requires 1024 wires, usually an interposer). This is just your standard 128-bit LPDDR4, maybe at a slightly higher clockrate than others for a slight advantage in memory.<p>------<p>In case of HBM2, you can&#x27;t upgrade RAM beyond one-stack per 1024-bit bus. A GPU goes 4x wide with 4x 1024-bit busses to 4x different HBM2 stacks for a massive 4096-pin layout (!!!), that&#x27;s 4096 wires connecting a GPU to individual HBM2 chips.<p>Hypothetically, a future GPU might go 6-stacks or 8-stacks (8192-wires), but obviously running all those wires gets more-and-more complex the bigger you go. So in practice, GPUs seem to be ~4-stacks, and then you just buy a new GPU and run the entire GPU in parallel when you need more RAM.<p>&gt; &gt; Moving high bandwidth RAM to be shared between the CPU &amp; GPU<p>That&#x27;s not the advantage. When the L3 cache is connected between CPU and GPU, you gain a bandwidth edge in heterogenous systems. AMD &#x2F; Intel have been connecting L3 caches to their iGPU solutions for over a decade now.<p>CPU - to DDR4 - to GPU is very slow compared to CPU - to L3 cache - to GPU. Keeping the iGPU and CPU memory-cohesive is a nifty trick, but is kind of standard at this point.')