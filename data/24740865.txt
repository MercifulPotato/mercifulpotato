Item(by='he11ow', descendants=None, kids=None, score=None, time=1602354734, title=None, item_type='comment', url=None, parent=24738447, text='Contrarian Opinion: It doesn&#x27;t matter one bit.<p>Take a walk down any science museum, and you see a consistent pattern in technology development: people will push an existing technology to its absolute extreme before they come up with the next clever step.<p>That&#x27;s GPT-3. It&#x27;s no holy grail.<p>I find work of the kind that Hugging Face are doing much more interesting, because they are trying to move forward. Their approach is trying to overcome two stumbling blocks for which GPT-3 has no answer: \nOne, that  useful language is domain-specific (in the sense that, beyond the written words, it presupposes a familiarity with a world of context). \nAnd two, that the way forward is not going big, it&#x27;s going small. In practically every aspect of historical technology development, the vector for improvement was towards being able to do more with less.<p>These are not the only problem GPT has. Other potholes include its blindness to text structure. This includes logic, and also why it has this rambling incoherent style.<p>So to me, GPT-3 never really crosses over from an academic curio to something that allows us to do something we&#x27;ve not done before. Can it somehow be used to sell EVEN MORE ads? Possibly. Hoorah.<p>But it&#x27;s not really the milestone the Open AI would like you to believe.<p>(However, if anyone can package Elon Musk&#x27;s capacity to spin...)')