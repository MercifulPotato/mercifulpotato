Item(by='jcranmer', descendants=None, kids=[25206351], score=None, time=1606258178, title=None, item_type='comment', url=None, parent=25203599, text='Superoptimization looks mainly at peephole optimizations. This is looking at small fragments of code, where you&#x27;re trying to shave off one or two cycles. STOKE (which is the superoptimizer I alluded to in my comment) scales to dozens of instructions, and still requires loop-free code (because SMT solvers don&#x27;t handle loops at all), and I&#x27;m not sure it handles branch cases more complicated than nested if-else [1].<p>The correctness oracles we need for superoptimization requires use of formal methods; basically SMT libraries these days. And modern SMT libraries tend to barely work when you deal with division (and remainder) operations, or if you use floating-point code [2].<p>So, essentially, the size of the programs that you <i>can</i> apply to this code generally means you can get away with ignoring these issues for such codes. The biggest exception is branch prediction, where a cmov is better than a branch if and only if the condition is unpredictable.<p>&gt; Also, wouldn&#x27;t thermals-based clock throttling be a factor as well, assuming that we&#x27;re talking about wall-clock performance instead of clock-cycles performance?<p>Clock cycle performance will largely be monotonic in wall-clock performance, especially at the level of peephole optimization. You&#x27;re not adjusting the amount of memory traffic, or other microarchitectural state significantly. The difference in energy between using a shift instruction versus a multiply versus an add isn&#x27;t going to cause enough thermal difference to throttle the fans. In order to really increase energy usage enough to change frequency, you&#x27;d have to go from unvectorized code to using largest register width, and that just isn&#x27;t going to happen in a superoptimizer--your loop and SLP vectorizer will be the one to change that. And once you&#x27;ve triggered the AVX-512-heavy frequency level, you&#x27;re <i>still</i> going to want to use the variant of that that uses fewer clock cycles anyways.<p>[1] It might work based on enumerating every path via path conditions, which could handle threaded jumps, but means complexity is roughly exponential in the number of conditions. Given that we&#x27;re not really pushing hundreds of instructions yet, that means that branching has to be <i>very</i> minimal in anything our current engines can work with.<p>[2] The typical approach here I believe is uninterpreted functions, so that SMT is largely only capable of applying the commutativity, associativity, distributivity, and other axioms you put into it.')