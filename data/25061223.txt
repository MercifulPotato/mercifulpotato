Item(by='danieldk', descendants=None, kids=[25062667], score=None, time=1605119504, title=None, item_type='comment', url=None, parent=25060965, text='<i>Eventually, it hit end of life and became AOCL [2]. I&#x27;ve not tried it, but I&#x27;m sure it&#x27;s fine.</i><p>It&#x27;s ok. I did some experiments with transformer networks using libtorch. The numbers on a Ryzen 3700X were (sentences per second, 4 threads):<p>OpenBLAS: 83,\nBLIS: 69,\nAMD BLIS: 80,\nMKL: 119<p>On a Xeon Gold 6138:<p>OpenBLAS: 88,\nBLIS: 52,\nAMD BLIS: 59,\nMKL: 128<p>OpenBLAS was faster than AMD BLIS. But MKL beats everyone else by a wide margin because it has a special batched GEMM operation. Not only do they have very optimized kernels, they actively participate in the various ecosystems (such as PyTorch) and provide specialized implementations.<p>AMD is doing well with hardware, but it&#x27;s surprising how much they drop the ball with ROCm and the CPU software ecosystem. (Of course, they are doing great work with open sourcing GPU drivers, AMDVLK, etc.)')