Item(by='magusdei', descendants=None, kids=None, score=None, time=1602374978, title=None, item_type='comment', url=None, parent=24740807, text='I&#x27;ve actually done this experiment by putting a GPT-3 bot in a Telegram group. Its replies were mostly stuck in an uncanny valley where they sort of made sense, but often either lacked detail or seemed to very slightly misunderstand what the topic of discussion was. This might have been just because I didn&#x27;t include enough context in the prompt, however. I have some plans for improving the prompting strategy, so we&#x27;ll see.<p>I actually recently wrote a post on the topic of whether GPT-3 can be said to understand anything[1]. The argument is a bit too long to summarize here, but I don&#x27;t think what GPT-3 is doing is as fundamentally different from what human brains do as people seem to think.<p>[1] <a href="https:&#x2F;&#x2F;magusdei.com&#x2F;why-gpt3-can-understand-things.html" rel="nofollow">https:&#x2F;&#x2F;magusdei.com&#x2F;why-gpt3-can-understand-things.html</a>')