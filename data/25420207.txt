Item(by='matthewdgreen', descendants=None, kids=[25422540, 25421437, 25421754, 25422118, 25421130], score=None, time=1607966564, title=None, item_type='comment', url=None, parent=25420074, text='Two more likely possibilities: (1) Pornhub wasn&#x27;t really checking, which is an easy way to get good stats.* (2) Many of Facebook&#x27;s 84 million incidents took place on private groups or Messenger chats with small numbers of participants, whereas a single PornHub upload (counted as &quot;1 incident&quot;) could easily reach hundreds of thousands of people. Fundamentally difficult to compare private communications networks with broadcast systems, they provide different opportunities for problematic content.<p>* ETA: Facebook is an industry leader on CSAM scanning, and has developed both its own algorithms and media databases. So your comment that &quot;Facebook isn&#x27;t taking the issue seriously&quot; seems like exactly the wrong diagnosis. Facebook&#x27;s high numbers are a consequence of putting serious effort into this area. (Whether scanning of private messages is actually effective in stopping distribution of the content, that&#x27;s something I&#x27;m more skeptical of.)')