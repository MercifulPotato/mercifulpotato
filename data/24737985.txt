Item(by='jlokier', descendants=None, kids=[24739474], score=None, time=1602326029, title=None, item_type='comment', url=None, parent=24737261, text='Looking at the video, on the one hand, I can see why that could be a sort of public service against the most egregious of brutal policing.<p>On the other hand... that AI&#x2F;ML looks like it has <i>immense potential for wrongful identification</i>.<p>&quot;AI hallucinating&quot; the wrong person&#x27;s face into the scene using totally convincing feature interpolation.<p>In a high stakes scene where people feel the need to fight back, it&#x27;s not hard to imagine such false positives ruining an innocent person&#x27;s life.<p>Edit: If the other comment about people being <i>killed</i> as a result of identification videos is true, &quot;ruining&quot; only scratches the surface.  Getting people killed due to an algorithm false positive would be a terrible thing to facilitate.  We are talking about an algorithm where the &quot;recognise face&quot; part is known to make errors as well as subject to many kinds of bias (and that&#x27;s even without a mask); and the &quot;project the face into the video part&quot; is optimised for making the most convincing deep fakes.  Especially in the most high stakes scenes, somebody will inevitably convince themselves or others that the interpolated face is really the person who was there behind that mask.  Heck, even experts misjudge pattern-matching evidence: <a href="https:&#x2F;&#x2F;www.cebm.ox.ac.uk&#x2F;news&#x2F;views&#x2F;the-prosecutors-fallacy" rel="nofollow">https:&#x2F;&#x2F;www.cebm.ox.ac.uk&#x2F;news&#x2F;views&#x2F;the-prosecutors-fallacy</a> &quot;The Prosecutorâ€™s Fallacy is most often associated with miscarriages of justice.&quot;')