Item(by='gruez', descendants=None, kids=None, score=None, time=1608041681, title=None, item_type='comment', url=None, parent=25429848, text='&gt;My big question is how much resolution you can get out of things like canvas finger printing and WebGL (or even sheer JS speed). Those are places where the analog reality underlying everything we develop on may peek through unless explicit (and inherently performance reducing) measures are taken.<p>I&#x27;m not sure how the &quot;analog reality&quot; applies here. The CPUs and GPUs generate discrete results, and behave identically two other chips of the same model. You talked about variations in performance, but is there evidence that apple does this with iphones? They could very well running them at lower clocks than what they&#x27;re capable of, ie. the chips come out of the fab being able to run at 1.6-1.8ghz, but apple runs all of them at 1.6ghz. Finally, even if the performance variation is there, the difference will have to be big enough that it doesn&#x27;t get drowned out in the noise or other environmental variations. A phone that has been in a pocket would perform worse than one that&#x27;s been sitting on a desk, because it&#x27;s probably 10 degrees warmer, which means 10 less degrees of thermal headroom.<p>&gt;I don&#x27;t disagree that the relatively small (and undoubtedly skewed from the general population) size of the EFF&#x27;s overall dataset is a limit for them, but &quot;I have no idea but it seems fishy because my iPhone should be identical because I say so&quot; isn&#x27;t an analysis.<p>But the eff site tells you exactly what they&#x27;re fingerprinting, and they&#x27;re not fingerprinting performance. What you described might be possible, but is irrelevant to the discussion.')