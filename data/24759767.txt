Item(by='XCSme', descendants=None, kids=[24763653], score=None, time=1602539014, title=None, item_type='comment', url=None, parent=24759684, text='Hi,<p>Thank you! It was not hard to work on it for so long, time flies, and I only worked on it as a side-project for a long time. Most of the work was responding to support queries and talking to customers. The good thing when you do something over a long period of time is that you have lots of time to get good ideas and change&#x2F;rethink parts of the product.<p>I personally don&#x27;t have any site that gets millions of users per month, but there are some customers using userTrack for around 300k sessions&#x2F;month. That being said, I think of userTrack as a solution for small and medium businesses, not really something for huge enterprises that probably already have dedicated analytics teams and expensive software stacks.<p>&gt; Do you have any experience handling millions of traffic?<p>I do have some experience with handling heavy traffic, not from userTrack, but from working on a multiplayer browser game with 300k+ monthly users. There we used MongoDB, and the servers handled it pretty well without huge focus on performance or scaling.<p>&gt; from my experience MYSQL is very slow performing aggregated queries on those datasets<p>From what I&#x27;ve seen so far, MySQL is really fast if the queries are done right. If everything has an index and most of the results are filtered, then most queries run without any performance issues, even if the database gets bigger (talking about several or tens of GBs, not about terra-bytes).<p>I am curious what was your bottle-neck with those queries and how the aggregation was being done. Did you run the queries with EXPLAIN to see why they were slow?')