Item(by='fennecfoxen', descendants=None, kids=[24987108], score=None, time=1604468492, title=None, item_type='comment', url=None, parent=24986195, text='Let&#x27;s see.<p>According to <a href="https:&#x2F;&#x2F;bdtechtalks.com&#x2F;2020&#x2F;09&#x2F;21&#x2F;gpt-3-economy-business-model&#x2F;" rel="nofollow">https:&#x2F;&#x2F;bdtechtalks.com&#x2F;2020&#x2F;09&#x2F;21&#x2F;gpt-3-economy-business-mo...</a> GPT-3 was run on V100s, which are the previous generation server GPUs (&quot;Volta&quot; vs &quot;Ampere&quot;).<p>&quot;GPT-3 uses half-precision floating-point variables at 16 bits per parameter... At around $130,000, DGX-1 is short on VRAM (8Ã—16 GB), but has all the other components for a solid performance on GPT-3.&quot;  (DGX-1 is the previous chassis NVIDIA offered for hosting V100s.)<p>So I tentatively think the answer is yes, a single DGX-A100 probably can run GPT-3 comfortably. You&#x27;ll still want a cluster of them to train it, though, because they note training takes about 355 V100-years.')