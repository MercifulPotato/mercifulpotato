Item(by='arc619', descendants=None, kids=None, score=None, time=1607287902, title=None, item_type='comment', url=None, parent=25321002, text='Yes, if the target is C++ then the whole output will be in C++, including code for GC operations, so you can directly inspect how this is translated. You can actually choose between several GCs for different needs: <a href="https:&#x2F;&#x2F;nim-lang.org&#x2F;docs&#x2F;gc.html" rel="nofollow">https:&#x2F;&#x2F;nim-lang.org&#x2F;docs&#x2F;gc.html</a><p>It&#x27;s worth mentioning that by default all types in Nim are stack allocated, and you have full manual memory management to the same level as C&#x2F;C++ but with better type safety and less boilerplate. The GC is only used when you tag a type as `ref`, in strings, and the &#x27;vector&#x27; dynamic list type, `seq`.<p>The newer GC, ARC (not related to Swift&#x27;s ARC), is similar to RAII - scope based, non-atomic, deterministic, shares memory between threads but not stop-the-world, and uses move semantics: <a href="https:&#x2F;&#x2F;nim-lang.org&#x2F;docs&#x2F;destructors.html" rel="nofollow">https:&#x2F;&#x2F;nim-lang.org&#x2F;docs&#x2F;destructors.html</a><p>This makes the GC a nice to use addition for resource management but not a fundamental requirement or speed limitation.<p>In my experience the default (thread-local refc + cycle collection) GC is very performant already, but it&#x27;s straightforward to write code that works entirely on the stack, or create objects that wrap manual heap allocs, or use custom external memory allocators. Passing `--gc:none` removes the GC entirely from the compilation target, for example if you&#x27;re working with very constrained embedded devices with the caveat that less of the stdlib is available (currently).<p>The ARC GC (doesn&#x27;t handle cycles unlike it&#x27;s sibling ORC) is aiming to be lean enough to be used in hard realtime and memory constrained embedded systems. For hard realtime though I&#x27;d expect most people would just manually manage their types anyway on the heap or stack.<p>If you&#x27;re doing interop between Nim and C++ and want Nim&#x27;s GC to manage types that you&#x27;re passing directly to pure C++ code, you can tell the GC that the data is still being used with GC_Ref() or not with GC_Unref(). There are a few libraries for C&#x2F;C++ interop, such as: <a href="https:&#x2F;&#x2F;github.com&#x2F;nimterop&#x2F;nimterop" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;nimterop&#x2F;nimterop</a><p>Personally in this case I would probably just manually allocate memory memory in Nim or C++ and not use GC&#x27;d types across boundaries for clarity if nothing else, still it&#x27;s an option if your design requires it.<p>Finally, there is a tool to help auto-translate C&#x2F;C++ to Nim with the c2nim tool: <a href="https:&#x2F;&#x2F;github.com&#x2F;nim-lang&#x2F;c2nim" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;nim-lang&#x2F;c2nim</a> and docs: <a href="https:&#x2F;&#x2F;github.com&#x2F;nim-lang&#x2F;c2nim&#x2F;blob&#x2F;master&#x2F;doc&#x2F;c2nim.rst" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;nim-lang&#x2F;c2nim&#x2F;blob&#x2F;master&#x2F;doc&#x2F;c2nim.rst</a>')