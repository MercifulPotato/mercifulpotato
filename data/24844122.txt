Item(by='Reelin', descendants=None, kids=None, score=None, time=1603244938, title=None, item_type='comment', url=None, parent=24843494, text='Yeah, without the ability to query a particular identity it&#x27;s not clear (to say the least) how you would go about filtering out malicious identities.<p>To some extent, identity politics based on public associations is an unavoidable problem. Public data can be scraped so someone is probably going to aggregate and analyze it at some point.<p>That said, it seems important that a reputation system not facilitate making associations that otherwise wouldn&#x27;t have been visible. To that end, it&#x27;s important to take care not to accidentally incentivize community moderators to leak information that otherwise wouldn&#x27;t have been discoverable by the general public.<p>In particular, it occurs to me that a naive reporting mechanism inherently reveals that the reported identity has associated with the reporting operator. I assume you&#x27;ve given this problem some thought - is there an obvious way around it? My concern would be that a more general use reputation system (ie one that goes beyond simple &quot;illegal content&quot; and &quot;spam&quot; event reports) would rapidly begin leaking association data on a broad scale, even from otherwise private communities.<p>I guess the goals here are at odds in a fundamental way. A server should be able to report scores for it&#x27;s participants. Querying an identity should reveal it&#x27;s various scores. Now repeat spammers (or those posting illegal content, or who are just generally assholes, or whatever) can be filtered out. But in being able to query scores for an identity I don&#x27;t see how you can avoid revealing the entity that reported any given score. If a broad set of categories are being reported (consider, for example, the birthday cake example from the article) then the information leakage seems like it would end up being quite broad.')