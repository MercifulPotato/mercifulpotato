Item(by='dragontamer', descendants=None, kids=[24886969], score=None, time=1603636467, title=None, item_type='comment', url=None, parent=24886539, text='&gt; The OS would have to search around for free areas and keep track of them to be able to give memory out.<p>I don&#x27;t think fragmentation is the issue.<p>The OS doesn&#x27;t search the page tables. The __CPU__ does, EVERY single time any program does a memory lookup (load&#x2F;store operation), the CPU may have to traverse the page table. Page-table entries are often cached in the TLB-cache, but if the cache is full, a full table-traversal is necessary.<p>Its clear that page-tables are optimized for minimum latency: so that the smallest area of the CPU can be used, and the simplest hardware can implement the page-lookup procedure.<p>&quot;blah = blah-&gt;next&quot; is a very common pattern in programming. Since the page-table implementation in the CPU can speed this operation up (or slow it down), its extremely important to optimize for absolute fastest latency.<p>-----<p>A lot of stuff goes on with &quot;blah = blah-&gt;next&quot;. If blah-&gt;next is outside the TLB cache, the CPU will have to jump to the page-table, traverse the 1st, 2nd, and 3rd levels of paging (looking for the physical location of blah-&gt;next).<p>A &quot;variable length page&quot; would complicate this lookup severely: the CPU wouldn&#x27;t know which offset to lookup pages, and your non-TLB pages will be much much slower as a result.<p>x86 &quot;huge pages&quot; are based on only searching one (1GB) or two (2MB) layers of the page-lookup procedure, instead of all three (going down to 4kB pages). That&#x27;s how you get support for other sizes without variable-length entries in the page tables &#x2F; page directory table &#x2F; etc. etc.')