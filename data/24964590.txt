Item(by='barrkel', descendants=None, kids=None, score=None, time=1604287895, title=None, item_type='comment', url=None, parent=24964480, text='Funny thing about debuggers is that they seem to encourage stepping - step in, step out, step over, single step, step to return.<p>Stepping is an enormous waste of time with a debugger.<p>Breakpoints are where it&#x27;s at. Level up your breakpoints: logging breakpoints, conditional breakpoints, memory breakpoints (super handy when combined with deterministic memory allocation), syscall &#x2F; library breakpoints - and soon you&#x27;re going somewhere useful.<p>Debugging is about formulating theories and proving them wrong, or right. Stepping doesn&#x27;t scale; breakpoints can scale, if you know where to put them.<p>I&#x27;m not sure that the gap between a debugger with breakpoints, and printfs in source, is that large, though. It&#x27;s easier to write complex conditionals or log the state of a complex predicate in the source language than in whatever the debugger gives you - even if it gives you the native language, you typically have to write it all on a single line. And you need to dive deep into the source to understand where to put those breakpoints - or printfs.<p>An underused debugging tool is an instrumenting profiler. The captured call graph is a useful clue for dynamic &amp; indirect control flow in particular, without needing to decipher it from stepping or infer it from chasing source references and indirections. Things like generic message dispatchers and event callbacks are horrible to try and step through and aren&#x27;t much better when eyeballing the source.')