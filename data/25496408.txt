Item(by='analog31', descendants=None, kids=[25506512], score=None, time=1608568240, title=None, item_type='comment', url=None, parent=25495907, text='I do some optics design. The Lytro was exciting. Reinforcing what you say, when a light ray hits a pixel on a conventional sensor, the sensor only knows where the pixel is located on the sensor. Ensuring that each pixel corresponds to a specific location in the scene being photographed is the lens design problem in a nutshell.<p>But a ray has both a position and a direction vector. If you can measure the complete ray vector -- its position and direction at the same time, then you can compute where it came from, even if the lens is not perfectly designed. The light field sensor relaxes the lens design problem considerably.<p>An earlier technology called a Shack-Hartmann sensor, similarly measures the full light field at once. It&#x27;s used for things like measuring the wavefront quality of lasers.<p>There is still a problem, which is that you have to assign a physical sensor pixel to each point in a 4-d space (2 position and 2 direction coordinates), which means that you have to give up some of the spatial resolution of the sensor. This makes it hard to compete in a market that is clamoring for more and more megapixels. Instead, the sales pitch has to be more nuanced, as in comparing the actual image quality of the pictures, which is a harder sell when the quality of pictures from cell phone cameras is pretty damn good.')