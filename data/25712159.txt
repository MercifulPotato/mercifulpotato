Item(by='Barrin92', descendants=None, kids=[25713342], score=None, time=1610265817, title=None, item_type='comment', url=None, parent=25710182, text='That doesn&#x27;t follow it all. Sentience concerns an internal state of mind, and we simply do not know if simulating the behaviour of sentient organisms requires underlying sentience. It even seems unintuitive because me not being able to distinguish Stockfish from Magnus Carlsen doesn&#x27;t imply that Stockfish experiences chess the same way he does.<p>A more accurate conclusion is that, if I can&#x27;t tell the difference precaution dictates that <i>I treat the robot as if it were sentient</i>, just in case it is, but it by no means follows from observation alone. Just because my cat thinks the laser pointer is alive, doesn&#x27;t mean it is. And like cats, humans are likely to be way too easily fooled by fairly simple systems that just emulate external behaviour. Story comes to mind of soldiers developing trauma after seeing bomb defusing robot spiders flail around.<p><i>&quot;Every time it found a mine, blew it up and lost a limb, it picked itself up and readjusted to move forward on its remaining legs, continuing to clear a path through the minefield. Finally it was down to one leg. Still, it pulled itself forward. Tilden was ecstatic. The machine was working splendidly. The human in command of the exercise, however -- an Army colonel -- blew a fuse. The colonel ordered the test stopped. Why? asked Tilden. What&#x27;s wrong? The colonel just could not stand the pathos of watching the burned, scarred and crippled machine drag itself forward on its last leg. This test, he charged, was inhumane.&quot;</i><p><a href="https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;wp-dyn&#x2F;content&#x2F;article&#x2F;2007&#x2F;05&#x2F;05&#x2F;AR2007050501009.html" rel="nofollow">https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;wp-dyn&#x2F;content&#x2F;article&#x2F;2007&#x2F;0...</a>')