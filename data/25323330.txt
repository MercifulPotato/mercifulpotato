Item(by='danieldk', descendants=None, kids=None, score=None, time=1607260929, title=None, item_type='comment', url=None, parent=25317655, text='So far, of the models that run on GPUs with 8-16GiB VRAM XLM-RoBERTa has been the best for these specific tasks. It worked better than the multi-lingual BERT model and language-specific BERT models by quite a wide margin.')