Item(by='1337shadow', descendants=None, kids=None, score=None, time=1611851338, title=None, item_type='comment', url=None, parent=25943771, text='I&#x27;ve come to this conclusion because all the other arguments come weak in my opinion, as such the only upside remaining for GitHub is that it&#x27;s free to use, based on what I wrote.<p>As for user friendliness I prefer gitlab but I get your point, UX would be a bit better for certain types of users in GitHub but a bit better for other types of users in GitLab.<p>I do understand your point about bandwidth, because in Europe we get great, cheap, unmetered bandwidth, which is something that I don&#x27;t ever see on american providers on cheap servers, even on oneprovider.com, but on scaleway you do get unmetered bandwidth from 200 to 500 Mbit&#x2F;s for 7.20â‚¬&#x2F;month here <a href="https:&#x2F;&#x2F;www.scaleway.com&#x2F;en&#x2F;virtual-instances&#x2F;development&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.scaleway.com&#x2F;en&#x2F;virtual-instances&#x2F;development&#x2F;</a> however, this small instance might not run gitlab really well, you should go for Gitea if you were to self host a git server on this server. Anyway, I mean that I get that Americans and Europeans don&#x27;t have the same relation with bandwidth.<p>So of course, everything is going to depend on many external factors. YMMV for sure, but just for the sake of the example I have tried cloning curl from both github.com and my gitlab server: it&#x27;s 1m52.233s vs 1m30.256s that&#x27;s probably a 20% difference. It&#x27;s true that GitHub has made a lot of efforts to improve speed because it used to be a lot worse.<p>For you 20% might not be a lot, or even meaningless, but I really spend a lot of time pushing and pulling across a bunch of repos, say 30 minutes a day 22.5 days a month, that&#x27;s 135 minutes I make a month, considering I spend around two times 10 minutes per months running the server upgrade, I&#x27;m left with a benefit of 115 minutes per months, that&#x27;s 23 hours a year: a complete day, and 9.6 days after 10 years ... sorry, I would understand this seems far fetched to you, I plead guilty to being the kind that optimizes this kind of things on the long term, a Lean Sensei.<p>BUT, I have paid for my server, so really, that&#x27;d be the only downside from my POV.<p>As for the git usage of the curl project, what I got from github insights is, for the last 24h: Excluding merges, 2 authors have pushed 5 commits to master and 5 commits to all branches. On master, 7 files have changed and there have been 153 additions and 38 deletions.<p>I don&#x27;t &#x2F;feel&#x2F; like they&#x27;d be saturating 100Mbps.<p>And there&#x27;s also self hosted CI, I just can&#x27;t live with non-dedicated CI hardware, can&#x27;t wait, can&#x27;t stand even paid hosted CI, too slow, and my devs also love that CI just instantly &quot;jumps&quot; on their patches to start crunching them. Because CI is on a simple dedicated server, docker cache also just works without the network bottleneck. But then again, keep in mind I&#x27;m not talking about &quot;big corporate setups&quot; here, if you have hundreds of devs then it&#x27;s not the same story.')