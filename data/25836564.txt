Item(by='hansvm', descendants=None, kids=[25836633], score=None, time=1611079870, title=None, item_type='comment', url=None, parent=25835543, text='Floating point multiplication and division are generally much safer in terms of precision loss than addition or subtraction, and on the flip side you could easily be more than a penny off with zero operations if the quantities involved were large enough.<p>Quibbles aside, they&#x27;re not suggesting doing accounting with floats. E.g., suppose you want to estimate the expected value of an option. You&#x27;ll have a model that attempts to describe that option&#x27;s behavior (e.g. Black Scholes), and you want to evaluate that model with a certain set of parameters. The model itself is imperfect, and given the transcendentals involved even if it were flawless there would be a guaranteed loss of precision when attempting to clamp a real option to its predicted expected value. The model is a tool that guides decisions, but nobody really cares if it&#x27;s off by a little bit because there are a ton of other error sources anyway. 1 in 10^14 is more than good enough.<p>Edit: Unless you&#x27;re just suggesting that people should do a little numerical analysis and be cognizant of the total error in a model?')