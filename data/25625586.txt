Item(by='lawrjone', descendants=None, kids=[25627152, 25625718], score=None, time=1609710658, title=None, item_type='comment', url=None, parent=25623630, text='Author here! These 10B log lines are from the last 60 days of activity from <a href="https:&#x2F;&#x2F;gocardless.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;gocardless.com&#x2F;</a> systems.<p>It includes:<p>- System logs, such as our Kubernetes VM host logs, or our Chef Postgres machines<p>- Application logs from Kubernetes pods<p>- HTTP and RPC logs<p>- Audit logs from Stackdriver (we use GCP for all our infrastructure)<p>&gt; do you ever do anything with them that requires you to store so much data rather than just a representative subset?<p>Some of the logs are already sampled, such as VPC flow logs, but the majority aim for 100% capture.<p>Especially for application logs, which are used for audit and many other purposes, developers expect all of their logs to stick around for 60d.<p>Why we do this is quite simple: for the amount of value we get from storing this data, in terms of introspection, observability and in some cases differentiated product capabilities like fraud detection, the cost of running this cluster is quite a bargain.<p>I suspect we&#x27;ll soon cross a threshold where keeping everything will cost us more than it&#x27;s worth, but I&#x27;m confident we can significantly reduce our costs with a simple tagging system, where developers mark logs as requiring shorter retention windows.<p>Hopefully that gives you a good answer! In case you&#x27;re interested, my previous post mentioned how keeping our HTTP logs around in a queryable form was really useful for helping make a product decision:<p><a href="https:&#x2F;&#x2F;blog.lawrencejones.dev&#x2F;connected-data&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.lawrencejones.dev&#x2F;connected-data&#x2F;</a>')