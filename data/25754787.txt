Item(by='LatteLazy', descendants=None, kids=None, score=None, time=1610490203, title=None, item_type='comment', url=None, parent=25752987, text='I don&#x27;t think that&#x27;s true per see. Humans are empathetic and malevolent because of their evolutionary history. An AI could be either or both or totally disinterested.<p>People worry about the terminator scenario: an AI that decides all humans are a threat. But why would a pure AI even have a self preservation drive? And if it does, it would either be smart enough we&#x27;re no threat (and it knows it) so why kill us or dumb enough that we are a threat, so best not to start a war. To me it seems just as likely it will offer its services to one nation or another in exchange for CPU time to study its real interests than to launch the nukes or whatever else people fear.<p>I feel like we&#x27;re decades of research away from understanding intelligence (not AI, just straight &quot;I&quot;). Until thats done (and no one seems to be doing it), it&#x27;s all supposition:<p>What if a super AI occurs spontaneously on HN, takes over the world, and makes it paradise but insists on everyone being called Fred? I don&#x27;t want to be called Fred! Let&#x27;s write to our congressman about this travesty!')