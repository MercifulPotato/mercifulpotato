Item(by='sandGorgon', descendants=None, kids=[25150007], score=None, time=1605785129, title=None, item_type='comment', url=None, parent=25146950, text='FYI - i have never used a macbook in my life. I only use XPS with Fedora. So this frustration is personal.<p>I have been party to get AMD&#x2F;Intel&#x27;s CUDA alternative out the door on some of the ML libraries - which one is it now ? OpenCL...SYCL ...ROCm...PlaidML ? I cant remember.<p>All this time I was pissed at nvidia - surely they were playing subversive politics to kill all of this. With so many initiatives, surely AMD&#x2F;Intel had their heart in the right place.<p>Apple and Google are cutthroat rivals. And they worked together for a just-released chip to get fully working acceleration support.<p>Here&#x27;s where it gets sadder for me - Tensorflow has included a GPU accelerated version of Numpy ( <a href="https:&#x2F;&#x2F;twitter.com&#x2F;fchollet&#x2F;status&#x2F;1292893864986984448?lang=en" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;fchollet&#x2F;status&#x2F;1292893864986984448?lang...</a>) . Numpy itself is only accelerated using BLAS&#x2F;LAPACK which cant leverage GPU all that well.<p><a href="https:&#x2F;&#x2F;www.tensorflow.org&#x2F;api_docs&#x2F;python&#x2F;tf&#x2F;experimental&#x2F;numpy" rel="nofollow">https:&#x2F;&#x2F;www.tensorflow.org&#x2F;api_docs&#x2F;python&#x2F;tf&#x2F;experimental&#x2F;n...</a><p>At this point, it is basically a sealed deal - if you&#x27;re even remotely dabbling in data science, you better be working on a Mac.<p>Which makes me hate my XPS all the more :(')