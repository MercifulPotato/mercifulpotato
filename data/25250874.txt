Item(by='blululu', descendants=None, kids=[25251446, 25251210, 25251766, 25253963], score=None, time=1606712336, title=None, item_type='comment', url=None, parent=25250768, text='The loan example comes up a lot but I&#x27;m not sure why. We already use machine learning to evaluate credit ratings in the US. It is not always a fair system but it is standard practice and nobody asks why they are turned down for a loan or demands to know how the system works (this information is proprietary and banks would claim their algorithms are a trade secret since a better algorithm gives them an edge on pricing loans).<p>&gt;&gt;You&#x27;d want the reason your application was not granted to be something reasonable (like a poor credit history) and not something like &quot;the particular combination of inputs triggered some weird path and rejected you offhand.&quot;<p>This is a low dimensional bias. If there is increased risk of default from high A &amp; B &amp; C &amp; D but not high A or high B or high C or high D, then the combination or parameters is what matters even if it is not easy to explain. Typically in a high dimensional space most of the volume is far from the axes so it is unlikely that things will line up along some preconceived set of inputs. As it is &#x27;poor credit history&#x27; is in fact an index that amalgamates a large number of different parameters so I&#x27;m not sure if that really explains why the loan was rejected or simply gives a simple name for a complicated thing.<p>In general yes, it is good to thoroughly debug any ML algorithm and make sure that is is doing roughy what you think that it is doing. A lot of times this process can be quite complicated and relies on a lot of intuition &amp; heuristics. While thoroughly testing a ML solution is certainly best practice, I&#x27;m not sure if having a highly skilled researcher conducting an in-depth mathematical analysis of an algorithm would really make it &#x27;interpretable&#x27;.')