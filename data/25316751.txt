Item(by='bisectable', descendants=None, kids=None, score=None, time=1607191756, title=None, item_type='comment', url=None, parent=25315215, text='You&#x27;ve worked with a visual appearances dataset, lacking sufficient examples from one class of entities, and it failed to perform well for that class. You solved the problem by adding more example of that class. While the malfunction might have hd some, as of yet unquantified, real world impact in some hypothetical police face recognition system, it doesn&#x27;t follow that:<p>a. Datasets that are not about visual appearances, are prone to the same problem and to the same degree. Perhaps the house lending datasets &#x2F; systems have small race (visual appearances) issues, but large class issues. The political debate of how to handle class issues is as old as politics have been around.<p>b. The extent of real world impact, which depends on the actual system deployed. Perhaps a hypothetical real world system has a 1% failure rate vs .1% failure rate. Should we stop developing useful system just because they are not produce exactly the same results across all visible demographics we can carve ourselves into?<p>c. Can the impact be mitigated by human post processing. The hypothetical face recognition system is part of the judicial process, there are many checks and balances before one gets to suffer drastic consequences. For example a human actually looking at the picture, or a solid alibi. &quot;Your honor, I was skiing in Canada at the time of the alleged Florida murder&quot;.<p>As others have expressed in this thread, dealing with first order visual issues is easy. everyone can agree at a glance what a correct solution to visual questions is, and bugs are usually straightforward to fix. Language issues on the other hand, are second order, everything is subject to interpretation. Once we open the can of worms of talking &#x27;critically&#x27; about language and AI, we are getting uncomfortably close to language police, and via Shapir Whorf, to thought police. The BIG underlying stake of &#x27;AI Ethics&#x27;, one that possibly neither side has completely articulated just yet:<p>Should a small group (in the thousands) of hyperachieving hyperpriviledged individuals working in the AI labs at the handful of megacorporations controlling the online flow of human language, get to decide what we can speak, and by extension what we can think?')