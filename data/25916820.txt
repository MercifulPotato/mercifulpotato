Item(by='jajool', descendants=None, kids=[25920067, 25921302, 25917568], score=None, time=1611674771, title=None, item_type='comment', url=None, parent=25916222, text='I have seen many PostgreSQL benchmarks having solid performance with TB data but my real world experience is the complete opposite.<p>Here are some of the main issues that I have encountered so far:<p>1. Queries on large tables (around 10 GB) are slow even when &quot;index only scan&quot; is used because of MVCC and the way postgreSQL manages concurrency.<p>2. Hot-standby instances can&#x27;t be used for anything serious since all queries are dropped regularly (I believe it&#x27;s not safe to use &quot;hot_standby_feedback&quot; config to overcome this issue).<p>3. It is not possible to have tables with heavy &quot;update&quot; workflows. (because of simultaneous autovaccum execution)<p>I would be very happy if anyone could show me that I am wrong.')