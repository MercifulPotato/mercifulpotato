Item(by='baaastijn', descendants=None, kids=None, score=None, time=1612186443, title=None, item_type='comment', url=None, parent=25986508, text='Hi there, I work at OVH (product manager data&#x2F;IA) :)<p>In fact we do offer GPUs from multiple ways<p>- Dedicated servers (baremetal) : hidden from the website today, we are refreshing the hardware parts. New ones with GPUs are planned in few weeks.\nBut you will need to buy servers with GPUs for at least 1 one. Good but no so flexible. Not good for AI Training budget imho espect if it&#x27;s 24&#x2F;7 trainings.<p>- Public cloud &#x2F; VMs : like AWS&#x2F;GCP&#x2F;AZure we provide VMs with NVIDIA 1 to 4 x Tesla V100 16GB\nThe good thing is flexibility (pay go hourly)\nThe &quot;bad thing&quot; is about perf when dealing with large dataset, and it also require sysadmin tasks (ssh, dist upgrade, you know it). You&#x27;ll also need tools such as kubeflow to allow a team to work with pipelines, orchestration and debugging tools<p>- (NEW) Public Cloud AI Training : it&#x27;s basically GPU as a service. like paperspace for example.\nYou start a &quot;job&quot; via UI&#x2F;CLI&#x2F;API with 1 to 4 GPUs NVIDIA Tesla V100s, plugged to provided images (notebooks + tensorflow, notebooks &#x2F; pytorch, fastAI, HuggingFace, ...), or you own images (hello docker public&#x2F;private registries).<p>The good thing is : you have full flexibility (you can launch as many jobs as you want), pay per minute, start in 15 seconds.\nNo SSH required, no drivers to install, ...\nAnd one last good thing is the hidden part : specific &quot;cache&quot; storage near the GPUs to play with large datasets (several TBs) without bottlenecks such as latency. It&#x27;s as good a local NVMe storage\nthe bad thing is : nothing :)<p>I&#x27;m not here for hidden advertisement but fuck yeah we have something to propose for GPU :p\nTo find the links or price, everything is public in our website, for a free Voucher just DM me ! \nHave a good day.')