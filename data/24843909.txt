Item(by='machinelearning', descendants=None, kids=None, score=None, time=1603241970, title=None, item_type='comment', url=None, parent=24842250, text='While most people think this &quot;knowledge&quot; should be organized and even shared, I strongly disagree. For context, I have worked in large research labs, ML engineering organizations and startups and have encountered many people across the engineer and research spectrum.<p>These intuitions are often wrong and arise due to the lack of vocabulary in correctly describing the mechanisms that occur.<p>From a researcher&#x27;s standpoint, learning these is counterproductive if the goal is to study and understand the underlying mechanisms from first principles.<p>From a beginner engineer perspective, these intuitions may be effective &quot;functional truths&quot; but there&#x27;s the danger of perceiving these handwavy intuitions as truths. This leads to inflexibility in light of empirical evidence that contradicts these intuitions and even worse - not debugging enough since the pattern seems to match roughly the intuition. The latter results in flawed institutional knowledge being accrued over time. An engineer might say: &quot;Engineer X tried Y and it didn&#x27;t work because of ML intuition Z, since this is a related problem, we should not prioritize Y due to the precedent.&quot;<p>I think its much better for a beginner engineer to learn the methods from first principles and develop an appreciation for them. They can then learn the distinction between what&#x27;s true and the intuitive language people use to describe a phenomenon they don&#x27;t completely understand but can pattern match to. This will help them avoid making the mistakes that people who rely on this intuitive language too much, mistaking it for ML theory.')