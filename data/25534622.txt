Item(by='esc_colon_q', descendants=None, kids=None, score=None, time=1608876423, title=None, item_type='comment', url=None, parent=25530178, text='&gt; IA will also remain quite essential, because for the foreseeable future, computers will not be able to match humans in their ability to reason abstractly about real-world situations.<p>I broadly agree with what this article says, but depending how you define &quot;foreseeable future&quot; I find this to be a dangerously naive viewpoint that just assumes nothing will change quickly.<p>I&#x27;m not stupid enough to say abstract reasoning about the real world is a simple problem or right around the corner, but there&#x27;s no evidence so far to indicate it&#x27;s much further off than, say, object recognition was when Minsky (or more likely Papert, apparently?) assigned it as an undergrad project. We pour exponentially more money into research each year, and have more and better hardware to run it on. We&#x27;re going to hit the ceiling soon re: power consumption, sure, but some libraries are starting to take spiking hardware seriously which will open things up a few orders of magnitude. There are dozens of proposed neural architectures which <i>could</i> do the trick theoretically, they&#x27;re just way too small right now (similar to how useless backprop was when it was invented).<p>Are we a Manhattan Project or three away from it? Sure. That&#x27;s not nothing, but we&#x27;re also pouring <i>so</i> much money into the boring and immediately commercializable parts of the field (all the narrow perception-level and GAN can that NeurIPS is gunked up with) that if any meaningful part of that shifted to the bigger problems, we&#x27;d see much faster progress. That <i>will</i> happen in a massive way once someone does for reasoning what transformers did for text prediction: just show that it&#x27;s tractable.')