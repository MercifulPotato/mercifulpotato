Item(by='throwaway894345', descendants=None, kids=[25422246], score=None, time=1607966241, title=None, item_type='comment', url=None, parent=25418944, text='That&#x27;s not how any real-world algorithms work (and maybe this is exactly your point); rather, <i>provided they learned on a representative sample</i>, they&#x27;d learn that there&#x27;s a 99% chance that a given light-skinned person is a non-citizen (or more likely, that the lighter the skin, the less likely they are to be a citizen--i.e., continuous and not discrete). For a given light-skinned person, they&#x27;d return a confidence of 99% that the person in question is a non-citizen. &quot;Bias&quot; would be a person looking at that confidence interval and misinterpreting it as 100%.<p>Additionally, it&#x27;s problematic because it&#x27;s easily conned--for example, if it&#x27;s used to determine who is eligible to vote (even if we take care not to round the confidence interval up to 100% by classifying 1% of light-skinned people as eligible and 1% of dark-skinned people as ineligible), someone could haul in a bunch of foreigners with dark skin to commit voter fraud. This also isn&#x27;t &quot;algorithmic bias&quot;, but rather foolishness in the application of the algorithm (of course, it&#x27;s impossible to conceive of a legitimate purpose for an algorithm that maps statistically between skin color and citizenship).')