Item(by='vczf', descendants=None, kids=None, score=None, time=1611759737, title=None, item_type='comment', url=None, parent=25927966, text='&gt; That looks overly complicated<p>In practice, it&#x27;s simple enough. I have a backup script that does all the heavy lifting for borg and rsync. Syncthing operates independently in the background, and I rarely log changes with git. The most tedious part of the process is logging new&#x2F;changed&#x2F;deleted files with fim.<p>&gt; Why is there no single tool that can do all of those?<p>Good question, and I totally agree. I was actually looking for a solution that could do deduplicated incremental backups (versioning, like time machine) plus file integrity management. I couldn&#x27;t find one. Nobody seems to care much about file integrity, and nowadays I&#x27;m actually unsure if this is a real problem for anyone except paranoid geeks.<p>Could also use a good frontend GUI that could notify you about changed files, allow you to easily mark directories for different levels of &quot;tracking&quot;, easily browse past versions and restore them, etc. The CLI isn&#x27;t doing any favors here.<p>&gt; I mostly use rsync. Occasionally I destroy my backups by calling it wrongly, like missing a trailing slash. That could not happen if the copying and file integrity checking was combined in one tool<p>Try borg-backup, it&#x27;ll be a massive improvement over plain rsync when it comes to backups.<p>&gt; But it stores the database as json? That is a bad format to store file names. And written in Java it is probably going to be slow (I have over a million files in ~, and multiple copies of it in the backups, so I care a lot about performance)<p>Gzipped json on-disk, but I haven&#x27;t noticed any problems with it over the last few years. I doubt java is bottlenecking the performance at all: it&#x27;s limited by IO and CPU throughput for hashing the files. For everyday use, you don&#x27;t need to hash every file in entirety to detect changes. There&#x27;s a &quot;fast&quot; mode that checks a couple of blocks. You can also operate in a subdirectory of the repo to ignore files outside that subdirectory.<p>I also don&#x27;t just use one massive fim repository. I have a .fim&#x2F; for each directory I care about (types of data) that a secondary scripts loops through for checking the status. That weakens the integrity guarantees since you can&#x27;t log the movement of files across directories, but makes it easier to reorganize things.<p>&gt; So many emojis in the commit log. Is that really necessary nowadays?<p>Yah, that&#x27;s the most emojis I&#x27;ve ever seen in a git repo. Maybe 2017 was a different era.')