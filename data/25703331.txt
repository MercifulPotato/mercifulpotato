Item(by='AshamedCaptain', descendants=None, kids=[25703467, 25706356, 25703579, 25703699, 25703945, 25703670, 25705742, 25707188, 25706767, 25704575, 25705476], score=None, time=1610218649, title=None, item_type='comment', url=None, parent=25701959, text='Claiming &quot;mmap is faster than system calls&quot; is dangerous.<p>I once worked for a company where they also heard someone say &quot;mmap is faster than read&#x2F;write&quot; and as a consequence rewrite their while( read() ) loop into the following monstrosity:<p>1. mmap a 4KB chunk of the file<p>2. memcpy it into the destination buffer<p>3. munmap the 4KB chunk<p>4. repeat until eof<p>This is different from the claim in the article -- the above monstrosity is individually mmaping each 4KB block, while I presume the article&#x27;s benchmark is mmaping the entire file in memory at once, which makes much more sense.<p>After I claimed the &quot;monstrosity&quot; was absurdly stupid, someone pointed to a benchmark they made and found that the &quot;monstrosity&quot; version was actually faster. To me, this made  no sense. The monstrosity has triple the syscall overhead vs the read() version, requires manipulating page tables for every 4KB block and as a consequence had several page faults for each 4KB block of the file. Yet it was true: their benchmarks showed the monstrosity version to be slightly faster.<p>The idealist in me couldn&#x27;t stand this and I reverted this change, using for my own (unrelated) experiments a binary which used the older, classic, read() loop instead of mmap.<p>Eventually I noticed I was getting results much faster using my build on my single-socket Xeon than they were getting on their $$$ server farms. Despite what the benchmark said.<p>Turns out, the &quot;monstrosity&quot; was indeed faster, but if you had several of these binaries running concurrently on the same machine, they would all slow down each other, as if the kernel was having scale issues with multiple processes constantly changing their page tables. The thing would slow down to single-core levels of performance.<p>I still have no idea why the benchmark was apparently slightly faster, but obviously they were checking it either isolated or on machines where the other processes where running read() loops. I guess that by wasting more kernel CPU time on yourself you may starve other processes in the system leaving more user time for yourself. But once every process does it, the net result is still significantly lowered performance for everyone.<p>Just yet another anecdote for the experience bag...')