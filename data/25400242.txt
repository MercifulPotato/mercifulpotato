Item(by='folkhack', descendants=None, kids=[25400392], score=None, time=1607797080, title=None, item_type='comment', url=None, parent=25399119, text='Also - as someone with a ton of experience on the other side of this coin:<p>Puppeteer etc. are nice and all but if you can get away with raw HTTP requests grabbing and parsing the HTML without pulling down stylesheets, JS, etc. do it. It is WAY more efficient than requesting the full overhead for the user experience from these folks and threading out 5-10 workers to gracefully crawl a site this way doesn&#x27;t typically cause things to melt down on your target&#x27;s end.<p>You may be saying &quot;well I need a browser-stack or evaluated JS to do my work&quot; and you may be right... but honestly though 90% of this stuff is reverse-engineer-able with Charles Proxy and some basic webdev experience. Heck - I&#x27;ve even sandboxed JS from a target&#x27;s site to generate tokens&#x2F;etc to cut down on repeat requests. Even CAPTCHA stuff can easily be done without having to pull down full UIX overhead these days.<p>---<p>&quot;Save a sysadmin: donâ€™t snowball.&quot;<p>Implement thread limits, rate limiting, throttling, intelligent caching, and try to fit within your target&#x27;s hosting capabilities without being disrespectful. Often I will &quot;smear&quot; large jobs over weeks worth of time so that it&#x27;s only a trickle of traffic here and there (and to also fly under the radar... sorry).<p>Also - on the custom UAS: Unless you&#x27;re trying to make it easy to get blocked&#x2F;identified then don&#x27;t take this advice. Let&#x27;s face it - this is a gray area for most. The <i>best</i> way is to not &quot;snowball&quot; and to make your scrapers indistinguishable from a reasonable stream of real users from real networks. I would never expect a sysadmin to contact me because frankly they aren&#x27;t paid to.<p>---<p>One last thought - the people who are out there writing these bots&#x2F;crawlers&#x2F;etc. are often the lowest common denominator. They&#x27;re the type that will get something &quot;working&quot; and hurry onto the next job because the nature of the work tends to be a ton of low-paid contract stuff. Also, at almost every place I&#x27;ve worked at in ecommerce that has scraping involved it&#x27;s the bottom-rung dev talent that&#x27;s assigned to the work.<p>Sucks, but near-100% I attribute your &quot;snowball&quot; situation to that.')