Item(by='qsort', descendants=None, kids=[24768918, 24767067, 24767175], score=None, time=1602601433, title=None, item_type='comment', url=None, parent=24765549, text='&gt; The definition of words changes in response to increasing knowledge<p>The usual process in mathematics and science is that you have a phenomenon that everyone agree exists but nobody can quite put their finger on it, so someone proposes a formal definition and if that definition turns out to be adequate, people work on the formal definition, and that&#x27;s much easier because you now can use math, statistics, formal methods, etc; a prime example of this is the notion of &quot;computability&quot;.<p>I don&#x27;t believe that we are seeing the same thing with the concept of &quot;intelligence&quot;, this is probably in part because it&#x27;s much harder to capture the concept in a formal definition. Computers do computable stuff. Overlapping that notion with &quot;intelligence&quot; serves no purpose in my opinion: it explains nothing, it doesn&#x27;t clarify anything, and it&#x27;s certainly not obvious that the two are related.<p>&gt; which are not &quot;just&quot; machine code either<p>I&#x27;m using &quot;machine code&quot; as proxy for &quot;instructions&#x2F;lambdas&#x2F;whatever for a computational model of your choice&quot;, which they certainly are.<p>&gt; The more you stress the simplicity of these models, the more intriguing their achievements seem.<p>It&#x27;s not my intention to downplay any of the achievements of &quot;AI&quot;. They are certainly not less intriguing when viewed from my perspective, the same way a compiler is not less intriguing if you think it&#x27;s &quot;just code&quot;.<p>My point is that any association of a formal concept (math, models, etc.) with philosophical concepts (intelligence, &quot;truths about the world&quot;, consciousness, etc.) is always on thin ice, because natural language and formal concepts are hard to mix. Especially so when the concepts at play are so ephemeral.')