Item(by='kkielhofner', descendants=None, kids=[25063326, 25064815], score=None, time=1605130315, title=None, item_type='comment', url=None, parent=25061097, text='I understand the allure of real hardware and doing this on a physical cluster but I&#x27;m always surprised not to see K8s&#x2F;k3s&#x2F;whatever running under (inside?) LXD as a learning&#x2F;experimentation tool discussed more often.<p>The physical cabling, underlying operating system, bootstrapping etc strikes me as the least of the K8s learning experience and the only advantage of a toy running on Pis vs LXD. Not to mention most K8s deployments these days will be in some cloud provider of choice where most of this is handled... In that case LXD on a local machine with software network bridging, etc probably more closely approximates what most people will go to production with anyway.<p>I&#x27;m a little sour on the whole &quot;LXD only officially distributed via snap&quot; thing too but at least on Ubuntu 18.04 and forward getting a toy X node Kubernetes cluster up and running is trivial and costs nothing more than RAM and disk space. As is commonly known LXD doesn&#x27;t even require a hypervisor so the hardware requirements are (essentially) anything x86_64. It&#x27;s also fun to spin up&#x2F;destroy any number of instances at will just using the command line.<p>MicroK8s even provides an LXD how-to that should work for your flavor of choice (with a little adaptation, of course):<p><a href="https:&#x2F;&#x2F;microk8s.io&#x2F;docs&#x2F;lxd" rel="nofollow">https:&#x2F;&#x2F;microk8s.io&#x2F;docs&#x2F;lxd</a><p>Of course if you&#x27;re actually doing some kind of edge deployment or whatever on actual Raspberry Pi&#x2F;armv7&#x2F;arm64 hardware that&#x27;s the obvious way to go (or you can just run LXD on your Pi) :).')