Item(by='tigerBL00D', descendants=None, kids=[25822679, 25824769, 25822203], score=None, time=1610973476, title=None, item_type='comment', url=None, parent=25820482, text='I don&#x27;t necessarily see the &quot;team of automated googlers&quot; as a fundamental or damning problem with GPT-like approaches. First I think people may have a lot fewer truly original ideas then they are willing to admit. Original thought is sought after and celebrated in arts as a rare commodity. But unlike in arts, where there are almost not constraints, when it comes to science or engineering almost every incremental step is of form Y = Fn(X0,..,Xn) where X0..Xn are widely known and proven to be true. With sufficient logical reasoning and&#x2F;or experimental data, after numerous peer reviews, we can accept Fn(...) to be a valid transform and Y becomes Xn+1, etc. Before internet or Google one had to go to a library and read books and magazines, or ask other people to find inputs from which new ideas could be synthesized. I think GPT-like stuff is a small step towards automating and speeding up this general synthesis process in the post-Google world.<p>But if we are looking to replace end-to-end intelligence at scale it&#x27;s not just about synthesis. We need to also automate the peer review process so that it&#x27;s bandwidth is matched to increased rate of synthesis. Most good researchers and engineers are able to self-critique their work (and the degree to which they can do that well is really what makes one good IMHO). And then we rely on our colleagues and peers to review our work and form a consensus on its quality. Currently GPT-like systems can easily overwhelm humans with such peer review requests. Even if a model is capable of writing the next great literary work, predicting exactly what happened on Jan 6, or formulating new laws of physics the sheer amount of crap it will produce alongside makes it very unlikely that anyone will notice.')