Item(by='core-questions', descendants=None, kids=None, score=None, time=1610151108, title=None, item_type='comment', url=None, parent=25692710, text='&gt; We&#x27;re concerned about speech that is being amplified in a way where there&#x27;s a civic responsibility to ensure that the harmful messages are not being amplified.<p>Who gets to pick what is harmful, though? Why can we not choose our own gatekeepers, rather than having them foisted upon us by corporate oligarchs?<p>The big problem here is that it is completely unreasonable and unprecedented to assume that this will be done in a transparent, consistent, open way. There will be no clear appeals process, and there&#x27;s no reason to believe that the censorship won&#x27;t be ideologically biased in favour of whatever is marketing best at the moment.<p>&gt; it&#x27;s controls on what can be said to large amounts of people<p>It&#x27;s controls on what <i>the working class</i> can say to large amounts of people. The elite can still just go buy a newspaper or a broadcast media network, or start their own website, etc. and issue forth opinions on a grand scale. Regular folks will have to go through censors, which will end up being some combination of AI and outsourced farms of moderators in other countries or some other such Kafkaesque nightmare of business process.<p>&gt;  there&#x27;s a civic responsibility to ensure that the harmful messages are not being amplified.<p>&quot;harmful&quot; is a social construct, and what is &quot;harmful&quot; to one group might not be to another. Which groups will be prioritized for this? How will you pick sides fairly without imposing a new dimension on whatever underlying group conflicts already exist?<p>The problem is that what you want to do cannot be done fairly. It can only be done in a draconian way, and the result will be an even wider fracturing of dialogue in a way that doesn&#x27;t result in what you want, at all.')