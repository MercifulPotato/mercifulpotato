Item(by='snidane', descendants=None, kids=[25995667, 25995688, 25995733], score=None, time=1612221682, title=None, item_type='comment', url=None, parent=25994760, text='While both BQ and Snowflake are adopting lake features, they still only support parquet and other file formats for loading, not for querying.<p>Can&#x27;t do a simple<p><pre><code>    select * from s3:&#x2F;&#x2F;file.parquet\n</code></pre>\nwhich you can do in Spark. Having to load it into the data warehouse means that you duplicate your data two times and it is stupidly annoying.<p>Many times the data doesn&#x27;t even resemble anything tabular before I structure it in python scripts. Why would I load it inside a warehouse only to then pull it down to do some python processing and loading it back. Which makes the data travel from DWH storage to a data lake and then to my compute cluster and then the same cumbersome roadtrip back. Pretty wasteful. Spark at least allows me to schedule a python function across a cluster while copying only from lake to my compute node and back.<p>Data warehouses like BQ and Snowflake are great for data scientists after a bunch of engineers slice and dice raw data into clean tables. For anyone working with not yet structured data, data lake wins hands down.')