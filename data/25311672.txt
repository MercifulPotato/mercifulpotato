Item(by='ozborn', descendants=None, kids=[25311710], score=None, time=1607141514, title=None, item_type='comment', url=None, parent=25311574, text='There are models much larger than BERT with a much larger footprint, GPT-3 being the most well kniwn example.<p>Models like BERT aren&#x27;t  just trained once either when they are developed, but trained again with different domains, different parameters, different tasks in some cases. There is also fine-tuning (more frequent, less carbon intendive), so these are real environmental problems, and others have pointed them out.')