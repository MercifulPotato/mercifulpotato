Item(by='phire', descendants=None, kids=None, score=None, time=1605634804, title=None, item_type='comment', url=None, parent=25125814, text='There is more than one way to scale. Over the last decade, Intel had been pushing wider SIMD.<p>Instead of making your cpu able to execute more instructions per cycle, why don&#x27;t you make each instruction do more work. SSE packs four floats&#x2F;ints or two doubles&#x2F;longs into a single 128bit register and then you can do the same ALU operation to each lane.<p>It works great on certain workloads.<p>With AVX, Intel increased the size of these registers to 256bit (eight floats) in 2011 and are currently pushing AVX512 doubles the width again (16 floats).<p>Apple, and ARM in general are limited to 128bit vector registers (though they are plans to increase that in the future)<p>Cinebench is well known as a benchmark which takes advantage of the 256bit AVX registers, and some people have speculated that Apple&#x27;s M1 might be at a significant disadvantage because of this, with just half the ALU thoughput.<p>But these numbers show that while cinebench gets a notable boost from AVX, it&#x27;s not as large as you might think (at least on this workload), allowing the M1&#x27;s IPC advantage to shine though.')