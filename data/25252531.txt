Item(by='sradman', descendants=None, kids=[25253821], score=None, time=1606733651, title=None, item_type='comment', url=None, parent=25251229, text='I think AWS Inferentia [1], Amazonâ€™s AI silicon, is much further along than the article suggests. The Alexa backend is mostly run on these chips now [2].  Other than this nitpick, the article is a great summary of how Google, Amazon, and Apple are vertically integrating silicon into their platforms.<p>[1] <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;machine-learning&#x2F;inferentia&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;machine-learning&#x2F;inferentia&#x2F;</a><p>[2] <a href="https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;aws&#x2F;majority-of-alexa-now-running-on-faster-more-cost-effective-amazon-ec2-inf1-instances&#x2F;" rel="nofollow">https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;aws&#x2F;majority-of-alexa-now-runni...</a>')