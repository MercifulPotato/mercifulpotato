Item(by='whimsicalism', descendants=None, kids=[24711412], score=None, time=1602092225, title=None, item_type='comment', url=None, parent=24708692, text='&gt; It somehow configures itself at inference time so that state machines which produce plausible continuations of whatever pattern it was fed, are most probably generated.<p>What is this sentence supposed to convey? I&#x27;m an NLP practicioner&#x2F;researcher and this isn&#x27;t even true - as GPT isn&#x27;t a &quot;state machine&quot; as the latent space is continuous and not finite.<p>Moreover, there is nothing that makes GPT-3 &quot;not capable of learning.&quot; It has had very exciting results from language modeling a zero-shot task at inference time, but there&#x27;s nothing (besides compute) precluding fine-tuning of it in principle.<p>I agree with the rest of your comment.')