Item(by='yamrzou', descendants=None, kids=None, score=None, time=1607028741, title=None, item_type='comment', url=None, parent=25293037, text='&gt; To tie this back to AI, it would mean that as long as your models produce racially biased results, they simply aren&#x27;t ready for deployment <i>or publication</i>. Go find better data until your work is no longer liable to inflict harm on anybody.<p>Well, the disagreement is about <i>publication</i>. Yann LeCun himself said that &quot;The consequences of bias are considerably more dire in a deployed product than in an academic paper.&quot;[1]<p>Why would it be wrong to publish research based on biased data?<p>[1] <a href="https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1274790777516961792" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1274790777516961792</a>')