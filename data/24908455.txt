Item(by='jcims', descendants=None, kids=None, score=None, time=1603813139, title=None, item_type='comment', url=None, parent=24907819, text='I completely agree but I do think humans <i>have</i> a language model, and considering how we use that to encode and decode the human experience might be useful in figuring out how we improve things like GPT-3.<p>Personally I feel that embodiment of some form, in which there is some vector space for a &#x27;world model&#x27; that can be paired up to a language model, is a route forward.  For example, if you have a Boston Dynamics (for example) robot that has a model for gravity, mass, acceleration, force, object manipulation, etc and you incorporate those into a language model, there is going to be a much richer latent space from which associations can be made between terms.  If you ask GPT-3 the difference between various gaits, e.g. walk, trot, gallop, it&#x27;s going to have associations with other contexts and adjectives used in the vicinity of those terms.  However, if you enrich it with data from a Spot Mini that can actually execute those gaits, you&#x27;re going to have information around velocity, inertia, power consumption and budget, object detection rates, route planning horizon, etc.')