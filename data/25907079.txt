Item(by='danShumway', descendants=None, kids=[25907580], score=None, time=1611600883, title=None, item_type='comment', url=None, parent=25903049, text='It&#x27;s possible to imagine an alternative system to FLoC that was actually privacy respecting.<p>Say we had an Open, standardized, human-readable list of categories&#x2F;groups that people could opt into (rather than a bunch of on-the-fly groupings determined by an AI). We could give users the ability to choose 0-X of those categories that they want to associate with. We could even let them choose on a site-by-site basis, so they could decide how ads would be targeted (or if they would be targeted at all) on <i>parts</i> of the web.<p>We could build UIs that helped them with that. We could have easy ways to opt into or out of categories. We could allow them to turn on category suggestions, so with their permission if a user visited a site about a specific kind of product, we could show a one-click option in the browser to add themselves to an associated category and see ads for similar products.<p>We could allow them to group sites together and say things like, &quot;I want news sites that I visit to know that I&#x27;m looking to buy a specific brand of car, but I don&#x27;t want any of the car dealership sites that I&#x27;m looking at to know what brand I want.&quot;<p>For users that don&#x27;t want that level of detail, we could still have a &#x27;smart&#x27; system that consumers could run (clientside) that looked at the websites they visited, or even more personal data, and auto-placed them in categories without them needing to think about the system at all. They&#x27;d just need to select an option to let the browser handle all of their categories for them.<p>But importantly, all of this would be based on consent. And instead of offering users a single choice to opt out, they would have an entire spectrum of choices that allowed them to decide how they presented themselves online, what specific data they shared, and who they shared it with.<p>If users genuinely benefit from targeted ads, then they&#x27;ll opt into the system and pick categories that are relevant to them and send them to sites. If they think Google&#x27;s data collection is accurate, then they&#x27;ll turn on the smart system in Chrome that locally categorizes them. But at any point, for any site, they could choose to turn off the data entirely, or to add themselves to a specific category, or to remove themselves from a specific category. In human-understandable terms, they would know exactly what data they were transmitting to websites.<p>----<p>For all that Google says they&#x27;re working on data privacy, very few of their proposals, even their good proposals, approach privacy from an angle of giving users more control over their identities. Google is still stuck in a world where they think of data collection as something that has to happen without the users knowledge, without the user&#x27;s ability to easily inspect what&#x27;s going on, without the user&#x27;s ability to form multiple identities or even to just opt-into the system at all.<p>What I want is control over my data. And what Google (and companies like them) keep on saying is, &quot;we&#x27;ll be somewhat more responsible with your data, but only if we keep control of it.&quot;<p>And this represents a general attitude that comes up in so many modern tech products, from Youtube, to social feeds, to modern UI design, to device security. These companies are like a controlling, overbearing parent. People want agency over their ads&#x2F;recommendations&#x2F;feeds&#x2F;etc, but the companies think the problem is that they&#x27;re just not good enough at controlling all of that for us. It&#x27;s a way of thinking about UX&#x2F;product&#x2F;process that&#x27;s divorced from user consent and agency as an ideals that we should strive towards.')