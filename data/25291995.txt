Item(by='alwillis', descendants=None, kids=None, score=None, time=1607017982, title=None, item_type='comment', url=None, parent=25289696, text='<i>M1 is still just a tablet SoC in a laptop form factor.</i><p>That wouldn&#x27;t be good enough for production hardware. The developer units had a previous iPad’s A12 SoC in an enclosure for developers to test things on. For example, the A series doesn&#x27;t support virtualization because that&#x27;s not required on a phone or tablet. But the M1 supports this and other laptop&#x2F;desktop features. Even the A14 only has 4 cores compared to the M1&#x27;s 8 cores. This isn&#x27;t <i>just</i> a tablet SoC.<p><i>We don&#x27;t know what the efficiency will look like after you add all the I&#x2F;O you need for a real desktop, we don&#x27;t know how the memory subsystem will deal with 4 more cores that are just as fast. What&#x27;s the point of having fast cores if you cannot feed them?</i><p>Perhaps you haven&#x27;t been paying attention, but the Mac mini is a <i>real</i> desktop. And all of the M1 Macs have blazingly fast memory access. Remember, it&#x27;s an SoC—the memory is on the same die as the CPUs, GPUs and they all have equal access to it. No bus to go across. That&#x27;s why it&#x27;s so fast.<p><i>People act like Apple changed the game or is light years ahead of everyone but they literally haven&#x27;t made a proper desktop-class chip yet.</i><p>The M1 already has features no &quot;desktop&quot; chip has, such as 8 instruction decoders. This may not sound like a big deal, but none of the Intel or AMD chips--not the threadripper or the Zen3—has more than 4. Why this matters:<p><pre><code>    &quot;It is because the ability to run fast depends\n    on how quickly you can fill up the ROB with\n    micro-ops and with how many. The more quickly\n    you fill it up and the larger it is the more\n    opportunities you are given to pick instructions\n    you can execute in parallel and thus improve performance.\n\n    Machine code instructions are chopped into micro-ops\n    by what we call an instruction decoder. If we have more\n    decoders we can chop up more instructions in parallel\n    and thus fill up the ROB faster.\n\n    And this is where we see the huge differences.\n    The biggest baddest Intel and AMD microprocessor\n    cores have 4 decoders, which means they can decode\n    4 instructions in parallel spitting out micro-ops.\n\n    But Apple has a crazy 8 decoders. Not only that\n    but the ROB is something like 3x larger. You can\n    basically hold 3x as many instructions. No other\n    mainstream chip maker has that many decoders in\n    their CPUs.&quot;\n</code></pre>\nSo Intel or AMD will just add 8 instruction decoders to increase their throughput, right? Nope:<p><pre><code>    &quot;However on an x86 CPU the decoders have no clue\n    where the next instruction starts. It has to\n    actually analyze each instruction in order to see\n    how long it is.\n\n    The brute force way Intel and AMD deal with this\n    is by simply attempting to decode instructions at\n    every posssible starting points. That means we have\n    to deal with lots of wrong guesses and mistakes which\n    has to be discarded. This creates such a convoluted\n    and complicated decoder stage, that it is really\n    hard to add more decoders. But for Apple it is\n    trivial in comparison to keep adding more.\n\n    In fact adding more causes so many other problems\n    that 4 decoders according to AMD itself is basically\n    an upper limit for how far they can go.\n    *This is what allows the M1 Firestorm cores to\n    essentially process twice as many instructions as\n    AMD and Intel CPUs at the same clock frequency.*&quot;\n</code></pre>\nAs I&#x27;ve said in other threads on HN, there&#x27;s no way Apple&#x27;s first laptop&#x2F;desktop chip should be competitive with AMD, but it is:<p><pre><code>    &quot;As far as I remember from performance benchmarks\n    the newest AMD CPU cores, the ones called Zen3\n    are slightly faster than Firestorm cores. But\n    here is the kicker, that only happens because the\n    Zen3 cores are clocked at 5 GHz. Firestorm cores\n    are clocked at 3.2 GHz. The Zen3 is just barely\n    squeezing past Firestorm despite having almost\n    60% higher clock frequency.\n\n    So why doesn’t Apple increase the clock frequency\n    too? Because higher clock frequency makes the chips\n    hotter. That is one of Apple’s key selling points.\n    Their computers unlike Intel and AMD offerings barely\n    need cooling.\n\n    In essence one could say Firestorm cores really\n    are superior to Zen3 cores. Zen3 only manages to\n    stay in the game by drawing a lot more current and\n    getting a lot hotter. Something Apple simply chooses\n    not to do.&quot;\n</code></pre>\n<i>So yes, Apple does have catching up to do.</i><p>Come again?<p>The Zen3 barely beats the M1, which runs at 60% of the speed and a small fraction of the power. It can essentially process twice as many instructions at the same clock frequency. They&#x27;re already ahead in many key areas, with performance per watt being the most obvious. There are issues with the x86 architecture, like instructions ranging from 1 to 15 bytes, which limits Intel and AMD from being able to process as many instructions per clock cycle as ARM processors in general and the M1 especially.<p>I’m quoting from the article &quot;Why is Apple’s M1 Chip So Fast?&quot;, which has a lot more technical details: <a href="https:&#x2F;&#x2F;erik-engheim.medium.com&#x2F;why-is-apples-m1-chip-so-fast-3262b158cba2" rel="nofollow">https:&#x2F;&#x2F;erik-engheim.medium.com&#x2F;why-is-apples-m1-chip-so-fas...</a>')