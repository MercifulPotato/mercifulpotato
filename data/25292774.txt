Item(by='sudosysgen', descendants=None, kids=[25293197], score=None, time=1607021108, title=None, item_type='comment', url=None, parent=25292638, text='Well, reading the thread, it&#x27;s pretty clear that she was correct. There is a second step of metaoptimization which incentives the researchers to encode algorithms to produce algorithms that more easily bias along a certain way. And she is correct that benchmarking models against biased datasets can lead researchers to bias for architectures that are in turn more likely to have a certain bias.<p>I&#x27;m sure LeCun knows this too. It&#x27;s a fact that has been known for almost 40 years now, that for a given generalization system multiple bias modes are are possible, and of course the process of optimizing architectures against a biased benchmark will change the learning bias of the model. It&#x27;s not just datasets that are biased, generalization systems are necessarily biased too.<p>As for the last line, I don&#x27;t know that it should be expected for employers to fire employees pursuing recourse against sexual harassment.<p>I&#x27;m sure we can agree that the tone wasn&#x27;t good, but she does have a point in saying that it&#x27;s not possible to reduce the bias to datasets used to train the final model.<p>The paper : <a href="http:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~tom&#x2F;pubs&#x2F;NeedForBias_1980.pdf" rel="nofollow">http:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~tom&#x2F;pubs&#x2F;NeedForBias_1980.pdf</a>')