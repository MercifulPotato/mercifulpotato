Item(by='samizdis', descendants=None, kids=None, score=None, time=1607042415, title=None, item_type='comment', url=None, parent=25292386, text='FT article [1] &quot;Google embroiled in row over AI bias research&quot; seems calm&#x2F;considered. Includes:<p>&gt; Jeff Dean, Google’s head of AI, defended the decision in an internal email to staff on Thursday, saying the paper “didn’t meet our bar for publication”. He also described Ms Gebru’s departure as a resignation, after Google had refused to agree to unspecified conditions she had set to stay at the company.<p>&gt; The dispute has threatened to shine a light on Google’s handling of internal AI research that could hurt its business, as well as the company’s long-running difficulties in trying to bring more diversity to its workforce. ...<p>&gt; The paper looked at the potential bias in large-scale language models, one of the hottest new fields of natural language research. Systems like OpenAI’s GPT-3 and Google’s own system, Bert, attempt to predict the next word in any phrase or sentence — a method that has been used to produce surprisingly effective automated writing, and which Google uses to better understand complex search queries.<p>&gt; The language models are trained on vast amounts of text, usually drawn from the internet, leading to warnings that they could regurgitate racial and other biases that are contained in the underlying training material.<p>&gt; “From the outside, it looks like someone at Google decided this was harmful to their interests,” said Emily Bender, a professor of computational linguistics at the University of Washington, who co-authored the paper.<p>[1] <a href="https:&#x2F;&#x2F;www.ft.com&#x2F;content&#x2F;995c62ab-26b1-4eed-b1fb-cb4846023ed2" rel="nofollow">https:&#x2F;&#x2F;www.ft.com&#x2F;content&#x2F;995c62ab-26b1-4eed-b1fb-cb4846023...</a>')