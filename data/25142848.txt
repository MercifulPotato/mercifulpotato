Item(by='john_moscow', descendants=None, kids=[25143074, 25147442, 25143017, 25146499, 25142897, 25143384], score=None, time=1605735980, title=None, item_type='comment', url=None, parent=25142269, text='I am more wondering why hasn&#x27;t AMD massively invested into porting common ML frameworks to OpenCL. Nvidia has outrageous margins on their datacenter GPUs. They&#x27;ve even banned the use of lower-margin gamer-oriented GPU in datacenters [0]. Given that tensor arithmetic is essentially an easily abstractable commodity, I just don&#x27;t understand why they don&#x27;t offer a drop-in replacement.<p>Most users won&#x27;t care what hardware their PyTorch model runs on in the cloud. All that matters for them is dollars per training epoch (or cents per inference). This could be a steal for an alternate hardware vendor.<p>[0] <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20201109023551&#x2F;https:&#x2F;&#x2F;www.digitaltrends.com&#x2F;computing&#x2F;nvidia-bans-consumer-gpus-in-data-centers&#x2F;" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20201109023551&#x2F;https:&#x2F;&#x2F;www.digit...</a>')