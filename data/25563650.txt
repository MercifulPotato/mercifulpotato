Item(by='_underfl0w_', descendants=None, kids=[25565881], score=None, time=1609192254, title=None, item_type='comment', url=None, parent=25562321, text='Does Clearview AI train on mugshot datasets specifically?<p>I&#x27;m absolutely NOT advocating for its use at all, but it seems like that might be a good source for well-tagged, organized data for what is turning out to be a very problematic (though apparently allowed) use case.<p>From a photography standpoint, it seems to follow that identical lighting in the same room where they&#x27;re taking everyone&#x27;s mugshots could produce different levels of contrast for facial features across different skin tones, simply as an artifact of cheap lenses and a lack of white-balancing or overall <i>care</i>, really.    \nIf persons A and B have different skin tones, then the routine, careless, terrible, one-size-fits-all black-and-white photo by an underpaid government office worker may not accurately capture the contrast in the shadows of both of their facial features to the same degree, no futile human bias required.<p>This lack of definition may then further help promote any existing biases in ML training, enforcement, etc. towards people whose features aren&#x27;t as well contrasted in the resultant, awful photos. Perhaps training on such a grainy, washed-out dataset would at least help the ML distinguish smaller variances in contrast to a finer degree, if nothing else.   \nUs humans can do it, after all.')