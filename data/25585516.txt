Item(by='cpascal', descendants=None, kids=[25588721, 25588100], score=None, time=1609359129, title=None, item_type='comment', url=None, parent=25585118, text='It really depends on your scale and how many messages you are processing per second. For a lot of applications, you’re absolutely correct, but if you’re scale is sufficient, a “micro” optimization like this is actually a “macro” optimization. Also the author of this article works at DataDog and I suspect the number of messages they process each second falls under the sufficient category.<p>For example, suppose you are processing 1M messages per second and you can shave 1 byte off the message size, that shaves off 1MB&#x2F;sec of data that needs to be processed. If you’re paying for network bandwidth or storing the messages, that saves you something like 2.6TB of data each month.<p>2.6TB&#x2F;month is not likely to be a huge deal when it comes to cost savings, but if you keep scaling the messages&#x2F;sec or the bytes&#x2F;msg you can start to get some significant savings.<p>Now I used message size as an example, and the article focuses on processing time not message size, but the point still stands. When you can make a micro optimization for something that is done a very large number of times, there are not-insignificant gains to be had.')