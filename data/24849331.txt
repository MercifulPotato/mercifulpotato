Item(by='LolWolf', descendants=None, kids=[24849646], score=None, time=1603297445, title=None, item_type='comment', url=None, parent=24848630, text='&gt; The granularity of the &quot;correctness&quot; is the major difference here and you&#x27;re asking the author to be ok with an extremely rough success criteria when they are proposing a mathematically perfect success criteria.<p>All I&#x27;m saying is that there are easier and clearer ways of presenting the same thing that could be done in a sentence and make the &quot;reason why&quot; obvious. No need to introduce gadgets and go on and on for 30 pages about &quot;exponential time&quot; (is the author talking about the exponential time hypothesis? Or is this P vs. NP?) among other things. There&#x27;s also some additional crossed wires about &quot;needing to try all cases&quot; or something, that doesn&#x27;t make any sense. No SAT solver&#x2F;TSP solver&#x2F;MILP solver, etc., does this. Anyone who is at all familiar with this topic would not make such statements, and certainly not, in the way you mention, a &quot;mathematically perfect&quot; criterion that &quot;is proven wrong.&quot; So which is it? Is the author being cavalier about the literature? Or do they simply not understand the basics?<p>Additionally, they&#x27;re not proving anything wrong. This is, like what I mentioned before, similar to bashing people for saying &quot;Nash-equilibria are PPAD-hard (and communication hard) so Nash-equilibrium as a concept is bad because it&#x27;s computationally difficult.&quot; (In fact, I&#x27;d say it&#x27;s even less interesting than this, because at least the latter is a nontrivial result; not a one-line argument that we can embed arbitrarily complex things into the market.)<p>&gt; Rationalism has not been shown to provide a pathway to a general epistemology.<p>This is &quot;rational&quot; as in &quot;rational agent&quot; (utility-maximizing, or an agent that makes at least Pareto-optimal choices, or who plays to Nash or correlated equilibria) not &quot;rationalists&quot; as in people who apply rationalism as an epistemology. Applied broadly, &quot;rational agents&quot; could solve halting-hard problems by making an obvious game where an agent who solves such a problem gets a million dollars, since such agents are often assumed to have unbounded computational power. (In particular, nothing about the agent&#x27;s computational power is often assumed.)<p>&gt; Fundamentally the author is making a really good case for the idea that oblique or poorly specified&#x2F;constructed goal and measurement criteria (eg. EMH) should not be assumed as a competent goal vectoring mechanism for society.<p>Not really, no. For one, EMH says nothing about exact solutions (this would require a much more careful argument with a different type of reduction), and two, in the same way as before, putting EMH on a pedestal (like putting Nash equilibria on a pedestal, or agent rationality, etc.) leads to absurd results. My point is that (a) this is well-known and (b) you can make much simpler examples (like the ones above) that don&#x27;t appear to be as &quot;clever&quot; but prove the same (nearly-obvious) point.')