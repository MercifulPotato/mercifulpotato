Item(by='bko', descendants=None, kids=None, score=None, time=1608753277, title=None, item_type='comment', url=None, parent=25520792, text='I&#x27;ve noticed all the top performing AI reinforcement algorithms i hear about know next to nothing about the initial rules. And not only do they perform as well as more supervised methods, but much better<p>The one exception is self driving. I listened to the Lex Fridman interview with ceo of waymo recently and he made a case for the controlled environment (e.g. separate detection from decision making and planning) and pushed back against the end to end approach that doesn&#x27;t make any preconceived assumptions about the environment. As an example he takes red lights. They&#x27;re clearly human engineered signals, so it makes sense to have a module that can explicitly determine the signal as opposed to learning the behavior<p>But that&#x27;s true about other games as well and end to end methods still outperform. Which makes me ask, is end to end learning an inevitability for self driving as well or is this the one domain special due to complexity or other aspects?')