Item(by='wildermuthn', descendants=None, kids=None, score=None, time=1609426032, title=None, item_type='comment', url=None, parent=25591552, text='I started skimming after he dismissed Deepmind’s work with Go. He doesn’t mention AlphaZero, MuZero, or Rebel (AlphaZero-ish for poker), or seem to understand the importance of solving games with ML.<p>But he does make an interesting point about the business of “AI”, a point made by a VC in a well-written post some time last year — it seems quite hard at the moment for ML to scale in the same way that we’ve grown used to software scaling.<p>But people were saying similar thing about “the World Wide Web” back in the late 90s, and especially after the bubble. Perhaps there is a ML bubble and it will pop, but this is a good thing. It in no way reflects upon the fundamental value of scaling human tasks with software.<p>Right now ML works fairly well for making a program that accomplishes some discrete and narrow task that could have conceivably been done with traditional hand-coded software, but at greater levels of accuracy and lower levels of human effort. For example, various forms of speech recognition have existed for ... decades? But ML models are far superior than anything that has been or could be hand-coded.<p>So this space for innovative businesses built upon ML software is as large as the current space for business built upon OOP and FP software — the method is somewhat irrelevant. What matters is still the difficulty of the problem being solved, and in general, the difficulty of making what people want. This is the hardest problem — making something actually valuable. ML software gives businesses a larger space of solvable problems, but it is not unlimited. It might not yet include self-driving cars.<p>But given time, the only theoretical limit to ML’s problem-solving space is the limit of intelligence itself. Research like AlphaZero is one step toward that holy grail of AGI, and deserve more credit than the author gives it.')