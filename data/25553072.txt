Item(by='hansvm', descendants=None, kids=None, score=None, time=1609093572, title=None, item_type='comment', url=None, parent=25549506, text='&gt; Traversing a medium depth DAG with a million nodes to find orphaned nodes takes less than a second on average hardware.<p>Unless you have an abnormally high edge count that sounds super slow to me. Even accounting for metadata overhead and disk page slop you&#x27;re only reading and processing tens of megabytes, and every algorithm in sight is linear. I&#x27;d be surprised if you couldn&#x27;t get a 2-5x speedup by reading the whole table to RAM in your favorite compiled&#x2F;jitted language and just traversing it there.<p>&gt; I have not yet found a situation where nosql databases like leveldb offer an orders of magnitude advantage over SQLite, and SQLite is so much more powerful and robust...<p>I have no skin in that game, but would some of the nosql solutions not perform significantly better under heavily concurrent insertions and the other workloads they were designed for?')