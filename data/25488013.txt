Item(by='cl3misch', descendants=None, kids=[25489123, 25488122], score=None, time=1608486122, title=None, item_type='comment', url=None, parent=25487747, text='I find the nomenclature in this article a bit weird.<p>&gt; Another disadvantage of backpropagation is its tendency to become stuck in the local minima of the loss function. Mathematically, the goal in training a model is converging on the global minimum, the point in the loss function where the model has optimized its ability to make predictions.<p>&quot;Backpropagation&quot; is the method how to compute the gradient of the weights with respect to a loss function. But the article repeatedly uses the term as if it was the whole optimization algorithm, running into local minima.')