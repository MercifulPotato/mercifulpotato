Item(by='MichaelBurge', descendants=None, kids=[24811074, 24811235], score=None, time=1602950925, title=None, item_type='comment', url=None, parent=24810057, text='You wouldn&#x27;t want to use it for training: This chip can do 4 INT8 TOPs with 2 watts. A Tesla T4 can do 130 INT8 TOPs with 70 watts, and 8.1 FP32 TFLOPs.<p>Assuming that ratio holds, you&#x27;d maybe get 231 GFLOPs for training. The Nvidia GTX 9800 that I bought in 2008 gets 432 GFLOPs according to a quick Google search.<p>Hobbyists don&#x27;t care about power efficiency for training, so buy any GPU made in the last 12 years instead, train on your desktop, and transfer the trained model to the board.')