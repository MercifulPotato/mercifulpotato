Item(by='rovr138', descendants=None, kids=[25026631], score=None, time=1604850648, title=None, item_type='comment', url=None, parent=25026098, text='I don’t know the content strategy for the site, but depending on the site, most link to inner pages. Once you find individual articles, those usually can have external links.<p>This is making a lot of assumptions on the content structure, that’s true. But it would be interesting to analyze.<p>For how to get the links from the database, not for this, but I have used the `urlextract` Python package to find urls. Then you can use `urlparse` to the get the domain.<p>For how to extract this from the database, you’ll have to write some sql to find the tables you want, then you can do a `select * from table`. Then it’s parsing the output, get the urls, get the domain for each.<p>I would probably aggregate all the urls and domains, then at the end actually scan so you can deduplicate entries and not waste time scanning the same domain over and over.<p>- urlextract - <a href="https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;urlextract&#x2F;" rel="nofollow">https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;urlextract&#x2F;</a><p>For the images portion, I’d look into imagemagick compare tool, <a href="http:&#x2F;&#x2F;www.imagemagick.org&#x2F;Usage&#x2F;compare&#x2F;" rel="nofollow">http:&#x2F;&#x2F;www.imagemagick.org&#x2F;Usage&#x2F;compare&#x2F;</a><p>You can take a screenshot of a page at the moment you know it’s good, then take daily screenshots. With this tool, you can grab the daily screenshot and compare it with the known good one and the changes are highlighted.')