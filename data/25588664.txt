Item(by='jasonzemos', descendants=None, kids=[25588853, 25589022], score=None, time=1609379381, title=None, item_type='comment', url=None, parent=25587925, text='&gt; Avoiding memory allocation significantly increases the complexity of an API -- or worse, leads to shortcuts like using (thread-unsafe) globals or (overrun-prone) fixed buffers.<p>Allow me to unpack this, because the object interface that all of these serialization schemes present is what increases complexity. It makes sense that the simple implementation would tend toward dynamic memory and not further compound such complexity on their interface. This is a flawed architectural premise taken by these library implementations.<p>On the receiving side, there is little reason to ever deviate from zero-copy&#x2F;zero-allocate. These libraries are far too pro-active in deserializing incoming data into native object structures. It&#x27;s not necessary to present the user with this; they should pique through the results lazily -- query into the data at their own discretion. This is important because it bounds the minimum requisite cost of receiving messages at ... zero. It costs nothing to discard trash. Whereas with these proactive serialization layers, every single incoming attack becomes an exercise against the deserializer. In a zero-copy&#x2F;zero-allocate -- let&#x27;s even say, <i>zero-parse</i> mere lexing of the data, software has more flexibility. In practice, that means passing pointers around to parts of messages straight off the wire to application functionality further up the stack.<p>On the sending side, there is little reason to ever force whole native object representations to conduct a serialization. In other words, don&#x27;t force the user to build an std::map first and serialize it later. All input is streaming input. Properties do not have to be pre-buffered, they can be streamed. One can model any network serialization this way, sans perhaps canonical representations (sorted JSON keys, etc), and far more efficiently than with requiring arbitrary native structures.<p>This is not really a rebuttal about the merits for or against dynamic memory in and of itself. I know the research, thread-aware allocators can be pretty good -- even darn good, and the state of the art in GC is nothing to shake a stick at. The problem is that with better design it&#x27;s just not necessary, and in the end it <i>does</i> have a cost that one <i>should</i> want to eliminate if possible. I&#x27;m certain it&#x27;s quite usually possible, at least more than I see in a list like <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Comparison_of_data-serialization_formats" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Comparison_of_data-serializati...</a> etc')