Item(by='dathinab', descendants=None, kids=[25206508], score=None, time=1606263359, title=None, item_type='comment', url=None, parent=25204327, text='It&#x27;s a lot +-1 on atomic variables guarded using atomic memory operations (mainly with the Aquire&#x2F;Release ordering)\non memory which might be shared between threads.<p>So low latency of the cache to system RAM can help here, at least for cases where the Rc is shared between threads. But also if the thread is not shared between threads but the thread is moved to a different CPU. Still it&#x27;s probably not the main reason.<p>Given how atomic (might) be implemented on ARM and that the cach and memory is on the same chip my main guess is that they did some optimizations in the coherency protocol&#x2F;implementation (which keeps the memory between caches and the system memory&#x2F;RAM coherent). I believe there is a bit of potential to optimize for RC, i.e. to make that usage pattern of atomics fast. Lastly they probably take special care that the atomic related instructions used by Rc  are implemented as efficient as possible (mostly fetch_add&#x2F;fetch_sub).')