Item(by='sdenton4', descendants=None, kids=None, score=None, time=1606790999, title=None, item_type='comment', url=None, parent=25258676, text='Well, we can agree that world peace is off the table!<p>Beyond that, let&#x27;s notice that expert systems did indeed change how airports and freeways work: They improved the areas where they solved problems. Deployment happened.<p>What we&#x27;re seeing now is new classes of previously unsolvable problems falling. Deployment in medicine is known to be particularly hard, but not impossible. My read on the situation is that there have been a number of ML applications in the current round that have been kinda-successful &#x27;in vitro&#x27; and failed in deployment. That doesn&#x27;t mean that all deployments will fail.<p>Furthermore... Neil Lawrence points out that in most cases we change the world to fit new technologies. For example, mechanized tomato pickers suck, so we develop a more machine-resistant tomato. Cars break easily on dirt roads, so we pave half the planet. ML&#x2F;AI somehow flips people&#x27;s expectations of how technology works, and expect the algorithms to adapt to the world. This is almost certainly wrong.<p>&quot;it&#x27;s specific problems chosen specifically for their likely ease in solving using current methods. DeepMind didn&#x27;t decide to take on protein folding at random; they looked around and picked a problem that they thought they could solve.&quot;<p>I&#x27;m actually not sure this is at all true. Protein folding is a long-standing grand challenge on which no current methods were working. My guess is that it was initially chosen for potential impact, and chased with more resources after some initial success.')