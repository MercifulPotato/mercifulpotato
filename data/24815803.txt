Item(by='stingraycharles', descendants=None, kids=None, score=None, time=1603000621, title=None, item_type='comment', url=None, parent=24815577, text='Not OP, but I work for QuasarDB and we deal with a lot of customers in this sector.<p>It’s typically a mix of everything, but predictive maintenance, anomaly detection and failure analysis are the most common. For example, there is one process that does trend analysis and tries to “predict” acceptable boundaries of a certain sensor’s measurements, and this is then compared in real-time with the actual sensor readings. If things fail for some reason, a technical engineer will dive into the data with dashboards (think: Grafana), zoom in, compare the readings with other sensors, etc.<p>The sheer volume of the data makes it fairly painful. Downsampling does happen, but only after a few weeks. This means that you still need enough storage capacity to deal with the full stream of data in real-time.')