Item(by='DanBC', descendants=None, kids=[25297656, 25297490, 25297480, 25298051], score=None, time=1607040108, title=None, item_type='comment', url=None, parent=25296900, text='Here&#x27;s an article that people might be interested in. It gives a bit more detail: <a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20100706052342&#x2F;http:&#x2F;&#x2F;www.spellingsociety.org&#x2F;journals&#x2F;j20&#x2F;spellchecking.php" rel="nofollow">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20100706052342&#x2F;http:&#x2F;&#x2F;www.spelli...</a><p>I&#x27;m particularly interested in this one, and I&#x27;m curious about how useful something like this would be to use.<p>&gt; The second does not use a dictionary at all (Morris &amp; Cherry 1975). Like the previous method, it divides the text into trigrams, but it creates a table of these, noting how often each one occurs in this particular piece of text. It then goes through the text again calculating an index of peculiarity for each word on the basis of the trigrams it contains. Given pkxie, for instance, it would probably find that this was the only word in the text containing pkx and kxi (and possibly xie too), so it would rate it highly peculiar. The word fairy, by contrast, would get a low rating since fai, air and iry probably all occur elsewhere, perhaps quite often, in the passage being analysed. Having completed its analysis, it draws the user&#x27;s attention to any words with a high peculiarity index. Like the previous method, it would fail to spot a high proportion of ordinary spelling errors, but it is quite good at spotting typing errors, which it was designed for. An advantage that it has over all dictionary-based methods is that it is not tied to English; it will work on passages of, say, French, German or Greek.<p>(The Morris there is Bob Morris).')