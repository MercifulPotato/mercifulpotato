Item(by='Tainnor', descendants=None, kids=[24661770, 24661663], score=None, time=1601638396, title=None, item_type='comment', url=None, parent=24661330, text='You&#x27;re right about the lookup being constant and insertions not, I didn&#x27;t think it through well enough before posting. :)<p>But I disagree about the O notation. The O notation is just a mathematical notation, it defines certain classes of functions. It can be used for many different things, worst-case complexity is one, but not the only one. It&#x27;s perfectly possible (and quite common) to describe expected complexity (which is a mathematical function of the input size, too) with O notation.<p>People do look at expected complexity for probabilistic algorithms and data structures and they are useful. The idea that &quot;O notation is not useful and you should perform benchmarks&quot; should also be taken with a grain of salt, you don&#x27;t always have time to perform benchmarks (and for good benchmarks, you also have to make some assumptions about the data, in particular when it comes to probabilistic data structures), while you can just read up on O notation for common algorithms (and do a quick in-your-head calculation for custom algorithms, e.g. three nested loops, then it&#x27;s probably O(n^3), not always of course) and use that at least as a very useful first-order approximation.<p>But you&#x27;re right that it&#x27;s more complex: one of the best examples of this is that the simplex algorithm for linear optimisation is not known to be polynomial (in fact, I think for every possible variant of the algorithm that has so far been proposed, we know that it can degenerate to exponential time with bad inputs), but somehow that doesn&#x27;t appear to be an issue in practice - it is my understanding that nobody fully understands why not. There are proven polynomial algorithms for linear optimisation, but they are more complicated and therefore less often used.')