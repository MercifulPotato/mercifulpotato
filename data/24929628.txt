Item(by='barrkel', descendants=None, kids=[24930189], score=None, time=1603973453, title=None, item_type='comment', url=None, parent=24928283, text='Microservices will add latency because network calls are much slower than in-process calls.<p>Microservices, as an architectural choice, are most properly chosen to manage complexity - product and organizational - almost by brute force, since you really have to work to violate abstraction boundaries when you only have some kind of RPC to work with. To the degree that they can improve performance, it&#x27;s by removing confounding factors; one service won&#x27;t slow down another by competing for limited CPU or database bandwidth if they&#x27;ve got their own stack. If you&#x27;re paying attention, you&#x27;ll notice that this is going to cost more, not less, because you&#x27;re allocating excess capacity to prevent noisy neighbour effects.<p>Breaking up a monolith into parts which can scale independently can be done in a way that doesn&#x27;t require a microservice architecture. For example, use some kind of sharding for the data layer (I&#x27;m a fan of Vitess), and two scaling groups, one for processing external API requests (your web server layer), and another for asynchronous background job processing (whether it&#x27;s a job queue or workers pulling from a message queue or possibly both, depends on the type of app), with dynamic allocation of compute when load increases - this is something where k8s autoscale possibly combined with cluster autoscaling shines. This kind of split doesn&#x27;t do much for product complexity, or giving different teams the ability to release parts of the product on their own schedule, use heterogeneous technology or have the flexibility to choose their own tech stack for their corner of the big picture, etc.')