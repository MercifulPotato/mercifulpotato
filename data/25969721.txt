Item(by='dragontamer', descendants=None, kids=[25969775], score=None, time=1612019852, title=None, item_type='comment', url=None, parent=25969699, text='A 32-wide SIMD core executing 16 or 8 or 1-thread at a time is just SIMD execution that&#x27;s running at 50%, 25%, or 3% utilization.<p>See figure 22 and figure 23 in: <a href="https:&#x2F;&#x2F;images.nvidia.com&#x2F;content&#x2F;volta-architecture&#x2F;pdf&#x2F;volta-architecture-whitepaper.pdf" rel="nofollow">https:&#x2F;&#x2F;images.nvidia.com&#x2F;content&#x2F;volta-architecture&#x2F;pdf&#x2F;vol...</a><p>Thread divergence is bad: very very bad. Running 2x, 4x, or 32x slower (or less parallel technically). You want to avoid those situations as much as possible.<p>What NVidia noticed is that thread divergence is necessary for many classical locking algorithms: where serialized code must execute one-at-a-time to run an algorithm correctly. Under these conditions, tracking the instruction pointer, and turning off 97% of your cores to execute 1-at-a-time (instead of 32-at-a-time SIMD) is done.<p>That&#x27;s WHY __syncwarp() exists, so that you can return to 32-at-a-time execution as soon as possible. Its not always possible for the compiler to figure it out, so the programmer can put a __syncwarp() as a compiler hint that 32-at-a-time is safe again.')