Item(by='pontus', descendants=None, kids=[25579602], score=None, time=1609306185, title=None, item_type='comment', url=None, parent=25577021, text='I agree that it&#x27;s important to be able to reproduce existing theories. What I don&#x27;t think is fair is to say that because we have not yet figured out a way to perform this reduction we should throw the theory out. There&#x27;s a difference between a theory being untestable even in principle and being untestable because we have not yet understood the theory well enough.<p>I like the analogy of a hash function. Imagine that someone gave you the exact specification of a hash function (e.g. sha256) as well as the hash value of a list of inputs. The only thing missing from the story is the salt that was used in hashing the inputs. You&#x27;re asked to make a prediction of what ought to happen when you hash the string &quot;hello&quot;, but unless you know the salt you can&#x27;t figure it out. So, you study all the examples provided and try to find collisions so that you can figure out what the salt is. The problem is that while it&#x27;s easy to hash values, it&#x27;s very hard to find collisions. It&#x27;s really frustrating because in some sense you have all the information you need, but unless you&#x27;re able to find vulnerabilities in sha256, you can&#x27;t move forward. So, you spend a lot of time trying to understand what this hash function is really doing. Maybe some day you&#x27;ll crack it at which point you&#x27;ll be able to figure out the salt and ultimately make your prediction. However, until that day people around you keep telling you that you&#x27;re being silly because your theory lacks predictive power. They say things like &quot;your theory can predict anything you want it to, just pick your favorite salt and it&#x27;ll output whatever you want!&quot;. It&#x27;s not that the theory is necessarily wrong, it&#x27;s that you don&#x27;t fully understand it yet.')