Item(by='donmcronald', descendants=None, kids=[25482789, 25481302], score=None, time=1608405410, title=None, item_type='comment', url=None, parent=25479836, text='Since computers are unbiased, the idea is that machine learning is also unbiased.  However, that&#x27;s not true and, if anything, it actually re-enforces a lot of bias.<p>I&#x27;ve never done any, but my understanding is that machine learning is just correlation.  It&#x27;s good at figuring out &quot;what&quot;, but not &quot;why&quot;.  Consider training an algorithm to recognize horses by feeding it millions of pictures of horses.  Eventually, the algorithm &quot;learns&quot; what a horse is, <i>but</i> it&#x27;s definition of a horse is based on the inputs it was given by a human.<p>So now, consider the scenario where the millions of pictures of horses were all brown.  If you give the algorithm a picture of a white horse, it&#x27;ll tell you it&#x27;s not a horse.  If you give it a picture of a brown donkey, it might think it&#x27;s a horse because it&#x27;s learned to put too much emphasis on the color brown.<p>If that algorithm becomes relied on to define a horse, &quot;the system&quot; will insist there are no white horses even though you can walk outside and see them plain as day.<p>Now, apply the same kind of idea and feed an algorithm mugshots of all criminals.  It&#x27;s going to develop the same bias and tell you that a black person is more likely to be a criminal than a white person.  There&#x27;s no nuance.  The inputs used to train the AI were tainted by decades of systematic discrimination, but the AI doesn&#x27;t know that.<p>Of course you could try to take that input bias into account, but the whole sales pitch of machine learning is that you feed it tons of data and it gives you an objective result.  As far as I know, no one is trying to quantify, and correct, the biases in the inputs.<p>The phrase &quot;money laundering for bias&quot; means the machine learning algorithms are used to re-enforce incorrect opinions and assumptions because it gives the excuse that an &quot;objective&quot; computer used cold hard data to draw the same conclusion.<p>Machine learning is one of the scariest parts of tech right now because it&#x27;s the equivalent of an extremely stupid person that only understands correlation and not causality and the systems being built are going to be making <i>a lot</i> of decisions at scale.')