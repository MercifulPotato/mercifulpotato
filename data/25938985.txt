Item(by='Nbox9', descendants=None, kids=[25939025, 25947080, 25939228], score=None, time=1611816647, title=None, item_type='comment', url=None, parent=25936521, text='This highlights a need in the market for tools to help moderate a community.  Imagine a tool that automatically detects hate speech and either auto-deletes or brings it to a moderator’s attention.  Certain communities are being highjacked by extremist, racist, and simply malicious actors.  The current method of reading chat and banning users doesn’t scale when sudden growth occurs.<p>If effective moderation can occur at smaller levels, like discord channels or subreddits, then those communities won’t been to be removed by the larger platform.  This would also be helpful for startup social media platforms that have yet to bring enough revenue to afford a facebook sized moderation team.<p>Technically speaking it can do things like:<p>* Flag posts that contain a blacklist of words, including non-obvious spellings of said word (using non-standard Unicode characters in place of letters)<p>* Cross reference IP addresses or user names with banned users in other communities<p>* Notify moderators of trending slogans, phrases, or hashtags that have non-obvious extremist roots.<p>* Identify images containing extremist&#x2F;hateful content<p>* Flag content that contains any political discussion for communities that want to be completely apolitical.<p>* Flag pornography<p>EDIT: To be clear, the target audience for this would be community moderators&#x2F;admins or startup social networks that haven’t built their own moderation infrastructure.')