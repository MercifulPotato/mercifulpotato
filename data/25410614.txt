Item(by='jandrewrogers', descendants=None, kids=None, score=None, time=1607895876, title=None, item_type='comment', url=None, parent=25408556, text='One modern systems, preemptive multitasking has a surprisingly high overhead. Much of your CPU time can be spent on context switching and the associated cache thrashing, which isn&#x27;t productive. Furthermore, many kinds of macro-optimizations based on temporal locality stop working because preemption can randomly inject badly chosen computation into your carefully crafted computational sequencing. Preemptive multitasking makes it more difficult to ensure robustness under load generally because the default behavior of the system is that it will happily do the wrong thing at the wrong time under stress, because the OS has no idea what the right thing is, which can aggravate the situation. Obviously, none of this applies to systems that are typically under light-to-modest load.<p>For servers with hardware capable of very high bandwidth I&#x2F;O, preemptive multitasking is a major drag on performance and scalability. Hence why &quot;thread-per-core&quot; software architectures are idiomatic for high-performance data infrastructure software these days. You don&#x27;t just gain significant absolute performance, the behavior can also degrade more gracefully under extreme load.<p>Like with all things, it depends on what you are doing. I&#x27;ve designed database engines both ways and Linux is not opinionated about such things.')