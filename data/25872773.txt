Item(by='quentusrex', descendants=None, kids=[25873010], score=None, time=1611331264, title=None, item_type='comment', url=None, parent=25867693, text='I&#x27;ve been using DD in production usage for just over a year now for low latency(sub second from event IRL to pipeline CDC output) processing in a geo-distributed environment(100&#x27;s of locations globally coordinating) some days at the TB per day level of event ingest.<p>DD for me was one of the final attempts to find something, anything, that could handle the requirements I was working with, because Spark, Flink, and others just couldn&#x27;t reasonably get close to what I was looking for. The closest 2nd place was Apache Flink.<p>Over the last year I&#x27;ve read through the DD and TD codebases about 5-7 times fully. Even with that, I&#x27;m often in a position where I go back to my own applications to see how I had already solved a type of problem. I liken the project to taking someone use to NASCAR and dropping them into a Formula One vehicle. You&#x27;ve seen it work so much faster, and the tech and capabilities are clearly designed for so much more than you can make it do right now.<p>A few learning examples that I consider funny:<p>1. I had a graph that was on the order of about 1.2 trillion edges with about 90 million nodes. I was using serde derived structs for the edge and node structs(not simplified numerical types), which means I have to implement(or derive) a bunch of traits myself. I spent way more time than I&#x27;d like to admit trying to get .reduce() to work to remove &#x27;surplus&#x27; edges that have already been processed from the graph to shrink the working dataset. Finally in frustration and reading through the DD codebase again, I &#x27;rediscovered&#x27; .consolidate() which &#x27;just worked&#x27; taking the 1.2 trillion edges down into the 300 million edges. For instance, some of the edge values I need to work with have histograms for the distributions, and some of the scoring of those histograms is custom. Not usually an issue, except having to figure out how to implement a bunch of the traits has been a significant hurdle.<p>2. I get to constantly dance between DD&#x27;s runtime and trying to ergonomically connect the application into the tonic gRPC and tokio interfaces. Luckily I&#x27;ve found a nice pattern where I create my inter-thread communication constructs, then start up 2 rust threads, and start tokio based interfaces in one, and DD runtime and workers in the other. On bigger servers(packet.net has some great gen3 instances) I usually pin tokio to 2-8 cores, and leave the rest of the cores to DD.<p>3. Almost every new app I start, I run into the gotcha where I want to have a worker that runs only once &#x27;globally&#x27; and it&#x27;s usually the thread that I&#x27;d want to use to coordinate data ingestion. Super simple to just have a guard for if worker.index() == 0, but when deep in thought about an upcoming pipeline, it&#x27;s often forgotten.<p>4. For diagnostics, there is: <a href="https:&#x2F;&#x2F;github.com&#x2F;TimelyDataflow&#x2F;diagnostics" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;TimelyDataflow&#x2F;diagnostics</a> which has provided much needed insights when things have gotten complex. Usually it&#x27;s been &#x27;just enough&#x27; to point into the right direction, but only once was the output able to point exactly to the issue I was running into.<p>5. I have really high hopes for materialize.io That&#x27;s really the type of system I&#x27;d want to use in 80% of the cases I&#x27;m using DD right now. I&#x27;ve been following them for about a year now, and the progress is incredible, but my use cases seem more likely to be supported in the 0.8-&gt;1.3 roadmap range.<p>6. I&#x27;ve wanted to have a way to express &#x27;use no more than 250GB of ram&#x27; and have some way to get a compile time feedback that a fixed dataset won&#x27;t be able to process the pipeline with that much resources. It&#x27;d be far better if the system could adjust its internal runtime approach in order to stay within the limits.')