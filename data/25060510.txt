Item(by='ineedasername', descendants=None, kids=[25062068], score=None, time=1605116031, title=None, item_type='comment', url=None, parent=25055456, text='There&#x27;s a few ways to infer whether or not a 1% response rate is truly representative, or if there&#x27;s some selection bias with responders responding because they&#x27;re different that non responders beyond that one simple binary behavior.<p>My job is basically data analyst&#x2F;programmer, but I have a decent background in research of this sort (not politics, surveys and qualitative research) and occasionally have to conduct surveys. It often falls to me, or I insist on it, because practically no one knows how to write quality survey questions that aren&#x27;t leading questions that bias the response.<p>For example, if you wanted an opinion on a new food product, someone that doesn&#x27;t know how to ask a neutral question (or is purposely rigging the survey) could ask &quot;How much do you like these french fries? 1) Fantastic 2) Very Good 3) Good 4) Okay 5) Awful. Those answers are front stacked with positive answers, only one negative answer, and no neutral answer. If someone doesn&#x27;t believe they&#x27;re awful, they have no choice but to answer &quot;okay&quot;.<p>In any case, one common method I use to measure the presence of responder selection bias is a followup communication to non-responders 1-2 weeks later to nudge them to take the survey. The hypothesis is that people who did not response initially, but do respond when prodded again, will represent a middle point between initial responders &amp; complete non-responders. If that middle point is not statistically significant in their responses that the original responders, I can infer that non-responders are less likely to be a group that would answer differently if had bothered to answer.<p>No, this is absolutely not a perfect method. More robust methods are needed to further reduce uncertainty: Ethnographic &amp; other qualitative studies can help. Talk to responders to find out what they responded and consider the inverse. e.g., if they say &quot;this is a really important election we have to get Trump out and I want to spread the word so it was important to share my opinion&quot; that should make you question whether Trump supporters would feel the same way about responding.<p>To <i>really</i> get to non-responders, you need more time &amp; more resources. Find them and pay them to talk to you. It&#x27;s not uncommon to reward research participants who certainly wouldn&#x27;t participate otherwise.<p>Again, none of these are perfect, they just inch you close to greater understanding a little bit at a time.')