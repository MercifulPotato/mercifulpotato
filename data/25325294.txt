Item(by='Straw', descendants=None, kids=[25327659, 25325491], score=None, time=1607278246, title=None, item_type='comment', url=None, parent=25314830, text='The kernel they find is a function of the gradient descent path, which is a function of the data. So no, its nothing at all like a normal kernel machine, where we pick the kernel before seeing the data.<p>It also only applies to the continuous limit of non-stochastic GD, far from the real training methods used.<p>We don&#x27;t gain any understanding either; understanding implies predictive power about some new situation, and I don&#x27;t see any- and nor does the paper suggest them.<p>Looks like yet another attempt to attract attention by &quot;understanding&quot; NNs. Look, humans can&#x27;t explain or understand how we drive, speak, translate, play chess, etc, so why should we expect to understand how models that do these work? Of course, we can understand the principles of the training process, and in fact we already do- the theory of SGD is well understood.')