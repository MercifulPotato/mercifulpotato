Item(by='1996', descendants=None, kids=None, score=None, time=1605980732, title=None, item_type='comment', url=None, parent=25170547, text='Just, no! This is good for a hobby or B2C, but not for serious stuff that must work 24&#x2F;7.<p>First, about my impression from the title: it&#x27;s not only the code put into production that matters: it&#x27;s the experience and history of all the code that was decommissioned from production because of issues, or the code that almost made it to production but didn&#x27;t because of some critical issue found at the last minute.<p>Maybe I&#x27;m the exception, but I often leave that code, commented out, in the sources - and I keep adding more and more!<p>I know it&#x27;s not proper in this day in age (git, documentation etc. should be the place it goes) but that&#x27;s the only place where I&#x27;m 100% positive a pair of eyeball WILL see that FOR SURE.<p>It&#x27;s a way to avoid institutional knowledge loss when working in teams, but also a way to avoid forgetting what you did when you work on projects spanning multiple years.<p>Now for the points raised, (2) is bad: what you buy you don&#x27;t understand when or how it may fail. Bitten once, twice shy...<p>So yes, I also go for manual QC (5), and staging environment (8), actually with production split in 4 : both running different version of the code (current, and previous), each with their own backup, because for what I do, (9) is unacceptable: if there&#x27;s a break in 24&#x2F;7 operation, the business closes.<p>Consequently, for (3), deployments are voluntarily made NOT EASY and are manual. It doesn&#x27;t add much extra friction, because code reaching a production server will at least have been reviewed by eyeballs forced to read what failed before (in comments), who&#x27;ll then have had to (5) quality control themselves to avoid feeling too sure about themselves, after which the code will have to prove its worth in (8) a staging environment for a few weeks.<p>Then, if something bad happens, back to the design board and eyeballing. If not, the code is just &quot;good enough&quot; to be deployed on half the fleet, replacing the oldest &quot;known good&quot; version first on the backup servers, then on the main servers.<p>And... that&#x27;s how it stays until the next main version.<p>If some unforeseen problem is discovered, the previous &quot;known good&quot; version is still available on half the fleet. If the server has a hardware problem, the backup server with the N-1 version of the code is the final thing that remains between business and usual and &quot;the 24&#x2F;7 contract is broken, clients leave, the business closes&quot;.<p>I sell data feed with SLA guaranteeing 24&#x2F;7 operation, and latency parameters. I&#x27;ve been going on for 3 years with only 1 failure that came close to interrupting production... but didn&#x27;t. Each lesson was dearly learned.')