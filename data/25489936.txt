Item(by='sdenton4', descendants=None, kids=[25490787], score=None, time=1608501748, title=None, item_type='comment', url=None, parent=25489850, text='Backprop is good at giving credit where credit is due: you&#x27;re looking at the impact of each weight on loss, which allows changing each weight to improve the loss, by an appropriate amount proportional to the other weights. You can even have some negative weight gradients and some positive; ie, it may be that even with a &#x27;good&#x27; overall result that it&#x27;s best to turn down a particular weight.<p>So my guess is that this approach would either take a much longer time to converge (as there&#x27;s less information transmitted back for the neuron updates) or stall out completely.<p>Probably not too hard to code up, if you want to try it. But I would also be pretty surprised if it hadn&#x27;t been tried before.')