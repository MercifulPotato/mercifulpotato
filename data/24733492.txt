Item(by='jon37', descendants=None, kids=None, score=None, time=1602271577, title=None, item_type='comment', url=None, parent=24732888, text='The classic rebuttal to free speech arguments which I&#x27;m sure you&#x27;ve heard, is that the first amendment doesn&#x27;t apply to private companies, and that your right to free speech doesn&#x27;t entitle you to a megaphone, etc.<p>I think a more nuanced and useful way to look at things is to think of Twitter as an amplification machine rather than a speech machine.  I can say what I want out loud, I can write whatever letters I want, I can make my own website if I want, etc., but putting it on Twitter causes Twitter to amplify it.  Many of these announced changes pertain to what Twitter chooses to amplify - and how - rather than what it permits people to say.  (As far as I can tell, the only tweets they are actually <i>removing</i> are those that call for violence, a standard for censorship that seems quite reasonable.)<p>If we think in terms of how and when to amplify speech, rather than trying to figure out what kind of speech to censor, we can hit upon more workable improvements.  Twitter&#x27;s proposals here, under that framing, are a mixed bag.<p>Twitter provides several ways to amplify posts - some of which are intentional on the part of users, some not.  For example, if I follow a person, I&#x27;m telling Twitter to show all that person&#x27;s posts in my feed.  If I reply to a tweet, I&#x27;m telling Twitter to show my post to that person in their notifications, and also show it to other people who engage with it.  If I quote-rt a tweet, I&#x27;m telling Twitter to show it to everyone who follows me, alongside my commentary.  Etc.<p>On the other hand, if I like a post, or engage with it in any way, I&#x27;m not telling Twitter to show it to anyone - but my Like may cause it to recommend the post to others, sort it upward in the algorithmic timeline, etc. This unintentional amplification can have unintended consequences, because the system cannot tell when engagement metrics are due to positive or negative characteristics of the post.<p>Quote-retweets are also rife with unintended consequences. If someone &quot;dunks&quot; on a post by quote-retweeting it with criticism or mockery, they&#x27;re betting that their comment is going to lower the status of the person they are quoting or persuade people the post is false.  But the folks reading their post may not agree - and the original post might have been an bad faith attempt at distraction, which a dunk then amplifies.  Alternatively, if a popular account dunks on a much less popular account, it can (sometimes intentionally, sometimes not) trigger a wave of hostility and harassment.<p>So I like parts of Twitter&#x27;s changes here - they have the right to try and amplify true information more than false information, and removing flagged posts from recommendations will do that.  Additionally, removing recommended content from non-followed accounts from the algorithmic timeline is positive as well - it reduces unintentional amplification and puts more control in the hands of users. But their encouragement of the quote-retweet is concerning. They don&#x27;t seem to realize how effective a weapon it can be.<p>I would argue that any automated recommendation of user-generated content needs to be carefully controlled, if not abolished altogether.  Recommendation systems cannot distinguish between content with high engagement due to quality, and high engagement due to emotionally manipulative dishonesty or other negative factors.  And specially interested (or bigoted) political actors, who are simply interested in &quot;the most effective way to attack &#x2F; promote X&quot; rather than arriving at the most truthful position, can test and manipulate those recommendation systems far more effectively than folks trying to engage with nuance and good faith.<p>This &quot;situation where lies so easily go viral&quot; seems to me to have intensified starting in around 2014 to 2015 - when Twitter introduced the quote-retweet, and Facebook introduced the algorithmic timeline.  I don&#x27;t think &quot;free speech&quot; is the right framing for thinking about it.  The recent phenomenon is not the <i>existence</i> of extremist political movements or medical misinformation, but rather, their <i>amplification</i>.')