Item(by='btwillard', descendants=None, kids=[25440882], score=None, time=1608097384, title=None, item_type='comment', url=None, parent=25436656, text='Hello, I&#x27;m the person spearheading this Theano fork!  Your comments match my experience with the old Theano very well, so I have to respond.<p>&gt; Apparently, the main new feature for Theano will be the JAX backend.<p>The JAX transpilation feature arose as a quick example of how flexible Theano can be, both in terms of its &quot;hackability&quot; and its simple yet effective foundation (i.e. &quot;static&quot; graphs).  It&#x27;s definitely not the main focus of the fork, but it is easily the newest feature that stands out at the user-level.<p>The points you raised about the old Theano are actually the main focus, and we&#x27;ve already made large internal changes that address a few of them directly.  At the very least, nearly all of them are on the roadmap toward our new library named &quot;Aesara&quot;.<p>The `Scan` `Op` and its optimizations are definitely going to change, and I have no intention of sacrificing improvements for backward compatibility, or anything else that would constrain the extent of improvements.  I too have dealt with the difficulties involved in writing Scan optimizations (e.g. <a href="https:&#x2F;&#x2F;github.com&#x2F;pymc-devs&#x2F;symbolic-pymc&#x2F;blob&#x2F;master&#x2F;symbolic_pymc&#x2F;theano&#x2F;opt.py" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;pymc-devs&#x2F;symbolic-pymc&#x2F;blob&#x2F;master&#x2F;symbo...</a>) and am painfully aware of how unnecessary most of them are.<p>&gt; - The graph building and esp the graph optimizations are very slow. This is because all the logic is done in pure Python. ...<p>The most important graph optimization performance problems are not actually related to Python performance; they&#x27;re demonstrably design and implementation induced.  That is unless you&#x27;re talking exclusively about graphs so large they reach the &quot;natural&quot; limits of Python performance by definition.  Even then, a nearly one-to-one C translation isn&#x27;t likely to solve those scaling problems.<p>For example, the graph optimization&#x2F;rewriting framework would require entire graphs to be copied at multiple points in the process, and this was almost completely due to some design oddities.  We&#x27;ve already made all of the large-scale changes needed in order to remedy this design constraint, so we&#x27;re well on our way to fixing that.  See <a href="https:&#x2F;&#x2F;github.com&#x2F;pymc-devs&#x2F;Theano-PyMC&#x2F;pull&#x2F;158" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;pymc-devs&#x2F;Theano-PyMC&#x2F;pull&#x2F;158</a><p>The rewriting process also doesn&#x27;t track or use node information very well (or at all), so the whole optimization process itself can take an unnecessary number of passes through a graph.  For instance, its &quot;local&quot; optimizations have a &quot;tracking&quot; option that specifies the `Op` types to which they apply; however, that feature isn&#x27;t even used unless the local optimizations are applied by a `LocalOptGroup`.  I&#x27;ve noticed at least a few instances in which these local optimizations are applied to inapplicable `Op`s on each visit to a node.  Worse yet, within `LocalOptGroup` those local optimizations aren&#x27;t applied directly to the relevant `Op`s, even though the requisite `Op` type-to-node information is readily available.  In other words, optimizations could be directly applied to the relevant nodes in these cases and dramatically reduce the amount of blind graph traversals performed.<p>At best, a reimplementation in a language with a better compiler, like C, would largely amount to a questionable brute-force attempt at performance, and the ease of manipulating graphs and developing graph rewrites would suffer.  With Aesara, we&#x27;re going for the opposite.  We want a smarter framework and _more_ focus on domain-specific optimizations (e.g. linear&#x2F;tensor algebra, statistics, computer science) from the domain experts themselves, so code transparency and ease of development really matters.  When we need raw performance in specific areas of the code, we&#x27;ll pinpoint those areas and write C extensions, in standard Python fashion.<p>&gt; ... When switching to TensorFlow, building the graph felt almost instant in comparison. ...<p>Last I checked, TensorFlow had almost no default graph optimizations, aside from some basic CSE and minor canonicalization and algebraic simplifications in the `grappler` module, so it absolutely should be instantaneous.  More importantly, TensorFlow isn&#x27;t designed for graph rewriting, and definitely not at the Python level where rapid prototyping and testing is possible outside of Google.<p>Otherwise, if you&#x27;re talking about initially _building_ a graph and not calling `theano.function`, there are no optimizations involved.  Latency in that case would be something entirely different and well worth reproducing for an issue.  If what you were observing was the effect of calling `theano.function`, the latency was most likely due to the C transpilation and subsequent compilation.  That&#x27;s a feature that necessarily takes time, but produces code that&#x27;s often faster than TensorFlow even today.<p>In summary, the changes we&#x27;re most focused on right now are for developers like yourself who have had to deal with the core of Theano, so, please, stop by the fork and help us make a better `Scan`!')