Item(by='throwaway189262', descendants=None, kids=None, score=None, time=1606297842, title=None, item_type='comment', url=None, parent=25195864, text='&gt; The problem is, without some kind of firewall (e.g. WAF), our application has to absorb so much traffic, and that&#x27;s the issue. We need to block it at the edge.<p>I think you need some high performance ingestion code.<p>One day somebody is going to load test or misconfigure their site. Or you&#x27;ll get a really big client. Or somebody will get Reddit frontpaged or slashdotted. Blocking huge volumes of traffic isn&#x27;t always going to be an option. You should be able to handle it.<p>I would get off all this &quot;sexy&quot; stuff like lamdba and SQS and build some old school battle boxes at a co-lo. Run some extreme performance framework like Actix or Vert.X built to handle giant piles of traffic. A single box with those frameworks and a 40 gig line can handle millions of requests a second.<p>Use counting bloom filters synced between boxes for IP blocking. This avoids saving IP&#x27;s and is needed to prevent ram exhaustion attacks anyways. Use two layers, one for individual IP&#x27;s and a second for blocking subnets with lots of bad actors in them. Block for ~24h by using dual sets of bloom filters in a sliding window with 12h overlap where IP&#x27;s get added to both. When a filter is 24h old, discard it. This needs to be done because you can&#x27;t remove items from Bloom filters, they saturate over time.<p>On these super boxes you can do filter, blocking, batching, and dedup. Then send the data off to wherever for further processing.<p>You mentioned not wanting to use Cloudflare because they&#x27;re a competitor. That&#x27;s fine but I would take a look at their blog. They go over the tech they use for mass data ingestion and filtering, and it&#x27;s basically what I just described.')