Item(by='jtmarmon', descendants=None, kids=None, score=None, time=1603993085, title=None, item_type='comment', url=None, parent=24932651, text='Key bits of the abstract (below the fold):<p>Abstractâ€” Goal: We hypothesized that COVID-19 subjects,\nespecially including asymptomatics, could be accurately\ndiscriminated only from a forced-cough cell phone recording using\nArtificial Intelligence. To train our MIT Open Voice model we\nbuilt a data collection pipeline of COVID-19 cough recordings\nthrough our website (opensigma.mit.edu) between April and May\n2020 and created the largest audio COVID<p>....<p>Results: When validated with subjects diagnosed using an\nofficial test, the model achieves COVID-19 sensitivity of 98.5%\nwith a specificity of 94.2% (AUC: 0.97). For asymptomatic\nsubjects it achieves sensitivity of 100% with a specificity of 83.2%.')