Item(by='MayeulC', descendants=None, kids=[24842015], score=None, time=1603223569, title=None, item_type='comment', url=None, parent=24840972, text='I was really confused for a moment, because the article mention CUDA a lot, which is a nvidia-specific API&#x2F;framework&#x2F;language. I guess that&#x27;s mainly to appeal to the CUDA crowd? However, Julia being seemingly based on LLVM, interfacing it with AMD GPUs should be quite doable:<p>&gt; Much of the initial work focused on developing tools that make it possible to write low-level code in Julia. For example, we developed the LLVM.jl package that gives us access to the LLVM APIs. Recently, our focus has shifted towards generalizing this functionality so that other GPU back-ends, like AMDGPU.jl or oneAPI.jl can benefit from developments to CUDA.jl. Vendor-neutral array operations, for examples, are now implemented in GPUArrays.jl whereas shared compiler functionality now lives in GPUCompiler.jl. That should make it possible to work on several GPU back-ends, even though most of them are maintained by only a single developer.<p>This is the takeaway to me. First-class access to GPU accelerators using the same syntax, regardless of the vendor :)')