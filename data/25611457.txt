Item(by='WalterBright', descendants=None, kids=None, score=None, time=1609579384, title=None, item_type='comment', url=None, parent=25611280, text='Some principles:<p>1. Code that looks right should be right, code that looks wrong should be wrong. (I know this sounds trite, but there are many examples.)<p>2. When a program self-detects a fault in its logic, it must stop immediately, as it no longer will be in a known state. (It&#x27;s still common practice to imagine one can recover from an assertion failure. I&#x27;ve spent many, many hours trying to convince other programmers of this.)<p>3. Better education will not prevent programming bugs. Better process and mechanical checking will. (This notion has been gaining a lot of momentum.)<p>4. Reliable systems can be built from unreliable components.\n<a href="https:&#x2F;&#x2F;www.digitalmars.com&#x2F;articles&#x2F;b39.html" rel="nofollow">https:&#x2F;&#x2F;www.digitalmars.com&#x2F;articles&#x2F;b39.html</a><p>&gt; Do you think these advantages are common among those who have (mech&#x2F;electrical&#x2F;chem&#x2F;etc.) engineering education and training who move into software development?<p>Heck, they haven&#x27;t even trickled into the nuclear power industry (Fukushima), the oil business (Deepwater Horizon), or the automobile industry (Toyota surging problem). Those disasters taught lessons learned by the aviation industry decades earlier.<p>See also:<p><a href="https:&#x2F;&#x2F;www.slideshare.net&#x2F;dcacm&#x2F;patterns-of-human-error" rel="nofollow">https:&#x2F;&#x2F;www.slideshare.net&#x2F;dcacm&#x2F;patterns-of-human-error</a><p>Perhaps I should amend my earlier statement that it&#x27;s experience in the aviation business that I&#x27;ve taken over to software. My engineering training was mostly about math, not cutting metal and the nut behind the wheel.')