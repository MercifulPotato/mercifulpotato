Item(by='dragontamer', descendants=None, kids=[25164715, 25167522, 25165425], score=None, time=1605902167, title=None, item_type='comment', url=None, parent=25164123, text='&gt; Do you happen to know where to find any resources on how Apple managed to make the M1 so good compared to the competition?<p>If you know computer microarchitecture, the specs have been discussed all across the internet by now. Reorder buffers, execution widths, everything.<p>If you don&#x27;t know how to read those specs... well... that&#x27;s a bit harder. I don&#x27;t really know how to help ya there. Maybe read Agner Fog&#x27;s microarchitecture manual until you understand the subject, and then read the M1 microarchitecture discussions?<p>I do realize this is a non-answer. But... I&#x27;m not sure if there&#x27;s any way to easily understand computer microarchitecture unless you put effort to learn it.<p><a href="https:&#x2F;&#x2F;www.agner.org&#x2F;optimize&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.agner.org&#x2F;optimize&#x2F;</a><p>Read Manual #3: Microarchitecture. Understand what all these parts of a modern CPU does. Then, when you look at something like the M1&#x27;s design, it becomes obvious what all those parts are doing.<p>&gt; And why this has not happened before with other manufacturers?<p>1. Apple is on TSMC 5nm, and no one else can afford that yet. So they have the most advanced  process in the world, and Apple pays top-dollar to TSMC to ensure they&#x27;re the first on the new node.<p>2. Apple has made some interesting decisions that runs very much counter to Intel and AMD&#x27;s approach. Intel is pushing wider vector units, as you might know (AVX512), and despite the poo-pooing of AVX512, it gets the job done. AMD&#x27;s approach is &quot;more cores&quot;, they have a 4-wide execution unit and are splitting up their chips across multiple dies now to give better-and-better multithreaded performance.<p>Apple&#x27;s decision to make a 8-wide decoder engine is a decision, a compromise, which will make scaling up to more-cores more difficult. Apple&#x27;s core is simply the biggest core on the market.<p>Whereas AMD decided that 4-wide decode was enough (and then split into new cores), Apple ran the math and came out with the opposite conclusion, pushing for 8-wide decode instead. As such, the M1 will achieve the best single-threaded numbers.<p>---------<p>Note that Apple has also largely given up on SIMD-execute. ARM 128-bit vectors are supported, but AVX2 from x86 land and AVX512 support 256-bit and 512-bit vectors respectively.<p>As such, the M1&#x27;s 128-bit wide vectors are its weak point, and it shows. Apple has decided that integer-performance is more important. It seems like Apple is using either its iGPU or Neural Engine for regular math &#x2F; compute applications however. (The Neural Engine is a VLIW architecture, and iGPUs are of course just a wider SIMD unit in general). So Apple&#x27;s strategy seems to be to offload the SIMD-compute to other, more specialized computers (still on the same SoC).')