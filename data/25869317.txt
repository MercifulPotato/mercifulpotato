Item(by='vlovich123', descendants=None, kids=None, score=None, time=1611300177, title=None, item_type='comment', url=None, parent=25863724, text='I think there are niche use-cases that would warrant the cost&#x2F;complexity trade-off. Namely cloud infrastructure for databases where you might be processing large amounts and transferring all that data first to the CPU is pretty ridiculous.<p>I think the complexity problem is solvable. If you can build such a thing for memory, you can reuse the same general concept for storage like NVME&#x2F;SSD&#x2F;spinning disk. It’s entirely possible this is warranted even in consumer devices as quite a bit of OS operations deal with modifying&#x2F;querying memory whereas doing offload can win you some serious wins (making the machine feel way more snappy&#x2F;interactive + more powerful to execute things locally).<p>I don’t have hope for traditional CPU designers so the question is whether someone can both design a memory system with this power AND a computational model that makes this easy to adopt in major languages while offering a perf win (given that a memory fetch costs ~100ns for ~256 bytes). It’s challenging and unlikely to come from x86 land where back Hw compatibility is extremely important. The innovation may eventually come from mobile land (which is where Apple is coming from) where memory controllers are custom designed and part of the SoC anyway, changing with each revision, so the hard part remains again how you make this fast, efficient, able to handle multiple concurrent programs (or at least have the OS control coarsest which program’s memory accesses were being prioritized), and language integration (so you can hand off an algorithm and it would be executed without upending existing software design knowledge). The OS integration could be even more intelligent - if the process&#x2F;thread is spending its time processing memory without returning results to the CPU, just put it to sleep until the result is available (separating memory access and CPU utilization, resulting in drastically better utilization of cycles rather than naively waiting for each memory stall one at a time).<p>So tldr I agree with you totally. This is not going to happen if memory manufacturers continue to go for the “cheap and large” memory route. I do see hope that such concepts may be explored if we get more innovation in the CPU space.')