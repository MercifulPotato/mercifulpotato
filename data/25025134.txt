Item(by='YeGoblynQueenne', descendants=None, kids=[25026577], score=None, time=1604836338, title=None, item_type='comment', url=None, parent=25022011, text='While waiting for Veedrac&#x27;s reply to my comment, I thought I&#x27;d clarify here what I meant by &quot;statistical pattern recognition&quot;. &quot;Pattern recognition&quot; is the name of the sub-field of AI research from which statistical machine learning grew into what it is today, for example many problems in machine vision are typically considered as pattern recognition problems, etc. &quot;Statistical&quot; refers to the methods used to achieve the task, e.g. neural networks are normally filed under &quot;statistical AI&quot; (for historical reasons).<p>Like I say in my previous comment, modern machine learning research started as a discipline that was separate from pattern recognition (and Pattern Recognition was sometimes considered distinct to AI, as a research subject). I quote below from Tom Mitchell&#x27;s wildly influential paper, &quot;Generalisation as Search&quot; (AI 18, 1982):<p>&quot;<i>5.2. Statistical pattern recognition</i><p><i>The field of statistical pattern recognition deals with one important subclass of generalization problems. In this subclass, the instances are represented by points in n-space, and the generalizations are represented by decision surfaces in n-space (e.g. hyperplanes, polynomials of specified degree). The matching predicate corresponds to determining whether a given point (instance) lies on one side or another of a given decision surface (generalization). The field of Statistical Pattern Recognition has developed very good generalization methods for particular classes of decision surfaces. Many of these methods are relatively insensitive to errors in the data and some have well understood statistical convergence properties, under certain assumptions about the probability distribution of input instances.</i>&quot;<p>&quot;<i>In contrast to work in Statistical Pattern Recognition, work on the generalization problem within Artificial Intelligence has focused on problems involving a different class of instance and generalization languages. These languages are incompatible with numerically oriented representations that describe objects as feature vectors in n-space. For example, Winston&#x27;s program [21] for learning descriptions of simple block structures such as arches and towers, represents instance block structures in terms of their component blocks and relationships among these. In this domain the natural representation for instances is a generalized graph rather than a feature vector. (...)</i><p><a href="https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;0004370282900406" rel="nofollow">https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;000437...</a><p>Pattern recognition these days is dominated by neural methods, e.g. CNNs for object classification etc. and so is machine learning so it kind of makes sense that the three terms are used interchangeably, but unfortunately many people are not aware of the historical context of the terms, hence misunderstandings as the one by Veedrac above, regarding my comment that machine learning has become a byword for statistical pattern recognition: it&#x27;s not because I&#x27;m dismissive of statistical pattern recognition, or of the ability of deep learning systems to perform it; it&#x27;s because the terms have really become interchangeable and I think even among researchers.<p>In any case, before commenting on a complex subject of research with a long history, my recommendation remains to first become well acquainted with the subject and its history. Otherwise, one runs the risk of appearing confused.<p>Edit: Note that Mitchell&#x27;s use of &quot;generalisation&quot; in the excerpt above does <i>not</i> refer to the ability of a model to generalise to test, or unseen, data. Rather, &quot;generalisation&quot; in Mitchell&#x27;s paper refers to the ability of a system &quot;<i>to take into account a large number of specific observations, then to extract and retain the important common features that characterize classes of these observations.</i>&quot; Mitchell&#x27;s paper describes a theory of search guided by generalisation relations between hypotheses and observations.')