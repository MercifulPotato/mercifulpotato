Item(by='schmooser', descendants=None, kids=[25591728, 25591300, 25591863], score=None, time=1609407723, title=None, item_type='comment', url=None, parent=25588898, text='I’m building data pipelines in AWS (s3&#x2F;sqs&#x2F;dynamo&#x2F;api gw&#x2F;lambda&#x2F;batch) + Snowflake.<p>Earlier this year I tried to use Terraform for everything, using principle “everything is a resource” (everything in my case is AWS, Datadog and Snowflake), so adopted “terraform apply” as universal deployment interface. Like if we need a ECR task and a Docker image, build the image from within Terraform (using null_resource which runs “docker build”). This approach works for everything but Lambda as Terraform requires a pointer to source code bundle at the plan stage. After unsuccessful fights I gave up for Lambda, so I build bundles prior to “terraform apply” (using “make build”, where build target does its magic of zipping either Go binary or Babashka Clojure sources).<p>That approach scales well for already two dozens of Lambdas and counting. Ping me if you want more details.<p>——<p>I disagree with this tutorial about tendency to use Terraform modules per AWS service, hiding well-documented AWS resources behind the facade of module with custom parameters with long names.')