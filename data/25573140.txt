Item(by='crispyambulance', descendants=None, kids=[25573661], score=None, time=1609266976, title=None, item_type='comment', url=None, parent=25569865, text='I think Dan has braggadoccio&#x27;d his time estimates, or his task is somewhat different from what he describes. I mean, the guy talks fast, like really fast, so I suppose he&#x27;s quick but mere minutes for something like this doesn&#x27;t seem realistic unless it&#x27;s extremely routine. Instead, it seems ad-hoc-ish and exploratory to me, it seems like something that needs to be considered and planned out rather than done between 2 sips of coffee. (I am considering his whole task here, not just the scp&#x27;ing of files).<p>He&#x27;s talking about log files from a few hundred THOUSAND servers that results in several terabytes of data that have to be parsed. He doesn&#x27;t say exactly what he&#x27;s looking for, but the point is he&#x27;s trying to answer some questions about performance for more than a few different applications. Are these simple questions, or involved ones which spawn other questions? We don&#x27;t know, but even if they&#x27;re easy questions, there&#x27;s many applications involved and many servers.<p>Right off the bat, for something THAT BIG, I think it&#x27;s reasonable to figure out what you&#x27;re going to do with a sample of logs before downloading &quot;home depot&quot; onto your hard-drive. So this is definitely a multi-pass kind of job: start with a survey, then try a bigger chunk, if everything&#x27;s OK do the rest.<p>Next, I think it&#x27;s advisable to consider factors about the servers themselves: the application versions, whether or not the applications were running (and why not), the hardware, the role of the server, whether or not the server was up (and why not). Is this metadata about each server available (can you trust it?) or is it something that has to be queried each time on each server? Dan says this supposed to be a couple of years of data, has each server been through upgrades? when? Is that relevant? We don&#x27;t know any of these, but they would have to at least be considered for someone doing this task.<p>After the data is parsed there&#x27;s slicing and dicing to do for the purpose of graphs. That takes lotsa of time-- I am assuming he&#x27;s not just talking about extracting one figure for each application and plotting it.<p>For someone that is all set-up and on top of things, this seems like something that is a day&#x27;s work and easily more, not counting follow-up work and validation to further investigate the additional questions that would inevitably (in my opinion) be raised on such a big dataset.')