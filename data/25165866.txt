Item(by='zomglings', descendants=None, kids=[25166496], score=None, time=1605911469, title=None, item_type='comment', url=None, parent=25162803, text='nbdev looks promising. I&#x27;m wondering if it solves what I see as the biggest pain of using notebooks when I&#x27;m doing data science work.<p>When a notebook gets large, it can be difficult to keep track of dependencies between cells. For workflows in which you have to run cells n_1, n_2, ..., n_k before running cell n.<p>I try to organize my cells so that if I run them from first to last, all dependencies are covered (e.g. &quot;Restart kernel and run all cells).<p>Unfortunately, this doesn&#x27;t help when I discover a bug in cell n_2 and don&#x27;t want to run ALL cells n_2 + 1, ..., n-1, n because some of them carry out expensive operations.<p>When working in my editor, the way I resolve this is to make a light CLI wrapper around my program (if __name__ == &quot;__main__&quot;: import argparse; ...) and my CLI commands encode all this dependency information.<p>Is it possible to get this kind of experience in a Jupyter notebook without building a custom plugin (I think a frontend plugin would suffice)?')