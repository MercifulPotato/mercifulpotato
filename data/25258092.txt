Item(by='pkage', descendants=None, kids=None, score=None, time=1606765833, title=None, item_type='comment', url=None, parent=25253029, text='R Guidotti et. al[0] wrote a good literature survey on black-box explainers, and contains a summary table on page 20 of the current state of the art.<p>In terms of designing NN-based ML, the above paper has some info and this paper by S Teso[1] is a good place to start looking further (though it is focused on XAL). SENNs are cool, but ultimately most inherenly interpretable models come down to classic ML (decision trees, linear&#x2F;logreg, etc.) which is limiting compared to the power of NNs. Post-hoc explanations are basically the only option (esp. for DNNs).<p>[0] <a href="http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1802.01933" rel="nofollow">http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1802.01933</a><p>[1] <a href="https:&#x2F;&#x2F;www.semanticscholar.org&#x2F;paper&#x2F;Toward-Faithful-Explanatory-Active-Learning-with-Teso&#x2F;a0564ba7ef9f37c286c55f0703fdbe1cc1937a90" rel="nofollow">https:&#x2F;&#x2F;www.semanticscholar.org&#x2F;paper&#x2F;Toward-Faithful-Explan...</a>')