Item(by='GistNoesis', descendants=None, kids=[25569511], score=None, time=1609246878, title=None, item_type='comment', url=None, parent=25557431, text='Now we have engines that ship for free all these techniques prepackaged. The whole ecosystem, hardware included, has been built to serve this way of rendering.<p>With general programming GPU, like CUDA, we can have the flexibility of software and the performance of traditional hardware pipelines.<p>Hopefully we will soon be able to add some neural networks in the rendering pipeline. Instead of computing expensive light effects, we could be faking them. For example the foliage could probably be handled better by just rendering a semantic mask indicating where the grass is, and let the neural network do some in-painting.<p>Neural rendering seems like a great way to get some speed-ups. On a powerful machine you render with High quality (eventually cinematographic quality), and you render the same scene with very low quality, and you train a neural network to convert the low quality into the high quality. At game\ntime, you render low-quality and predict with the neural network the high quality image. It&#x27;s a trade-off of sacrificing accuracy to gain speed but because humans are bad at evaluating accuracy, it&#x27;s poised to be worth it.<p>The additional advantage of using neural rendering is that you don&#x27;t need to spend as much creating the assets. You can get rid of one of the biggest mistake in 3D history, the invention of the triangle mesh. Representing objects as a list of textured triangle is just a bad representation. The main reason they are bad is that they are 2D surfaces in a 3D world which introduce some geometrical constraints that need to be solved explicitly when you deform the object, or you will get some artifacts<p>Alternative representations like dense or sparse point-clouds either in feature-space or color-space, or implicit fields representation don&#x27;t suffer from these. Their main issue was the need to be converted back to triangles for rendering. These representations are continuously deform-able, which means you can use machine learning to infer them.')