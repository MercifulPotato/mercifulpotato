Item(by='the-rc', descendants=None, kids=None, score=None, time=1607179093, title=None, item_type='comment', url=None, parent=25312314, text='The number is probably quite a bit lower. The Strubell paper uses a PUE coefficient of 1.58, while Google datacenters are at 1.1. The figures are for GPUs, but Google uses TPUs, whose power characteristics were not public. Price is a proximate for power usage, though. TPUs might have been half as expensive in that experiment. Let&#x27;s say that a further half of those gains are money that goes to Nvidia and not really related to power. So, making numbers up, training with TPUs might be another 25% more efficient. That&#x27;s probably conservative, as Google claims that the TPUs are tens of times less power-hungry, due to their simplicity, but on the other hand, you also other fixed costs like racks, fabric and the CPUs to feed the chips.<p>In an ideal world, nobody would get hung up on details and everybody would understand that there is a lot of nuance when comparing things. In practice, if Google published a paper which quoted the Strubell paper without the caveats, I can see headlines about how inefficient and bad for the environment Google Translate is. PR would get busy and obtain corrections or follow-up articles to clarify things, but those rarely get the same attention. And it&#x27;s still extra work that could have been avoided, which in itself is bad optics (&quot;do you folks even review the stuff you send out for publication?&quot;).<p>I&#x27;m all for reducing emissions and improving efficiency, but I find the premise a bit of a stretch.<p>Yes, large and wealthy organizations have a big advantage, but that applies to pretty much anything they do, not just language models. Inefficiencies are bad, but if you ask a number of people why fix them, I think they&#x27;d mention financial cost and wasted time well before looking at it as an issue of ethics and fairness.<p>Reducing costs for language models is already a great idea across all fronts. So is reducing inequalities. It&#x27;s linking the two that sounds like a strained argument to me. Suppose someone makes models ten times smaller next week. Will marginalized communities&#x27; lives improve soon? There must be more. I haven&#x27;t seen the paper, so I&#x27;m curious how it is all framed.')