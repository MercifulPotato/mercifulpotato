Item(by='tel', descendants=None, kids=None, score=None, time=1608729523, title=None, item_type='comment', url=None, parent=25516691, text='Bayesian modeling has a somewhat distinct feeling to both (typical) deep learning algorithms and boosting&#x2F;bagging classifiers.<p>Most particularly, Bayesian modeling tends to be generative modeling as opposed to discriminative. This means that you construct your model by describing a process which generates your observed data from a set of latent&#x2F;unknown quantities.<p>For instance, we might observe that n[u, d] clicks are observed on user u on day d for various choices of u and d. We could build a variety of generative stories here: that n[u, d] is independent of u and d, just being a random draw from a Normal(mu, sigma) distribution; that n[u, d] incorporates another unknown parameter p[u], the user&#x27;s propensity to click, and then is a random draw from Normal(mu + b p[u], sigma); or that we also include season trends sm[d] and ss[d] to both the mean and spread of n[u, d], saying it&#x27;s Normal(mu + b p[u] + sm[d], sigma * ss[d]).<p>In these examples, the unknown latents are parameters like mu, sigma, and b as well as any latent data needed to give shape to p[-], sm[-], and ss[-]. Once we&#x27;ve posited the structure of this generative model, we&#x27;d like to infer what values those latents might take as informed by the data.<p>This is the bread and butter of Stan modeling. It lets you describe these generative models as a &quot;forward&quot; process where we sample latents in a simple forward program. Similar to Tensorflow&#x2F;etc Stan extracts from this forward program a DAG and computes derivatives, but instead of simply maximizing an objective function through backdrop, Stan uses these derivatives to perform a sampling algorithm over the latents (mu, sigma, b).<p>Ultimately, this gives you a distribution of plausible latent configurations given the data you&#x27;ve observed. This <i>distribution</i> is a key point of Bayesian modeling and can provide a lot of information beyond what the objective-maximizing value would. As a simple example, it&#x27;s trivial from a Bayesian output distribution to make statements like &quot;we&#x27;re 95% confident that mu &gt; 0.1&quot;.')