Item(by='renewiltord', descendants=None, kids=[25292666], score=None, time=1607018321, title=None, item_type='comment', url=None, parent=25291750, text='In the interest of explaining (not arguing), I believe the distinction is sort of that the community at large recognizes performance only on certain metrics. Let&#x27;s set aside the notion of whether something or someone is &quot;racist&quot; because that&#x27;s a bit charged. We&#x27;ll instead just talk about whether we&#x27;re creating generally capable systems.<p>For instance, if I were to champion metric A which purports to measure performance on human faces but it really only rewards performance on Senegalese then models that do better in general may not be recognized for being better.<p>In an isolated sense this is not a problem. However if the mainstream is that all metrics that are taken seriously are dataset-biased then we&#x27;ll have an environment where the models will be trained on biased datasets in order to be successful.<p>For instance if everyone uses LFW to determine how good facial recognition is, then Senegalese fine-tuned facial recognition tech will not be recognized as being good at facial recognition.<p>So the argument is that dataset bias is built-in to our approach to the problem. I, personally, think that this isn&#x27;t malice. We need benchmarks to judge approaches against each other. Benchmarks always have a first mover advantage and a massive path dependence issue. The first benchmarks aiming for things on humans do not reflect humanity accurately. These benchmarks became standard among the community. To be taken seriously you have to do well on benchmarks that are standard in the community. Dataset bias is then natural in newer approaches because the approaches are judged against how good they are against the inaccurate (if you will) benchmarks.<p>So no one need be racist or anything for the end result of the field to end up being discriminatory.<p>I don&#x27;t think a successful approach is to call people racist over this. After all, it isn&#x27;t malice that guides them. The discrimination comes from the sort of historical accident that has North facing up on a map. And no individual is really racist. It&#x27;s sort of like the Bechdel test: no movie is crappy simply because it doesn&#x27;t have two girls talking to each other, but if very few movies have two girls talking to each other about something other than boys, then it makes you think &quot;hmmm, why&#x27;s that the case&quot;.')