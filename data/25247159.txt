Item(by='ncmncm', descendants=None, kids=None, score=None, time=1606676674, title=None, item_type='comment', url=None, parent=25238720, text='A perfect sending congestion control algorithm would need to trust the receiver, which we don&#x27;t usually get, on the internets.<p>It is possible, in TCP, to lie and make the sender flood the route, by acknowledging packets not actually received. Protocols that allow requests for retransmission of ranges enable exploiting this loophole, but it does not seem often abused.<p>When you can trust the receiver implicitly, you can accept reports of end-to-end forward packet transmission time from it, and feed those to a predictor. When the time is increasing, the sending rate is too high; when decreasing, the rate could be higher. This allows ignoring packet loss as a signal, which is good because it is very noisy; it is caused by many things other than congestion.<p>Given a predictor, control theory provides easy means to tune sending rate exactly to the instantaneous capacity of the channel, and vary as other traffic begins and ends.<p>(Interestingly, round-trip time does not work for this. The channel carrying ACKs has completely different characteristics, so RTT is nearly useless. That does not stop people from trying!)<p>TCP, at its best, fails to use most of the channel, when RTT gets long. It is possible to adjust the sending rate in real time to consume exactly all of the usable bandwidth that TCP does not, so that TCP sees no effect from the better-controlled traffic, and is only slowed by sharing with other TCP streams.<p>The above is the basis for the Aspera file-transfer system, for which IBM still gets <i>huge</i> license fees from military, medical, extraction, and media customers.')