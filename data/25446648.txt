Item(by='weswpg', descendants=None, kids=None, score=None, time=1608144581, title=None, item_type='comment', url=None, parent=25446634, text='From Facebook Reality Labs:<p>&gt; Today in Nature Communications, Chang and David Moses, a postdoctoral scholar in Chang’s lab at UCSF, published the results of a study demonstrating that brain activity recorded while people speak could be used to almost instantly decode what they were saying into text on a computer screen. While previous decoding work has been done offline, the key contribution in this paper is that the UCSF team was able to decode a small set of full, spoken words and phrases from brain activity in real time — a first in the field of BCI research. The researchers emphasize that their algorithm is so far only capable of recognizing a small set of words and phrases, but ongoing work aims to translate much larger vocabularies with dramatically lower error rate<p><a href="https:&#x2F;&#x2F;tech.fb.com&#x2F;imagining-a-new-interface-hands-free-communication-without-saying-a-word&#x2F;" rel="nofollow">https:&#x2F;&#x2F;tech.fb.com&#x2F;imagining-a-new-interface-hands-free-com...</a>')