Item(by='DyslexicAtheist', descendants=None, kids=None, score=None, time=1611679814, title=None, item_type='comment', url=None, parent=25917439, text='if this is important to some users (to me it is) why blindly trust an application&#x27;s claim of what it does without verifying&#x2F;restricting it[1]? The IMHO logical step for a user (again most don&#x27;t care) would be to sandbox the application with a precise set of calls that are whitelisted and judge the application not based on trust but based on what they allowed in their security controls (firejail, apparmor, seccomp, SElinux, ...) and so immediately see if they did something different (that breaks the promise&#x2F;trust)? (even then browsers have million lines of code so even with best intentions ymmv)<p>Reading&#x2F;writing clipboards is a problem for sandboxing since they act as a bridge to another layer that otherwise has no contract or understanding of the application. So are many other features not just on browsers but on any application that for some reason needs to handle a gazillion tings (on Linux subscribing to system&#x2F;user dbus messages is a big issue and out of the box totally unmitigated).<p>[1] If a monolith like chrome&#x2F;firefox needs to understand&#x2F;parse hundreds of protocols, technology-standards, etc, is a challenge to sandbox, maybe it isn&#x27;t the sandboxing but the application that is the wrong tool for the users threat-model? Note, there is also Tor&#x2F;Tails&#x2F;QubesOS if isolation between user-space applications is a serious concern.')