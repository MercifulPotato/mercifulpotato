Item(by='kelnos', descendants=None, kids=None, score=None, time=1609883818, title=None, item_type='comment', url=None, parent=25650283, text='&gt; <i>The odds of me dying in a car crash is lower than the average as a result of precautions I take to be safe.</i><p>I&#x27;m not specifically accusing you of this, but consider that more people than is numerically possible believe that they&#x27;re better&#x2F;safer than the average driver.  There are a <i>lot</i> of people who believe they are much safer drivers than they actually are.<p>Regardless, just because you believe that you personally will be a safer driver than a computer, we should scrap the whole thing?  What about all the people who <i>aren&#x27;t</i> better drivers than the computer?  Let&#x27;s assume for a moment that you actually are safer than the eventual self-driving systems that are approved for general use -- which is by no means a certain assumption to make -- then maybe you just don&#x27;t use or ride in a self-driving car?  It&#x27;s your choice, after all (especially in a place like the US, where I imagine manual-drive car ownership in a self-driving world will end up nearly as closely protected as firearm ownership).  And sure, maybe someone else&#x27;s self-driving car might hit you and kill you, but someone else&#x27;s human-driven car might do the same.  And if self-driving cars are doing that at lower rates than humans are, it&#x27;s still a net win.<p>I think many people are taking this weird view that even though a self-driving car might make fewer mistakes (and cause fewer deaths) overall, it&#x27;s somehow a worse situation that they&#x27;ll likely make <i>different</i> mistakes than a human would; that is, a self-driving car might kill you in a situation where a human driver would save you.  And that somehow makes the whole thing not worth it.  I just find that line of reasoning to be flat-out wrong.  It&#x27;s an emotional appeal to some illusion of control.  (Of course, unfortunately, logic doesn&#x27;t write laws when it comes to contentious issues... emotion does.)<p>&gt; <i>The focus on potential glitches is because it&#x27;s something the driver has no control over.</i><p>This is pretty short-sighted, because there are a ton of things that you have no control over when you drive your own car, and yet you&#x27;ve decided (in many cases likely unconsciously) that those things are acceptable risks.<p>I&#x27;m not saying you should ignore the possible risk of glitches, but focusing on a number that we don&#x27;t even know yet, and immediately assuming that it will be too high for your risk tolerance is... a bit weird?<p>And that&#x27;s the thing: I don&#x27;t expect self-driving systems that have equal or worse crash records than humans do will be approved for use.  And if they are, people will (rightly!) reject them.  So any approved, accepted self-driving system will end up causing fewer deaths.  Some of those deaths will be caused by outright bugs, and others will be caused by situations that a human driver would not be able to recover from either.  All deaths are tragic, but fewer deaths overall is what we should be -- must be -- aiming for.  Not playing games with control illusions.  Not arbitrarily deciding that certain failure modes are somehow less acceptable than others when they cause the same (or even fewer!) deaths.<p>My position -- and what I believe to be the only logical, community minded position -- is that the glitch rate does not matter one bit.  The only thing that matters is the overall death rate, and if self-driving cars have a lower death rate than human drivers, that should be enough.  And if they don&#x27;t, they should not be approved for use, and people will rightly reject them anyway.<p>I do agree with you that companies building self-driving systems need to be liable for mistakes and negligence to the same degree as human drivers are.  Unfortunately that&#x27;s harder to prove, but it&#x27;s a necessary thing to figure out.')