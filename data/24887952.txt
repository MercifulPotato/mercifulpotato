Item(by='zurfer', descendants=None, kids=[24889929], score=None, time=1603646456, title=None, item_type='comment', url=None, parent=24886852, text='No, You don&#x27;t need more. This is compressed text. All of English Wikipedia is roughly 20 GB.\nYou can train amazing and state of the art text models with this data in addition.<p>Openai states themselves that they trained on &quot;40GB of internet text&quot;<p><a href="https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;better-language-models&#x2F;" rel="nofollow">https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;better-language-models&#x2F;</a>')