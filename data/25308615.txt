Item(by='morelisp', descendants=None, kids=None, score=None, time=1607118713, title=None, item_type='comment', url=None, parent=25308144, text='&gt; You want to strive to test that logging logs and observability observes?<p>You&#x27;re asking this rhetorically, but I often find interesting problems once I start really exercising the latter, like:<p>- Non-global collectors we forgot to register, or fail to get registered on some code paths.<p>- Collectors that get registered twice or overlap with other collectors only in some conditions (e.g. connection addresses that are sometimes the same and sometimes not depending on how your service gets distributed).<p>- Collectors that are not really safe scraping concurrently with the rest of the program; our test suites include race detectors.<p>- Metrics that don&#x27;t follow idiomatic naming conventions (can be found via e.g. `promtool check metrics`).<p>- Metrics with legitimate difficult-to-notice bugs. We had an underflow counting the size of a connection pool because `Close()`ing one twice was explicitly allowed.<p>&gt; Testing trivial code brings negative value<p>Agreed in the abstract, but if we were good judges of what code was trivial or not, we&#x27;d write a lot less bugs in the first place!<p>That being said, this is also a discussion about coverage, not assertions. Even if I&#x27;m not actually checking any of those things, those code paths (and logging) are still getting exercised via any decent E2E&#x2F;functional&#x2F;behavioral test suite.')