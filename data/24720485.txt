Item(by='sixdimensional', descendants=None, kids=None, score=None, time=1602173405, title=None, item_type='comment', url=None, parent=24719187, text='I say this as someone who built data infrastructure before and after the invention of data lakes, and I have done it every way - the old and the new..  For the record, for a lot of scenarios, the &quot;old ways&quot; actually do still work fine.  But there are new opportunities&#x2F;possibilities too.<p>I really understand what you are saying... I know the hype problem, I lived it.  It makes me both frustrated and sad - because the hype is annoying, there is a lot of vaporware - but there is also something real that is happening too which is part of the story of the evolution of data architecture&#x2F;infrastructure.  My strong advice is, being open-minded is helpful - learn and take what was good&#x2F;real and leave behind the stigma&#x2F;hype.  Something real and useful happened in terms of architecture, so take the benefits - but of course, don&#x27;t compromise on delivering real, working solutions.<p>Regarding &quot;data lakehouse&quot;, I struggle with the buzzword term also, but once again, I recommend looking at what is good&#x2F;real and ignoring the stigma of the buzzwords.  One way of looking at it is the literal translation - a data warehouse made from the components used to make data lakes.  To be honest, it is a marketing term, but it is also an architectural pattern we had even before the term existed - for example - you could use a data warehouse product such as Vertica, and back it by HDFS - guess what, there&#x27;s a data &quot;lakehouse&quot;.. and most of the big database vendors can do this trick now - a full traditional data warehouse engine sitting on top of lake storage infrastructure.<p>There are several &quot;real&quot; use cases for data lakes.  Precursor architectures could be seen to be &quot;operational data stores&quot; [1].  Data lakes are real, they are one approach to solving some problems.<p>These use cases could include: 1) raw, long term storage of large volumes of diversely structured data for staging&#x2F;historical purposes; 2) data discovery&#x2F;exploration of this data to identify patterns&#x2F;models and relationships (this is both an AI and analytics use case for power users and BI&#x2F;analytics&#x2F;data scientists, etc.); and 3) an opportunity to change the paradigm of traditional ETL - instead of pulling from sources, one way you look at it is, allowing many diverse&#x2F;distributed sources to push their data into the lake for powering analytics, exploration, AI model building, etc.  It makes sense as part of lambda&#x2F;kappa architecture as well - some of the &quot;push&quot; in can come from streaming sources as well.<p>Use case #1 is very much a &quot;data infrastructure&quot; kind of use case that we do anyway in data warehouses - especially those that do ELT (vs. ETL) - staging databases.  If you want an architecture that actually helps make some sense of such a use case of data lakes more formally, one could look into Dan Lindstedt&#x27;s data vault architecture [2].  While data vault modelling doesn&#x27;t necessarily require &quot;data lakes&quot;, the &quot;raw&quot; part of the data vault architecture use case overlaps nicely with data lakes.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Operational_data_store" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Operational_data_store</a><p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Data_vault_modeling" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Data_vault_modeling</a>')