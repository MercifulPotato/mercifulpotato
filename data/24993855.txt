Item(by='mjb', descendants=None, kids=None, score=None, time=1604530053, title=None, item_type='comment', url=None, parent=24990613, text='This is a really good post. I liked seeing the TLA+ code here. There&#x27;s a pretty serious ambiguity in the Paxos Made Simple paper, which makes it very easy to follow the paper and still end up with a broken algorithm. From Lamports publications page (<a href="https:&#x2F;&#x2F;lamport.azurewebsites.net&#x2F;pubs&#x2F;pubs.html#paxos-simple" rel="nofollow">https:&#x2F;&#x2F;lamport.azurewebsites.net&#x2F;pubs&#x2F;pubs.html#paxos-simpl...</a>):<p>&gt; In 2015, Michael Dearderuff of Amazon informed me that one sentence in this paper is ambiguous, and interpreting it the wrong way leads to an incorrect algorithm.  Dearderuff found that a number of Paxos implementations on Github implemented this incorrect algorithm.  Apparently, the implementors did not bother to read the precise description of the algorithm in [122].  I am not going to remove this ambiguity or reveal where it is.  Prose is not the way to precisely describe algorithms.  Do not try to implement the algorithm from this paper.  Use [122] instead.<p>Lamport&#x27;s core point here is using something like TLA+ to describe algorithms like this is essential. Writing is just too prone to ambiguities and misunderstandings, and the formalism really helps. The downside, obviously, is that TLA+ can look impenetrable if you&#x27;re not familiar with it. While it&#x27;s not hard to learn (the mathematical underpinnings are quite simple), the initial curve is quite steep.<p>It&#x27;s not that simpler written descriptions are bad, just that it&#x27;s hard to make them exact enough to communicate the algorithm perfectly. On the other hand, learning from the mathematical notation is pretty hard. I don&#x27;t know how to fix this problem.')