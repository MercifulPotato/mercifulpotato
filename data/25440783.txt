Item(by='nutanc', descendants=None, kids=None, score=None, time=1608112781, title=None, item_type='comment', url=None, parent=25440494, text='Empirical success shows that the GPT-3 model has seen the sequence before(maybe many times).<p>Transformer architectures do map sequences to sequences. What is not known is that the task of programming is a sequence problem. This experiment seems to suggest that maybe its not a sequence problem.')