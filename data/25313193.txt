Item(by='0-_-0', descendants=None, kids=[25313924], score=None, time=1607161931, title=None, item_type='comment', url=None, parent=25313150, text='That&#x27;s a straw man though, no classification system assigns a &quot;criminal&quot; score. Here&#x27;s another quote that points out exactly what I was talking about:<p>“There are two ways that this technology can hurt people,” says Raji who worked with Buolamwini and Gebru on Gender Shades. “One way is by not working: by virtue of having higher error rates for people of color, it puts them at greater risk. The second situation is when it does work—where you have the perfect facial recognition system, but it’s easily weaponized against communities to harass them. It’s a separate and connected conversation.” [0]<p>[0] <a href="https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2020&#x2F;06&#x2F;12&#x2F;1003482&#x2F;amazon-stopped-selling-police-face-recognition-fight&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2020&#x2F;06&#x2F;12&#x2F;1003482&#x2F;amazon-s...</a>')