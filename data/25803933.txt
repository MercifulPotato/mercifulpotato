Item(by='dragontamer', descendants=None, kids=None, score=None, time=1610820038, title=None, item_type='comment', url=None, parent=25803288, text='Big O is literally easier than the analytical alternative.<p>I didn&#x27;t &quot;understand&quot; Big-O until I read Donald Knuth&#x27;s &quot;Art of Computer Programming&quot;. I forget exactly where Knuth does this... but Knuth derives the _exact_ number of average runtime on some algorithm. (Where &quot;average&quot; is defined as all possible permutations of the input).<p>I forget why or where this derivation was, but it was along the lines of 3<i>n</i>log(n) + 5n +25, or something along those lines (I made up the numbers).<p>Solving for the specific and exact runtime of a function is very, very, very difficult. Instead of doing that, Comp. Sci has decided that the easier Big-O is &quot;good enough&quot; for most purposes.<p>That&#x27;s it. Big-O is ALWAYS easier to calculate than the exact runtime. Yeah, its still hard in some cases, and there are situations like Radix sort (O(n)) vs Quicksort (O(n*log(n)), or Karatsuba multiplication vs optimal multiplication (like O(n^1.5) vs O(n^1.4...)) where the &quot;slower Big-O&quot; is better in practice.<p>But such situations are rare, and are easily figured out through profiling.<p>---------<p>So lets do some real-talk. Most programmers don&#x27;t wait on their code anymore. Computers are so fast, that all this algorithmic complexity is a red herring compared to other issues. By and large, inefficient programming languages are being used in grossly inefficient ways and no one cares.<p>For most practical purposes, profiling with a stopwatch is your go-to methodology for analyzing algorithms. If that&#x27;s not good enough, then profiling with a dedicated profiler (which can statistically count specific situations: like cache-hits or branch-mispredictions, as well as how many times any particular line of code ran).<p>That&#x27;s the information you want and need. Take the runtimes, plot it on a log-log plot, fit a growth-exponent on the curve and BAM, you got O(n^whatever).<p>Where Big-O comes in are the situations where you&#x27;re waiting for your code to finish. You run your code, and you wait 10-minutes, 1-hour, 10-hours, 2-days... will your code finish? Do you have an infinite loop? Or is it actually making forward progress? If so, how long do you estimate it to last? (And indeed: Hollywood movies are known to take multiple days to render a single frame, so these situations come up every now an then in practice).<p>Under such a situation, you can&#x27;t really run a profiler or use a stopwatch. You probably can run a big-O analysis by pen-and-paper over your code however, and then get an estimate on the size of your data. You&#x27;ll want to make sure that you&#x27;re O(n) or O(n*log(n)). If you&#x27;re getting O(n^2) or O(n^3) from an algorithm that&#x27;s taking days to run... you might be in trouble.')