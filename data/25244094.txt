Item(by='matja', descendants=None, kids=None, score=None, time=1606643453, title=None, item_type='comment', url=None, parent=25243401, text='Yes, ZFS makes this very easy.  It&#x27;s no problem to snapshot an entire filesystem with billions of files every 5 minutes from cron.<p>Then the OP could have done:<p><pre><code>  zfs-restore-file recording-16679.flv\n</code></pre>\nWith `zfs-restore-file` as the following script (for example only, I hacked it up in a few minutes) :<p><pre><code>  #!&#x2F;bin&#x2F;bash\n  \n  FILE=&quot;$1&quot;\n  FULL_PATH=$(realpath &quot;$FILE&quot;)\n  DATASET=$(findmnt --target=&quot;${FULL_PATH}&quot; --output=SOURCE --noheadings)\n  MOUNT_POINT=$(findmnt --source=&quot;${DATASET}&quot; --output=TARGET --noheadings | head -n1)\n  CURRENT_INODE=&quot;$(stat -c %i &quot;${FULL_PATH}&quot;)&quot;\n  RELATIVE_PATH=&quot;$(echo &quot;$FULL_PATH&quot; | sed &quot;s|^${MOUNT_POINT}&#x2F;||&quot;)&quot;\n  \n  # iterate all snapshots of the dataset containing the file, most recent first\n  for SNAPSHOT in $( \\\n    zfs list -t snapshot -H -p -o creation,name &quot;${DATASET}&quot; \\\n    | sort -rn | awk &#x27;{print $2}&#x27; | cut -d@ -f2 \\\n  ) ; do\n    echo &quot;snapshot $DATASET @ $SNAPSHOT&quot;\n    SNAPSHOT_FILE=&quot;${MOUNT_POINT}&#x2F;.zfs&#x2F;snapshot&#x2F;${SNAPSHOT}&#x2F;${RELATIVE_PATH}&quot;\n    SNAPSHOT_FILE_INODE=&quot;$(stat -c %i &quot;${SNAPSHOT_FILE}&quot;)&quot;\n    if [ &quot;${SNAPSHOT_FILE_INODE}&quot; == &quot;&quot; ] || [ &quot;${SNAPSHOT_FILE_INODE}&quot; == &quot;${CURRENT_INODE}&quot; ] ;   then\n      continue\n    fi\n    echo &quot;found the same named file with a different inode:&quot;\n    ls -l &quot;${SNAPSHOT_FILE}&quot;\n    cp -i &quot;${SNAPSHOT_FILE}&quot; &quot;${FILE}&quot;\n    break\n  done\n</code></pre>\nIf OP didn&#x27;t change the inode (overwritten with new content) then you could make another script that compares size&#x2F;hash of the file, or manually specify a time of a snapshot to restore.')