Item(by='tpoacher', descendants=None, kids=None, score=None, time=1604920796, title=None, item_type='comment', url=None, parent=25031265, text='Except this is not what a p-value is supposed to tell you in the first place. It&#x27;s supposed to tell you how compatible your observations are with the ASSUMED theory. The minute you use it as an interpretation of a posterior probability (let alone a malformed one), you have violated the assumption on which you rely to interpret it.<p>To use your own example. If you picked a coin from said bag which is mostly full of otherwise unbiased coins, and your hypothesis is &quot;this coin is not biased&quot;, a sequence of ten heads would be largely &quot;incompatible&quot; with your hypothesis (as if the hypothesis of unbiasedness was true, you should only expect this result 1&#x2F;1024 times).<p>It is up to you to then place this result in the context of other prior assumptions etc, and say &quot;yes it&#x27;s incompatible but still very likely&quot;. The p-value does not preclude you from performing a post-hoc analysis of the base-rate if you so wish. It just so happens that the &#x27;assume a hypothesis&#x27; approach is a useful one in the absence of all other information. Which is not so different from a Bayesian saying &#x27;I&#x27;ll use an uninformative prior and let the data speak for itself&#x27;.<p>But using it as a test of posterior probability, especially when prior information exists, and saying &quot;ha see it sucks&quot; is not a fair criticism for it (whereas criticising its use as a test of posterior probability is).')