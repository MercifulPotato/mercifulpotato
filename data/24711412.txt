Item(by='Cybiote', descendants=None, kids=[24711475], score=None, time=1602097067, title=None, item_type='comment', url=None, parent=24710639, text='&gt; What is this sentence supposed to convey?<p>There are examples where it is able to recognize and continue patterns in strings which if manually generated, would have required a FSM. In fact, some of the more impressive examples would require a stack of some sort so I thought I was rather underselling its capabilities in that arena.<p>&gt; as GPT isn&#x27;t a &quot;state machine&quot; as the latent space is continuous and not finite.<p>Technically speaking, that is impossible since these models leverage floating point numbers and are limited in memory to whatever hidden and self-attention layers.<p>Practically speaking, in order to generate strings based on patterns as mentioned prior, there must be abstract states which correspond to states and state changes such that thinking in terms of at least state machines is useful.<p>Studying LMs in terms of automata is not strange, there have been papers which do this for specific trained RNNs (such as <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1711.09576" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1711.09576</a>). I contend GPT-3 is capable, to a certain extent, of generating these dynamically at inference time.<p>As far as I know this way of extracting what LMs are doing hasn&#x27;t been done for Transformers but you can also frame Transformers in term of RNNs so there&#x27;s no reason why such methods wouldn&#x27;t readily apply to them too.<p>&gt; Moreover, there is nothing that makes GPT-3 &quot;not capable of learning.&quot;<p>I specifically addressed that: to count as learning, without diluting the utility of the term, it has to be capable of remembering. Without permanent changes to its weights, the use of the term learning stretches the word beyond utility.')