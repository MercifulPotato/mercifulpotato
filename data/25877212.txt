Item(by='throwawaygh', descendants=None, kids=[25877287, 25877968], score=None, time=1611355346, title=None, item_type='comment', url=None, parent=25877175, text='<i>&gt;  It’s always some external thing: “the algorithm”, as if that doesn’t just mean “the way we programmed it”.</i><p>This is true.<p><i>&gt; Computing systems are do not act on their own.</i><p>That doesn&#x27;t mean that computer systems behave the way that we intend them to behave, or even that we really fully understand our own intent!<p>How much of your own code have you formally verified? (<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Formal_verification" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Formal_verification</a>)<p>How much of your own code even has a precise enough purpose that the spec of what it&#x27;s supposed to do is shorter than the length of the code? Such that you could even in theory formally verify that the implementation is in some sense &quot;correct&quot;?<p>For that matter.... how much of your code has a precise enough purpose that the spec of what it&#x27;s supposed to do can be written down in formal language <i>at all</i>?<p>And actually... how much of your code has a precise enough purpose that the spec of what it&#x27;s supposed to do can be written down in ENGLISH <i>at all</i>?<p>I don&#x27;t think something like an &quot;extremism filter&quot; can ever be implemented in a bug-free way, because I don&#x27;t think there&#x27;s a precise enough definition of what &quot;bug-free&quot; would even mean.<p>The problem of people blaming bad outcomes on &quot;the algorithm&quot; is real, and organizations should take responsibility for misclassifications generated by code that they own and operate.<p>It&#x27;s unhelpful to pretend like engineers and the organizations they work for have zero agency.<p>However, it&#x27;s equally unhelpful to pretend like buggy behavior aligns with the <i>intent</i>  of the engineer&#x2F;organization.')