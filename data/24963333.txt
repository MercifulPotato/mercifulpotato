Item(by='timscarfe', descendants=1, kids=[24963377], score=1, time=1604271758, title='AI Alignment and AGI Fire Alarm â€“ Connor Leahy', item_type='story', url=None, parent=None, text='https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HrV19SjKUss<p>This week Dr. Tim Scarfe, Alex Stenlake and Yannic Kilcher speak with AGI and AI alignment specialist Connor Leahy a machine learning engineer from Aleph Alpha and founder of EleutherAI. We cover a wide array of topics today, including philosophy, AI safety, AGI fire alarm, free-will, causal decision theory, behavioural economics, logic and game theory. Connor believes that AI alignment is philosophy with a deadline and that we are on the precipice, the stakes are astronomical. AI is important, and it will go wrong by default. Connor thinks that the singularity or intelligence explosion is near. Connor says that AGI is like climate change but worse, even harder problems, even shorter deadline and even worse consequences for the future. These problems are hard, and nobody knows what to do about them.<p>Connor also makes the big call that he thinks GPT-3 is more intelligent than humans! :)')