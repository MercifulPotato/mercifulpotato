Item(by='datameta', descendants=None, kids=None, score=None, time=1605203311, title=None, item_type='comment', url=None, parent=25072030, text='Simply put miniaturization of neural networks coupled with more powerful yet more energy efficient microcontrollers has allowed projects like this to be feasible since &#x27;19, maybe &#x27;18. In retrospect it seems an obvious next step from edge ML but at one point it looked like ML was only possible in the domain of beefy GPUs or power hungry CPUs on the cloud.<p>A cornerstone of embedded ML aka TinyML is that not sending data using comms decreases energy consumption by many magnitudes when compared to chip ops, SRAM use, sensor I&#x2F;O etc.<p>What we have is the culmination of many techniques applied in concert. A huge one is float32 -&gt; int8 quantization to compress the network 4x with usually only around ~1-2% drop in accuracy.<p>I for one am incredibly excited about the prospects of this nascent field.')