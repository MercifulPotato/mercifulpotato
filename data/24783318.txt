Item(by='jimmydorry', descendants=None, kids=[24783438, 24783360, 24783442], score=None, time=1602720931, title=None, item_type='comment', url=None, parent=24783162, text='That is also a matter for interpretation, I believe. This cuts to the heart of the raging platform vs publisher debate (section 230).<p>From my understanding, the current status quo is:<p>1. A platform can not moderate its content beyond removing illegal content that is brought to their attention;<p>2. A publisher can moderate and selectively cull what ever user content they like, but is held liable for any infringing content that breaks its ToS or the law.<p>This is a matter I strongly believe requires an update to relevant legislation and a clear &#x2F; strong precedent that can be pointed to. It feels like social media (Twitter, Facebook, etc.) is trying to be both a platform and publisher when it suits them.<p>EDIT: Made the language a bit more neutral and closer alined to the current than the &quot;should be&quot;. A child reply linked an article that is worth reading [1], however take it with a grain of salt, seeing as it&#x27;s more opinion and interpretation of intent than a reading on application of the law as it is written. This issue has been simmering away long before 2016. It&#x27;s only started to come to the foreground as the social media giants started moving closer to &quot;publisher&quot; than &quot;platform&quot;. It would have been unthinkable to see Twitter, Facebook and Youtube &quot;fact checking&quot; and adding content below posts ten years ago.<p>I see this less as a partisan issue and more of a civil rights issue. I don&#x27;t want to imagine a future where we have untouchable arbitrers of truth.<p>[1] <a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2019&#x2F;6&#x2F;21&#x2F;18700605&#x2F;section-230-internet-law-twenty-six-words-that-created-the-internet-jeff-kosseff-interview" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2019&#x2F;6&#x2F;21&#x2F;18700605&#x2F;section-230-inte...</a>')