Item(by='maest', descendants=None, kids=[25600592], score=None, time=1609465923, title=None, item_type='comment', url=None, parent=25597799, text='I think this comes down to what you think biases are and what you think should be optimised.<p>Consider the gender imbalance in tech jobs. Let&#x27;s say that is because more men pursue tech degrees than women and this is because the field is already male dominated and women don&#x27;t have female role models.<p>A hiring algorithm will optimise for the best candidate for the job. If we assume men are as good as women, the gender ratio will be skewed simply because the underlying population has a skew. However, we, as a society, may want to overweight women candidates even at a cost of choosing a slightly less fitting candidate because, in the long term, this will provide female role models and convince more women to join tech (there are reasons why this may be desirable, but it does have to be argued for).<p>Under this view, the algorithm is biased because it&#x27;s optimising for the wrong thing - it is assigning no extra value to choosing a female candidate even if we, as a society, think there is value.<p>This is a thorny issue, though, as I&#x27;ve made some assumptions above and plenty of people will disagree with them, on various grounds. Still, I think this is a useful way if thinking about biases.<p>Also, viewed like a problem of figuring out the correct function to optimise, this suggests fixing this problem via slow and heavy handed law making (e.g. a blanket rule enforcing hiring gender ratios) is probably the wrong way to do this.<p>By the way, hiring committees can also be thought of as algorithms and at least part of their biases can be explained when viewed as them optimising for the wrong thing.')