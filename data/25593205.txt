Item(by='nmfisher', descendants=None, kids=[25593241], score=None, time=1609426625, title=None, item_type='comment', url=None, parent=25592827, text='No (at least, not the version I read a few years ago). But transformers are a specific neural network architecture, so I’d still recommend the book for the fundamentals around backpropagation, activation &amp; loss functions, etc.<p>Once you’re comfortable with neural networks (and the notation), the “Attention is all you need” paper is fairly accessible.')