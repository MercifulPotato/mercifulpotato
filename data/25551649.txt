Item(by='lukeschlather', descendants=None, kids=[25551796], score=None, time=1609082981, title=None, item_type='comment', url=None, parent=25542011, text='Describing this as &quot;memorizing&quot; seems wrong. Humans often repeat things they heard earlier, and they will (honestly) swear up-and-down that the thing they&#x27;re repeating is an original thought. If we succeed in making AGI that has human-equivalent intelligence we should expect this sort of behavior.<p>The stuff about whether or not models should be destroyed if they contain copyrighted work gets kind of chilling if models actually achieve sentience someday. If I could make a faithful copy of my consciousness, my consciousness can reliably reproduce numerous copyrighted works. As can anyone.<p>Of course, most of those I deliberately memorized. I think it&#x27;s a crucial thing here that the model is not actually memorizing anything - if we assume for a moment that the model is a consciousness, these are all half-remembered snippets leaking into casual conversation. And I think it&#x27;s most likely any truly conscious entity is going to do that sort of thing from time to time.')