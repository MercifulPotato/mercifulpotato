Item(by='SarikayaKomzin', descendants=None, kids=None, score=None, time=1604640006, title=None, item_type='comment', url=None, parent=24998305, text='This is ones of those essays that pops up on Hacker News every so often, and I&#x27;m always happy to reread it. Regardless of how the technologies have changed or if the prognostications were correct, this article is about timeless and relevant themes.<p>Abstraction is the most powerful force within the human mind. It is perhaps solely responsible for the world we&#x27;ve built around us. But it is also absolutely terrifying how increasingly reliant we are on it.<p>&quot;Contemporary culture is a two-tiered system, like the Morlocks and the Eloi in H.G. Wells&#x27;s The Time Machine, except that it&#x27;s been turned upside down. In The Time Machine the Eloi were an effete upper class, supported by lots of subterranean Morlocks who kept the technological wheels turning. But in our world it&#x27;s the other way round. The Morlocks are in the minority, and they are running the show, because they understand how everything works.&quot;<p>We are more and more surrounded by technology that the majority of us don&#x27;t understand even at a fundamental level (for the record, I include myself in the Elois). More often than not, these technologies are essentially taken for granted as magic. While no reasonable person should expect everyday people to understand the inner workings of their handheld supercomputers or their cable TV box, we would all be better off if we better understood the fundamental building blocks of the technologies we are surrounded by -- whether that&#x27;s basic logic gates, the simple patterns of conditional statements in programming languages, what caching and cookies are on the web, or how a hard drive works at 30,000 feet.<p>&quot;So GUIs use metaphors to make computing easier, but they are bad metaphors. Learning to use them is essentially a word game, a process of learning new definitions of words like &quot;window&quot; and &quot;document&quot; and &quot;save&quot; that are different from, and in many cases almost diametrically opposed to, the old.&quot;<p>Like Stephenson so vividly describes, the way our technology mixes metaphors is not instructive to what&#x27;s actually happening on the metal. These lossy abstractions don&#x27;t seem harmful at face value because they aren&#x27;t, but, as they compound and more complex technologies are adopted in our homes and places of work, they threaten to make us less efficient at our jobs, more reliant on manufactures for repair and troubleshooting, more susceptible to disinformation and encroachments on our privacy, and, in my opinion most importantly, at risk for critical failures in our infrastructure (what if there aren&#x27;t enough Morlocks?)((the IoT, machine learning and social media algorithms are what really frighten me)).<p>And we haven&#x27;t even mentioned how we are now increasingly reliant on fragile systems that no single person can understand, and the dynamic nature of software means that many, many applications out there are essentially ships of Theseus that could sink at any time.<p>This isn&#x27;t hyperbolic Doomerism. I don&#x27;t think this is the Decline and Fall or anything. It&#x27;s also not a condemnation of super-abstractions or casual technology use. I, like Stephenson, am a paying Disney World customer if you will. I just believe we need to invest more into the right kinds of high-level technocratic education for the general populace (and continue to combine it with liberal arts, of course), and our technologists need to invest in redundancies and stable technologies.<p>Luckily, we have built the Library of Alexandria 2.0 in the internet; we just need to use it.<p>Some fun, relevant links off the shelves of that library:<p><a href="https:&#x2F;&#x2F;reasonablypolymorphic.com&#x2F;book&#x2F;preface.html" rel="nofollow">https:&#x2F;&#x2F;reasonablypolymorphic.com&#x2F;book&#x2F;preface.html</a><p><a href="https:&#x2F;&#x2F;blog.nelhage.com&#x2F;post&#x2F;computers-can-be-understood&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.nelhage.com&#x2F;post&#x2F;computers-can-be-understood&#x2F;</a><p><a href="https:&#x2F;&#x2F;www.nand2tetris.org&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.nand2tetris.org&#x2F;</a><p><a href="https:&#x2F;&#x2F;mcfunley.com&#x2F;choose-boring-technology" rel="nofollow">https:&#x2F;&#x2F;mcfunley.com&#x2F;choose-boring-technology</a><p><a href="https:&#x2F;&#x2F;cs.stanford.edu&#x2F;people&#x2F;nick&#x2F;how-hard-drive-works&#x2F;" rel="nofollow">https:&#x2F;&#x2F;cs.stanford.edu&#x2F;people&#x2F;nick&#x2F;how-hard-drive-works&#x2F;</a><p><a href="https:&#x2F;&#x2F;singularityhub.com&#x2F;2016&#x2F;07&#x2F;17&#x2F;the-world-will-soon-depend-on-technology-no-one-understands&#x2F;" rel="nofollow">https:&#x2F;&#x2F;singularityhub.com&#x2F;2016&#x2F;07&#x2F;17&#x2F;the-world-will-soon-de...</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Machine_Stops" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Machine_Stops</a><p><a href="https:&#x2F;&#x2F;medium.com&#x2F;message&#x2F;everything-is-broken-81e5f33a24e1" rel="nofollow">https:&#x2F;&#x2F;medium.com&#x2F;message&#x2F;everything-is-broken-81e5f33a24e1</a><p>P.S. I love this related thought experiment --&gt; <a href="https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;rebooting-civilization-survivorse28099-how-to-guide-for-restoring-technology-after-the-apocalypse-excerpt&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.scientificamerican.com&#x2F;article&#x2F;rebooting-civiliz...</a>')