Item(by='FartyMcFarter', descendants=None, kids=[25582298, 25582841, 25582860, 25582083, 25583103, 25582772, 25581982, 25582007, 25582161, 25584260, 25583643, 25582682, 25582687, 25582893], score=None, time=1609338456, title=None, item_type='comment', url=None, parent=25560295, text='&gt; ` (...) They keep pushing it to later!’ His big concern about AI isn’t Judgment Day, but rather ‘that people will believe machines actually understand things’. He gives examples of symmetrical chess configurations in which humans consistently outperform computers by abstracting to a higher level<p>This sounds a lot like the usual moving of goalposts whereby &quot;anything computers can do isn&#x27;t AI, so AI doesn&#x27;t work&quot;.<p>When AI couldn&#x27;t do anything, chess was supposed to be a demonstration of human intelligence. Now that AI can play chess and other board games, suddenly it needs to solve symmetrical configurations and think &quot;abstractly&quot; (which is left fairly loosely defined).')