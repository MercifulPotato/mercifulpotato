Item(by='chrisdalke', descendants=None, kids=None, score=None, time=1602874584, title=None, item_type='comment', url=None, parent=24781057, text='Not entirely the same use case, but I&#x27;ve had some success displaying charts of time series data using Postgres&#x27;s width_bucket function to group values into a histogram. width_bucket computes a histogram bucket for a value, which then can be used in a &quot;group by&quot; clause to group and calculate aggregate statistics for each bucket. This is pretty similar to the approach detailed in the post, but it&#x27;s providing averaged values instead of a randomly sampled distribution.<p>If you want to display a line chart that is 500px wide, for example, you know you really only need 500 data points. You can treat this chart as a histogram, and compute a min&#x2F;max&#x2F;avg for each value. The chart could display the min &amp; max as a high-low band, and if you zoom in further, adjust the histogram interval and requery.<p>This is what a query would look like with this strategy:<p><pre><code>  start_timestamp: The start of the histogram range\n  end_timestamp: The end of the histogram range\n  num_divisions: The number of histogram divisions\n\n  select\n      start_timestamp + ((bin_id - 1) * ((end_timestamp - start_timestamp) &#x2F; num_divisions)) as bin_start_at,\n      start_timestamp + ((bin_id) * ((end_timestamp - start_timestamp) &#x2F; num_divisions)) as bin_end_at,\n      average_value,\n      min_value,\n      max_value,\n      num_values\n  from (\n      select\n             avg(value) as average_value,\n             min(value) as min_value,\n             max(value) as max_value,\n             count(*) as num_values,\n             width_bucket(data_points.timestamp, start_timestamp, end_timestamp, num_divisions) as bin_id\n      from data_points\n      where\n            timestamp &gt; start_timestamp and timestamp &lt; end_timestamp\n      group by bin_id\n      order by bin_id asc\n   ) t;\n</code></pre>\nI&#x27;m interested to see if anyone else has taken this approach, and if there are any performance considerations I haven&#x27;t considered!')