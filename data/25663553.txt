Item(by='lhorie', descendants=None, kids=None, score=None, time=1609972238, title=None, item_type='comment', url=None, parent=25663093, text='&gt; The American philosopher Robert Nozick came up with a thought experiment to make the point. Nozick asks us to imagine a &quot;machine that could give you any experience you desired&quot;. The machine would allow you to experience the bliss of fulfilling your every wish. You could be a great poet, become the greatest inventor ever known, travel the Universe in a spaceship of your own design, or become a well-liked chef at a local restaurant. In reality though, you would be unconscious in a life-support tank. Because the machine makes you believe that the simulation is real, your choice is final.<p>&gt; Would you plug in? Nozick says you wouldnâ€™t because we want to actually do certain things and be certain people, not just have pleasurable experiences. This hypothetical situation might seem frivolous, but if we are willing to sacrifice limitless pleasure for real meaning, then happiness is not the highest good.<p>I think there&#x27;s a flaw in this line of reasoning. Suppose you were actually accomplished in whatever field you wanted to be, and then you found out that your entire life was a lie and in actuality you were plugged into said machine (much like the plot of The Matrix). Would you give up your reality for one where you were not only not accomplished&#x2F;happy, but also had a potentially insurmountable challenge to overcome in order to maybe get there (with a real risk that you won&#x27;t)? Generally speaking you wouldn&#x27;t because of fear of the unknown. In fact, often times people will say in old age that in hindsight they regret not taking a risk earlier in their lives to change careers because of sunk cost fallacy, or because of previous life commitments (e.g. family lifestyle), etc.<p>Another experiment that comes to mind is one where mice were hooked up to a device that delivered stimulus directly to the pleasure center in their brain. Once they realized they could activate it at will, they would lose interest in everything else, including life critical activities such as eating.<p>IMHO, what Nozick is observing is that given a choice, humans will choose the least foreign condition. The thought of being stuck in a tank subsisting on a simulated lie is not as &quot;natural&quot; as living in the real world, but if that simulation was your only reality, then the thought of being outside would be &quot;unnatural&quot;, not to mention brutal, regardless of which was the absolute reality.')