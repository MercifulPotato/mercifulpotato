Item(by='lowercased', descendants=None, kids=None, score=None, time=1607516050, title=None, item_type='comment', url=None, parent=25341006, text='Let&#x27;s stop comparing every single expense with the &quot;fully loaded cost of an average US developer&quot;.  Averages are skewed by higher end companies.  There&#x27;s some weird thinking that permeates these sorts of discussions that somehow every developer is $500k&#x2F;year, because some facebook and google engineers get stock options.<p>&quot;It seems like it would be a win if it improved productivity and&#x2F;or retention even a tiny little bit.&quot;  Why?  Perhaps your &quot;seems like&quot; is, in fact, wrong, and there&#x27;s no measurable improvement in my you the latest gear every year.  Perhaps you get a 1% &#x27;productivity improvement&#x27; over the year - on 2000 hrs, let&#x27;s say that&#x27;s 20 hrs more of &#x27;productivity&#x27; from you.  But all the overhead - purchasing overhead, inventory management, network provisioning, security checks, <i>your</i> time in moving stuff over, reinstalling&#x2F;upgrading your software, moving keys, etc - costs more than that mythical 1% of &#x27;improvement&#x27; you <i>might</i> deliver.<p>I bought my own RAM for a company-provided tower once, and a couple IT folks flipped out.  But it did make my system measurably important, and cost me... $70 at the time (something like that) - went from swapping to spinning rust all the time to everything fitting in memory, and no swapping.  But it ruffled feathers, even though the company was not out any money.<p>Take the raise.  Become an independent consultant.  Charge more.  Buy your own hardware, use what you want.')