Item(by='vczf', descendants=None, kids=[25925456], score=None, time=1611725531, title=None, item_type='comment', url=None, parent=25902030, text='I don&#x27;t think it&#x27;s a good idea to depend mainly on low-level or device-specific features (in a NAS or your filesystem) to detect bitrot and corruption in files. As a user, you don&#x27;t care WHY a file changed, only that it did so unintentionally.<p>The filesystem cannot truly know if a file being modified was intended or accidental. Sometimes a software error can wipe or corrupt a file, and a filesystem can&#x27;t detect that, even if it can detect bitflips.<p>The data architecture I use combines, in order of importance: (1) borg, for incremental deduplicated backups onsite and offsite; (2) syncthing, for duplication and synchronization across devices; (3) fim, for managing file integrity; (4) rsync, local copy to another drive for convenient restores; and (5) git, in places where commit history is actually useful, like code or dotfiles.<p>fim combined with incremental backup solves this problem, is filesystem agnostic and painless to migrate around, and is for some reason completely unknown and obscure: <a href="https:&#x2F;&#x2F;evrignaud.github.io&#x2F;fim&#x2F;" rel="nofollow">https:&#x2F;&#x2F;evrignaud.github.io&#x2F;fim&#x2F;</a>')