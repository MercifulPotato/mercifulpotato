Item(by='haberman', descendants=None, kids=None, score=None, time=1607196023, title=None, item_type='comment', url=None, parent=25316138, text='There is also a separate article from this site that speculates that Tesla&#x27;s easily observable quality problems with Autopilot are actually the result of Tesla intentionally hobbling it so drivers don&#x27;t become complacent: <a href="https:&#x2F;&#x2F;jperla.medium.com&#x2F;why-tesla-autopilot-ought-to-be-awful-until-its-perfect-8fb0b0764ef8" rel="nofollow">https:&#x2F;&#x2F;jperla.medium.com&#x2F;why-tesla-autopilot-ought-to-be-aw...</a><p>The article admits it has no evidence for this speculation (&quot;Is Tesla doing this? Perhap not.&quot;) but at other points assumes it is true (&quot;This is the Safety Paradox. Tesla cannot launch its safest, newest version of the algorithm for every driving mile because that would, paradoxically, cause more accidents since the safest, newest software would be above the L3 Barrier.&quot;)<p>It then makes the further unsupported assertion that you can measure the extent to which Tesla has &quot;perfected&quot; its self-driving capability by measuring the rate of Tesla accidents that occur when Autopilot is <i>not</i> enabled, theorizing that this is the only mode where Tesla has not hobbled its safety features.  In this mode, the article theorizes, the full power of Tesla&#x27;s self-driving technology goes to &quot;correct for human driving, as if one has a virtual bumper car, protecting and cocooning the driver.&quot;<p>In general the site seems quite pro-Tesla and anti-Waymo.<p>Disclosure: I work for Google but also own a Tesla.')