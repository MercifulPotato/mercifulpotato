Item(by='jiggawatts', descendants=None, kids=[25890272], score=None, time=1611443819, title=None, item_type='comment', url=None, parent=25885640, text='It&#x27;s possible to extract depth information from a monocular lens. There&#x27;s several ways to do this, and Tesla has talked publicly that they&#x27;ve implemented at least one approach.<p>One is depth-from-defocus combined with &quot;overlap&quot; hierarchy information that can be used to build a depth-map. This is the technique Tesla talked about. Interestingly, instead of manually coding up this algorithm, they simply trained a neural net to do it! The trick was to use the radar data as the &quot;ground truth&quot;, and train the NN to predict it based on the optical input. It works quite well, and there are videos floating about showing how a Tesla can build up an accurate 3D model of the world around it as it drives along.<p>There are other approaches as well. For example, the way birds gather depth information is they move their head. One eye takes two &quot;snapshots&quot; of the scene in rapid succession from slightly different positions, producing a stereo pair. A moving car is constantly shifting the camera positions. Note that you don&#x27;t have to be moving the cameras side-to-side, moving along the road can be enough, as the shift of the focal plane can be used as an additional channel of information for the depth-from-defocus method mentioned above. This is what some mirror-less cameras do: they shift focus back-and-forth a bit to gain more information about the scene. A moving car has the same effect.<p>Tesla has recently implemented some variant of this latter technique, they also talked about this publicly. Essentially, the first version of the self-driving hardware didn&#x27;t have the computing power to analyse multiple frames together like this. The current version has the compute power to include the last few frames as well as inputs to the NN, which gives it not just more temporal stability but also the opportunity to extract depth information from motion. (However, I&#x27;m not sure if they&#x27;ve actually used motion in this specific way.)')