Item(by='jlokier', descendants=None, kids=None, score=None, time=1606652015, title=None, item_type='comment', url=None, parent=25238033, text='&gt; it seems like you’re saying there’s absolutely no correlation whatsoever between availability of tests to the general public and the accuracy of the announced R number for the general public.<p>Depends what you mean by accuracy, whether that&#x27;s bias or uncertainty.  If you&#x27;re talking about <i>bias</i>, then I agree with the above statement.  My estimate of the mean bias in published R estimates is zero.  (Possibly on a logarithmic scale :-)<p>But if you&#x27;re talking about uncertainty and not bias, then in general more data is better provided its biases are known, but it&#x27;s hard to say that <i>focusing</i> tests on a subset of the population reduces certainty.  In a mathematical sense, to minimise uncertainty from sampling estimates if you have a fixed number of samples but a choice about which situations to assign them to, you want to focus more testing on the situations which provide the highest information content.  That is not necessarily the same as spreading them evenly through the population in an unbiased manner.<p>I think what you may be misunderstanding, and therefore misrepresenting, is the idea that a combination of statistically sampled tests (ONS) plus biased targeted tests (NHS, key workers, Test &amp; Trace etc) results in &quot;skewed&quot; or more misleading R estimates than just the statistically sampled tests (ONS) by themselves.  I think that&#x27;s unlikely.<p>I&#x27;m assuming the data is combined by competent professional statisticians.<p>Assuming they are competent, the likelihood of any biases due to NHS sampling that you or I might think of not having already been evaluated by the statisticians is negligible.<p>So, provided the bias can be estimated, combining data from multiple sources tends to reduce uncertainty rather than introducing bias in a particular direction.<p>That&#x27;s why I say my personal &quot;estimate of mean bias&quot; is zero.  Published R may by higher or lower than true R, and we can take it for granted it will be off by some amount and constantly (and retroactively) revised with new data, which is fair enough for estimations, but I have no basis on which to assume corrected results are more likely to have bias in one direction or the other.<p>A nice feature of having two or more <i>kinds</i> of sampling is that intentionally-randomly-sourced data (ONS) acts as an &quot;anchor&quot; on the interpretation of non-ONS data, allowing raw biases from various sources to be estimated and adjusted for, uncertainties to be estimated too, while at the same time <i>trends</i> (such as over time) remain trackable with the higher statistical power that comes from larger numbers of samples.<p>In other words, a bit of the best of both worlds.  And since r and R are trend parameters, that&#x27;s quite helpful.')