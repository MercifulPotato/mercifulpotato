Item(by='lawrenceyan', descendants=None, kids=[25707778], score=None, time=1610225703, title=None, item_type='comment', url=None, parent=25703212, text='Given the non-linear dynamics that proteins must live under, I like the usage of local minima as an analogy. It feels apt.<p>Generally though, within the context of machine learning, one of the benefits of gradient descent, especially when stochastic, is that we can get past those local minima humps. Does this hold less true with respect to the process of sequence mutation that viruses go through?')