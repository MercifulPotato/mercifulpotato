Item(by='dragontamer', descendants=None, kids=[25361786], score=None, time=1607535041, title=None, item_type='comment', url=None, parent=25342922, text='BDDs &#x2F; ZDDs are really cool, but this isn&#x27;t a good link for Hacker News IMO. And the title is clickbait: its not the famous Knuth quote (and the famous Knuth quote isn&#x27;t even in the blogpost).<p>Maybe the Wikipedia page is a better start. Or maybe a blogpost out there is a better description of BDDs.<p>-------<p>Okay, so what is a BDD? Lets start with what problem we&#x27;re trying to solve.<p><a href="https:&#x2F;&#x2F;www.hillelwayne.com&#x2F;post&#x2F;decision-table-patterns&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.hillelwayne.com&#x2F;post&#x2F;decision-table-patterns&#x2F;</a><p>&quot;Decision Tables are useful&quot;. Lets start with that. They&#x27;re useful in a variety of algorithms and situations. The above blogpost is your &quot;ELI5&quot; introduction to this subject.<p>Now lets start talking HARD problems, I&#x27;m talking NP-hard, like traveling salesman. We can use &quot;decision tables&quot; to decide if &quot;CityA + CityB&quot; should be in a certain order in the path, or if it should be &quot;CityB -&gt; CityA&quot;, and the like. Ultimately, its all a table of decisions, but this table starts getting big. Very, very, very big.<p>Exponentially big even. Every &quot;column&quot; you add doubles the size of the table. We can&#x27;t fundamentally get around this, but we can offer a kind of &quot;compression&quot;. Lets start with a 3-bit table and think about things.<p><pre><code>    ABC | True &#x2F; False bit\n    ----+-----------\n    000 | 1\n    001 | 0\n    010 | 0\n    011 | 0\n    100 | 1\n    101 | 1\n    110 | 1\n    111 | 1\n</code></pre>\nOkay, simple enough. But what if... we &quot;collapsed&quot; the table to compress the values?<p><pre><code>    ABC | True &#x2F; False bit\n    ----+-----------\n    000 | 1\n    001 | 0\n    01* | 0\n    1** | 1\n</code></pre>\nNow instead of taking up 8-rows, the table only takes up 4-rows. That&#x27;s the general gist of the problem: these &quot;tables&quot; clearly have compression available.<p>Now Binary Decision Trees are a compression methodology. Instead of storing a table, you store a graph. One such graph is...<p><pre><code>    A=1 -&gt; 1\n    A=0 -&gt; B=1 -&gt; 0\n    A=0 -&gt; B=0 -&gt; C=0 -&gt; 1\n    B=0 -&gt; C=1 -&gt; 0\n</code></pre>\nIts the same information as the table, but now in graph form. It achieves the &quot;compression&quot; thing we&#x27;re looking for.<p>Ultimately: that&#x27;s the goal. To &quot;compress&quot; these tables so that they take up less RAM. But we still want to perform operations on them (such as AND&#x2F;OR&#x2F;NOT, but also cross-joins and a bunch of relational-algebra). The overall discovery was that the graph-form, the Binary Decision Tree, is actually pretty efficient with a large number of operations.<p>----<p>EDIT: Ah right. And the &quot;key feature&quot; of BDDs is the ability to share &quot;subtables&quot; between different tables. Notice that B=0 has two links, so there is substantial &quot;column-savings&quot; compared to the original table.<p>The &quot;compressed table&quot; had to store 000 and 001 in two different rows. But the A=0 -&gt; B=0 link is &quot;redundant information&quot; in that situation, and itself can be compressed.<p>The graph form compresses that information, while the &quot;compressed table&quot; doesn&#x27;t. These small savings don&#x27;t matter on 3-bit examples. But on a 16-bit or 32-bit or larger graph, those sorts of things really add up to huge amounts of compression.<p>And once you start sharing subtables among &quot;unrelated&quot; tables (ex: lets say you have 100-such tables. The graph form provides an obvious &quot;common subtable&quot; that can be shared between say 20+ tables at a time. The &quot;compressed table&quot; cannot share such subtables in any obvious way).<p>You don&#x27;t want to go too crazy: the optimal sub-table compression is itself an NP complete problem. But don&#x27;t worry about that: this is quite common on NP-hard situations. You need to solve NP-hard subproblems to solve the greater NP-hard problem efficiently...<p>Instead, find a greedy, &quot;decent&quot; solution to compression. Simple heuristics (column ordering heuristics, variable-ordering heuristics, etc. etc.) and the like are common here. As long as it works kinda-sorta okay, you&#x27;re probably fine.')