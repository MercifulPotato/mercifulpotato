Item(by='KaiserPro', descendants=None, kids=[25914494, 25914345], score=None, time=1611655319, title=None, item_type='comment', url=None, parent=25907312, text='I have had the privilege of running a mixed machine learning cluster at almost this scale (5000 nodes). I would never dream of doing it on K8s. Its just not really designed to run at the this scale usefully, simply or cheaply. Especially if you have complex jobs(ie you have a bunch of dependencies, run this task before that).<p>On AWS we used batch. It runs a docker image on a machine. it takes care of all the machine prep, scheduling and error handling.It scales simply, secrets are built in (using parameter store) and you can have EFS&#x2F;lustre for file access.<p>You will however need to make a job description language, but that&#x27;s trivial (mine is a 500 line lambda)<p>Its not as nice to use as tractor&#x2F;alfred&#x2F;deadline, but it works, and doesn&#x27;t need a team of devops to keep it running optimally.<p>K8s has some appeal (widespread adoption) but its still not really a HPC workload system. It&#x27;s networking scheme is just insane (and chatty as fuck, just look at the graphs, almost 10gigs in control traffic, on AWS if you&#x27;re running in multiple az, thats about $150 an hour just in transfer alone)')