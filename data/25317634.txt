Item(by='danieldk', descendants=None, kids=None, score=None, time=1607197369, title=None, item_type='comment', url=None, parent=25316012, text='<i>There&#x27;s nothing preventing you from sharing weights across layers, and would be interesting to see some research about that.</i><p>E.g. the ALBERT model does that:<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1909.11942" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1909.11942</a><p>I have done model distillation of XLM-RoBERTa into ALBERT-based models with multiple layer groups and for the tasks that I was working on (syntax) it works really well.<p>E.g. we have gone from a finetuned ~1000MiB XLM-R base model to a 74MiB ALBERT-based model with barely any loss in accuracy.')