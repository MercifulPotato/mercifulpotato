Item(by='sixdimensional', descendants=None, kids=None, score=None, time=1603229388, title=None, item_type='comment', url=None, parent=24840995, text='I have a whole smattering of thoughts based on the article and your comment...<p>From the article: &quot;The authors say the most successful companies learn from early uses of AI and adapt their business practices based on the results.&quot;<p>This sounds exactly like the advice that ERP companies used to recommend to organizations.  Don&#x27;t try to customize the ERP, adapt your business to the out-of-the-box best practices.  Those who don&#x27;t often face huge costs and pain trying to adapt the tool to the business, rather than the other way around.<p>Interestingly, this might say more about organizational culture that encourages adaptation than anything else.  It has been said (I think Steven Hawking may have been the one) that &quot;adaptability is intelligence&quot; [1].<p>From your comment: &quot;Per Conway&#x27;s law, no organization wants to reorganize itself to use a new technology like software, they want to make the new technology an imitation of itself, old wine in 5% more efficient new skins. It takes either intense near-death-experiences (see: remote working&#x2F;corona) to force a shift, or starting up new businesses or units to be born-digital.&quot;<p>Conway&#x27;s Law is about how the design of an organization&#x27;s information systems often mirror their communication patterns.  I have seen this myself to be quite realistic, anecdotally... although.. isn&#x27;t this really kind of sad in a way?  First of all, I see this as an excuse to write off groups of people as &quot;legacy&quot; and &quot;outdated&quot; - for example, digital transformation seems to be as much about a generational shift as it is a technological one.  Or perhaps it is just showing the way - change culture&#x2F;communication - value adaptability - to change systems.<p>Laws were meant to be broken, so why the belief that because of Conway&#x27;s law, it always has to be this way, or that Conway&#x27;s law is a constraint that cannot be broken?  Certainly, we won&#x27;t change things if we aren&#x27;t willing to adapt.<p>Second, regarding the recognition of it taking near-death experiences to force change - doesn&#x27;t that seem true for the broader human population, not just organizations?  For that matter, why do we seem to be so stubborn and unable to flip these odds in our favor?  That part is frustrating.<p>Next, to starting new business or units to be &quot;born-digital&quot; - of course, I understand why people think this way, why it probably works, and why it is a go-to strategy.  But there is some part of me that this is part of disposable culture, it is partly exactly what is wrong with how we approach things - instead of incremental improvement, it is burn things down or start from scratch.  Because we can&#x27;t adapt the designs we implement, we have to start all over.. and it seems like a wasteful exercise.  Where is our logical &quot;exnovation&quot; (the opposite of innovation)?<p>Lastly, about the gap between those who become &quot;AI-enabled&quot; companies and actually achieve success, and those who do not.  In full recognition of the reality that those who do not get with the times, often get left behind, when it comes to technology - this gap worries me more.  I&#x27;m thinking here of intellectual property, and that what is the best AI model will most likely always be locked and controlled by the profit motive - and thinking, what then?<p>I suppose this is why some thinkers are so worried about an AI-enabled future (ex. Elon Musk or Stephen Hawking) - it&#x27;s not the positive potential that scares them, it&#x27;s what happens to humans [2].<p>[1] <a href="http:&#x2F;&#x2F;www.actinginbalance.com&#x2F;intelligence-is-adaptability&#x2F;" rel="nofollow">http:&#x2F;&#x2F;www.actinginbalance.com&#x2F;intelligence-is-adaptability&#x2F;</a><p>[2] <a href="https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;news&#x2F;innovations&#x2F;wp&#x2F;2018&#x2F;04&#x2F;06&#x2F;elon-musks-nightmarish-warning-ai-could-become-an-immortal-dictator-from-which-we-would-never-escape&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;news&#x2F;innovations&#x2F;wp&#x2F;2018&#x2F;04&#x2F;0...</a>')