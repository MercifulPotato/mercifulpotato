Item(by='klodolph', descendants=None, kids=[25677589], score=None, time=1610053509, title=None, item_type='comment', url=None, parent=25677188, text='&gt; A multiply in GF(2^8) is just a single multiplication lookup. 256 x 256 == 64kB lookup table. I&#x27;m not sure how much faster you can get than a single 8-bit lookup on a table small enough to fit in a typical CPU&#x27;s cache.<p>64 KB often wonâ€™t fit in L1 cache anyway.<p>&gt; A GF(2^4) multiply would be a single multiplication lookup 16 x 16 or 256 byte (0.25kB) lookup table. Very, very tiny, probably no faster than the GF(2^8) lookup.<p>Or you can do <i>three</i> operations using a single 16 x 16 x 16 x 16 lookup table, and introduce fewer data dependencies into your CPU pipeline.<p>The operations work on half as many bits, but complete three times as many steps. Sounds like a win to me.<p>&gt; I expect that 8-bit bytes is actually faster for modern computers than 4-bit nibbles. Even if you are using a severely shortened &#x2F; punctured code, there are strong benefits to sticking with 8-bit bytes on a modern computer.<p>You keep saying this. I understand how CPUs are byte-addressed. When you operate on smaller sizes, you have to do packing &#x2F; unpacking. If your CPU core spends most of its time doing table lookups, then a little bit of packing &#x2F; unpacking is nearly free, since your ALUs are otherwise fairly idle, assuming you have a couple registers free.')