Item(by='tgbugs', descendants=None, kids=None, score=None, time=1606757532, title=None, item_type='comment', url=None, parent=25253488, text='My conclusion reading this is that a gradient is a gradient is a gradient. If you can minimize one, you can minimize them all. The hard work would seem to be figuring out how to transform into a gradient that your hardware can solve. It will also be interesting to see the kinds of systematic errors that will come as a result of the biases in the training set, and whether it can be used to predict what the structures would look like under slightly different conditions (e.g. pH).')