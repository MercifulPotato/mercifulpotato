Item(by='firethief', descendants=None, kids=[25224181], score=None, time=1606422152, title=None, item_type='comment', url=None, parent=25221810, text='&gt; The more of the language you lift into the parser (decidable! easily-analyzable memory bounds!), the less you need to worry about types.<p>Doing the easy cases of type-checking at a different time doesn&#x27;t allow you to worry about types less, because you are still doing that work; just at a different time. Making it necessary to pass type information between phases increases the amount of worrying about types.<p>&gt; As a trivial case consider a language where `5 + &quot;&quot;` would fail typecheck. But why even get so far? Why does your parser accept `lit-term := lit &#x27;+&#x27; lit` and not `lit-term := [str &#x27;+&#x27; str] | [ num + num ]`, etc.<p>This approach increases the complexity of parsing so much that your trivial example is wrong. What good is `lit-term` in a language with different expression-trees for different value types? You need something like `maybe-str-expr := [maybe-str-expr &#x27;+&#x27; maybe-str-expr] | [function-call] | ...` -- where everything is `maybe-`, because enough type information is available to determine that certain things are wrong, but not enough is available to ensure everything is correctly-typed. We could strictly improve on this situation by increasing the scope of the parser, to include looking up the types of items so that it can <i>fully</i> type-check the tree and accept only validly-typed programs. We can further improve the situation by splitting the parser into two phases: one that just identifies the lexical structure of the input, and one that does the type-checking. Let&#x27;s just not call that part a type-checker -- it&#x27;s part of the &quot;parser&quot; now.')