Item(by='nemothekid', descendants=None, kids=[25870215, 25873086], score=None, time=1611293598, title=None, item_type='comment', url=None, parent=25867693, text='I&#x27;ve always been interested in distributed stream processing platforms (Storm, Spark, Samza, Flink, etc) - and I&#x27;ve been interested in a distributed processing platform that wasn&#x27;t on the JVM (there used to be one called Concord). That said, I came across differential dataflow a while ago (as I also began writing more and more Rust).<p>I think the biggest issue is the documentation, not so much on writing code, but on building an actual production service using it. I think most of us can now grok that you have a Kafka Stream on one end and a datastore on the other, and the quintessential map&#x2F;reduce hello world is WordCount.java. That doesn&#x27;t isn&#x27;t clear from the differential dataflow documentation - I remember thinking <i>how are they getting data from the outside world into this thing</i>, then thinking <i>maybe I don&#x27;t understand this project at all</i>.<p>Consider the example in the ReadMe - the hello world is &quot;counting degrees in a graph&quot;. While it gives you an idea of how simple it is to express that compuation, it isn&#x27;t interactive - it&#x27;s unclear how one might change the input parameters (or if that&#x27;s even possible). The hardest part of most of these frameworks is glue - but once you have that running then exploring what&#x27;s possible is much easier. Differential Dataflow doesn&#x27;t provide that for me right off the bat.<p>That said - I&#x27;m not surprised, when I last checked it out Rust Kafka drivers weren&#x27;t all there and it seemed to be evolving parallel to everything else. I think what would make it more popular is a mental translation of common Spark tasks (like WordCount) to differential dataflow.')