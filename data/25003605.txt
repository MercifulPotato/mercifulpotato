Item(by='hyperpape', descendants=None, kids=[25004208, 25003799, 25003747], score=None, time=1604622161, title=None, item_type='comment', url=None, parent=25003299, text='&quot;If jobs are randomly coming in at the same speed that a worker can work, you will get a line. The lines can grow without bound, and the average length of the line is linear in the amount of time this has been going on. Therefore the amount of time spend waiting in line grows quadratically with how long this has been going on.&quot;<p>I don&#x27;t think this is true, unless I&#x27;m misunderstanding your description. Do you mean if the work comes in faster than the worker can process it?<p>If work arrives at the same rate the worker can process it, the depth of the queue is a random walk starting at zero, with the restriction that it can never go below zero. I&#x27;m not sure how that behaves, but it definitely grows much less than linearly.<p>Python simulation code below:<p><pre><code>    import random\n    \n    def random_walk(steps):\n        count = 0\n        max_count = 0\n        for step in range(steps):\n            if count &gt; 0:\n                count -= 1\n            if random.random() &gt; .5:\n                count += 2\n            max_count = max(count, max_count)\n            if step in [2 ** i for i in range(14)]:\n                print(f&quot;step={step}, count={count}, max_count={max_count}&quot;)\n    \n    for i in range(10):\n        random_walk(2**13 + 1)</code></pre>')