Item(by='copy-pastries', descendants=None, kids=[25196660, 25197137], score=None, time=1606206134, title=None, item_type='comment', url=None, parent=25196124, text='Yes, it&#x27;s pretty much exactly what you said.<p>Algorithms like those for parallel solvers for systems of equations will divide the problem up into blocks of cells for parallel processing. But typically each cell&#x27;s next state calculation needs some values from its close neighbours. That&#x27;s fast and fine for cells inside a block, but for cells on the borders of blocks, that means communicating (doing &quot;halo exchange&quot;) with neighbouring processors on every iteration of a solver. Even within one GPU, that means synchronising between the GPU&#x27;s &quot;cores&quot; and reading state from the global memory (DRAM), which is orders of magnitude slower and more energy expensive than reading from the on-chip &quot;cache&quot;-style memory. These algorithms also don&#x27;t do a lot of FLOPs per cell relative to the amount of memory that is accessed, so their performance is \ncompletely bound by memory bandwidth (how fast data can get to the processor) rather than compute performance (how fast the processor can operate on it).<p>It&#x27;s much worse when the problem doesn&#x27;t fit in a single GPU: then the border tiles have to communicate with remote GPUs and CPUs, which is orders of magnitude slower and more energy intensive again. Then performance can become communication-bound.<p>Because these algorithms are core to so many science applications (like differential equation solvers), there&#x27;s a huge body of research around making them run better: overlapping communication and computation, swapping fatter halos less frequently, funky spatio-temporal tiling over blocks and loop iterations, etc.<p>The Cerebras chip does amazingly well on these because its 400000 cores can access 18GiB of fast on-chip memory and communicate state over the fifos extremely fast and with very little energy relative to a GPU or multi-CPU solution. The power requirements are a tiny fraction of the GPU equivalent.<p>But many of the problems come back when the problem being solved needs more than the 18GiB of on-chip memory, which sadly is most realistic simulations. Speed will still be limited by how quickly border data can be exchanged.')