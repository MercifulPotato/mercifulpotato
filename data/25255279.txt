Item(by='iandanforth', descendants=None, kids=[25255812], score=None, time=1606752809, title=None, item_type='comment', url=None, parent=25253248, text='A few points:<p>Their &quot;powerful AI engine&quot; is almost certainly just humans. It might have a few off-the-shelf components like face detection but most of what they claim to do is just so easy to outsource that almost all companies do it. If there is any delay between the system observing a suspect behaviour and the student being told to correct it then they are <i>definitely</i> using humans.<p>An institution using a service like this is a huge red flag. You should take it as an indicator of a low quality administration if not a low quality institution.<p>As an engineering problem this task is <i>hard.</i> Ryan Calo (Prof of Law, UW) once presented a fascinating bit of research on trying to automate something as simple as fining someone for speeding. Given perfect information how do you build the system? If someone exceeds the speed limit for 1 second, do you fine them? If everyone around the person is exceeding the speed limit do you use the same rules? If someone oscillates between just above and just below the speed limit, how many times do you fine them? If someone exceeds the speed limit and <i>stays there</i> does this result in fewer fines? How do you square the code written with the law as written? The problems are so extensive it may be that application of rules like this require <i>human level</i> judgement. Proctoring an exam may turn out to be an AI-complete problem.')