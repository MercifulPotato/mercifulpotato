Item(by='ALittleLight', descendants=None, kids=None, score=None, time=1609363329, title=None, item_type='comment', url=None, parent=25586125, text='The article suggests that the energy usage of language models is a problem.  I don&#x27;t think energy usage is a problem.  I&#x27;m not sure how you interpret this as being defensive.<p>There are hundreds of thousands of flights per day.  Adding an additional flight, or even an additional thousand flights, to substantially improve Google doesn&#x27;t seem like a big cost.  Consider: Would your life be worse if one random trans-American flight was cancelled today, or if Google searches became 10% worse?<p>Another way of thinking about this same point, is, why is the author writing about language models if they are so concerned about the environment.  Surely the airline industry is a better subject as, again, they fly hundreds of thousands of flights each day.  It&#x27;s hard to take someone seriously when they are focusing on an infinitesimal part of a huge problem.<p>It&#x27;s also misleading because there is a difference between energy used by an airline flight, where the energy comes from burning jet fuel, and energy used in a data center.  In Google&#x27;s case (the people training BERT) the energy used was 100% renewable - Google reached that goal in 2017.  Perhaps Open AI didn&#x27;t use renewable energy to train GPT-3, but I wager they didn&#x27;t power their machines by burning jet fuel either.<p>Maybe electricity used to power to train language models will become a meaningful issue at some point in the future.  I don&#x27;t think that future is close at hand though.')