Item(by='boulos', descendants=None, kids=[25175438], score=None, time=1606023142, title=None, item_type='comment', url=None, parent=25174351, text='Disclosure: I work on Google Cloud.<p>If Filestore (our managed NFS product) is too large for you, I&#x27;d suggest having gcsfuse on each box (or just use the GCS Connector for Hadoop). You won&#x27;t get the kind of NFS-style locking semantics that a real distributed filesystem would support, but it sounds like you mostly need your data scientists to be able to read and write from buckets as if they&#x27;re a local filesystem (and you wouldn&#x27;t expect them to actively be overwriting each other or something where caching gets in the way).<p>Edit: We used gcsfuse for our Supercomputing 2016 run with the folks at Fermilab. There wasn&#x27;t time to rewrite anything (we went from idea =&gt; conference in a few weeks) and since we mostly just cared about throughput it worked great.')