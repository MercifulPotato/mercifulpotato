Item(by='ChuckMcM', descendants=None, kids=[25474681], score=None, time=1608337346, title=None, item_type='comment', url=None, parent=25472843, text='Everything old is new again right? IBM, DEC, HP all built their own chips as part of their development. That got eaten alive by people like Sun and Apollo who started building workstations on commodity microprocessors, which got better and better so that even the &quot;toy&quot; computers (which is what the IBM PC started out as) became capable of eating their lunch, so they moved &quot;into chips&quot; with SPARC, PA-RISC, PowerPC which forced Intel to abortively try Itanium except that AMD kicked them in the nuts with AMD64. And that was where we lived until the computer architecture &quot;for the masses&quot; became the phone, with ARM chips and they started trickling down into the masses, and then Samsung and Apple started pushing advantages because they could customize their SoC chips and others couldn&#x27;t, and all the while Intel kept adding specialized instruction sets to try to hold off ARM and AMD from their slipping hold on the Data center and what was left of the &quot;laptop&quot; business. Intel won some small battles in the &quot;ARM Laptop&quot; wars, with Microsoft&#x27;s limited support for ARM applying pressure and Google&#x27;s largely unsuccessful ChromeOS system of Chromebooks. But then Apple started making waves with their &quot;tablet&quot; the iPad and iPad pro and were getting margins that the laptop folks could only drool over so laptop makers started making bespoke chips to &quot;up&quot; their game like the pixel &#x2F; pen processor in the Surface line. And as the iPad and the Surface and the other &quot;ultralight&quot; tablettops collided with overlapping features Apple went ahead and did the unthinkable and put a bespoke CPU into a laptop, and somehow once again managed to pull of huge margins.<p>That pretty much sealed the deal for any serious laptop makers and now we&#x27;ve got Microsoft embracing &quot;alternate&quot; instruction sets, Amazon embracing non-Intel data center architectures, and Apple out competing with a bespoke CPU in a bespoke laptop form factor.<p>&lt;opinion!&gt;\nIntel is toast. (if you were still wondering) Which truly sucks because you really really want and need a chip fab business that can compete on the global scale. Intel needs to be that business for the US (Sorry Global Foundries you had your chance)<p>RISC-V is the new 8080A, FPGAs are the new SoC. Look for a huge number of computers available in all price points based on RISC-V sitting inside FPGA fabrics. This is going to be driven by open source tools and a set of open source HDL cores for all of the &quot;essential&quot; peripherals.<p>The consumer device kingmakers will be graphics architecture suppliers. The biggest differentiator for the next few years will be &quot;can your graphics card do this?!&quot;\n&lt;&#x2F;opinion!&gt;')