Item(by='dmurray', descendants=None, kids=None, score=None, time=1608424848, title=None, item_type='comment', url=None, parent=25480257, text='&gt; Now, apply the same kind of idea and feed an algorithm mugshots of all criminals. It&#x27;s going to develop the same bias and tell you that a black person is more likely to be a criminal than a white person.<p>No. Nobody training an ML system to detect criminals would train it only with pictures of criminals. And if you somehow did, it wouldn&#x27;t determine that black people are more likely to be criminals, but that <i>humans</i> are more likely to be criminals than say ducks or fire engines.<p>Yes, ML models can end up reflecting prejudices in their training data, but this description is incorrect, reductionist and unhelpful.')