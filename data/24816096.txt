Item(by='tannhaeuser', descendants=None, kids=None, score=None, time=1603005729, title=None, item_type='comment', url=None, parent=24815820, text='No. That is exactly what a transactional DB is designed to prevent. The journal gets appended with both the old and the new data and physically written to disk, and only then the primary data representation (data and B-tree blocks) gets updated in memory, then eventually that changed data is written to DB files on disk. If the app or DB crashes during any stage, it will reconstruct primary data based on journalled, comitted changes. DBs shouldn&#x27;t attempt to allocate memory during the critical phase, and should be able to recover even on failed allocations at any time by just crashing and let regular start-up recovery clean up. Though a problem on Linux might be memory overcomitting.<p>Edit: and another problem is disk drives&#x2F;controller caches lying and reporting write completion when not all data has actually reached stable storage')