Item(by='boulos', descendants=None, kids=[25175707], score=None, time=1606022601, title=None, item_type='comment', url=None, parent=25149154, text='Disclosure: I work on Google Cloud.<p>Cool work! I love seeing people pushing distributed storage.<p>IIUC though, you make a similar choice as Avere and others. You&#x27;re treating the object store as a distributed block store [1]:<p>&gt; In HopsFS-S3, we added configuration parameters to allow users to provide their Amazon S3 bucket to be used as the block data store. Similar to HopsFS, HopsFSS3 stores the small files, &lt; 128 KB, associated with the file systemâ€™s metadata. For large files, &gt; 128 KB, HopsFS-S3 will store the files in the user-provided bucket.<p>...<p>&gt; HopsFSS3 implements variable-sized block storage to allow for any new appends to a file to be treated as new objects rather than overwriting existing objects<p>It&#x27;s somewhat unclear to me, but I think the combination of these statements means &quot;S3 is always treated as a block store,  but <i>sometimes</i> the File == Variably-Sized-Block == Object. Is that right?<p>Using S3 &#x2F; GCS &#x2F; any object store as a block-store with a different frontend is a <i>fine</i> assumption for dedicated client or applications like HDFS-based ones. But it does mean you throw away interop with other services. For example, if your HDFS-speaking data pipeline produces a bunch of output and you want to read it via some tool that only speaks S3 (like something in Sagemaker or whatever), you&#x27;re kind of trapped.<p>It sounds like you&#x27;re already prepared to support variably-sized chunks &#x2F; blocks, so I&#x27;d encourage you to have a &quot;transparent mode&quot;. So many users love things like s3fs, gcsfuse and so on, because even if they&#x27;re slow, they preserve interop. That&#x27;s why we haven&#x27;t gone the &quot;blocks&quot; route in the GCS Connector for Hadoop, interop is too valuable.<p>P.S. I&#x27;d love to see which things get easier for you if you are also able to use GCS directly (or at least know you&#x27;re relying on our stronger semantics). A while back we finally ripped out all the consistency cache stuff in the Hadoop Connector once we&#x27;d rolled out the Megastore =&gt; Spanner migration [2]. Being able to use <i>Dual-Region</i> buckets that are metadata consistent while <i>actively</i> running Hadoop workloads in two regions is kind of awesome.<p>[1] <a href="https:&#x2F;&#x2F;content.logicalclocks.com&#x2F;hubfs&#x2F;HopsFS-S3%20Extending%20Object%20Stores%20with%20POSIX-like%20Semantics%20and%20more%20(industry%20track).pdf" rel="nofollow">https:&#x2F;&#x2F;content.logicalclocks.com&#x2F;hubfs&#x2F;HopsFS-S3%20Extendin...</a><p>[2] <a href="https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;gcp&#x2F;how-google-cloud-storage-offers-strongly-consistent-object-listing-thanks-to-spanner" rel="nofollow">https:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;gcp&#x2F;how-google-cloud-...</a>')