Item(by='segfaultbuserr', descendants=None, kids=[25674933], score=None, time=1610040903, title=None, item_type='comment', url=None, parent=25673463, text='&gt; <i>We can treat this essay as a historical document</i><p>It&#x27;s why I&#x27;m rereading this book today.<p>One thing I&#x27;ve been thinking about since morning was ESR&#x27;s &quot;Linus Law&quot;, &quot;given enough eyeballs, all bugs are shallow&quot;. Today the idea is heavily criticized. The very existence of fetchmail by the author was a counterpoint - the code quality was below average, it had numerous security vulnerabilities, and arguably basing the whole book on fetchmail is the book&#x27;s greatest flaw (not to say the criticisms of ESR&#x27;s personal qualification from many hackers).<p>But if you read the original context...<p>&gt; Linus was directly aiming to maximize the number of person-hours thrown at debugging and development, even at the possible cost of instability in the code and user-base burnout if any serious bug proved intractable. Linus was behaving as though he believed something like this: Given a large enough beta-tester and co-developer base, almost every problem will be characterized quickly and the fix obvious to someone.<p>The original context was strictly about beta-testing - about how the Linux kernel didn&#x27;t collapse on its own weight despite the lack of a BSD-style &quot;core&quot; team and heavily scrutinized release. Instead, it achieved system stability with the help from a large number of beta-testers and co-developers who are willing to run on the bleeding edge. It&#x27;s still how the kernel and the majority of the FOSS world. &quot;Build today&#x27;s git snapshot and see whether it explodes&quot; can be quite effective.<p>Then ESR simplified it to...<p>&gt; Or, less formally, &quot;Given enough eyeballs, all bugs are shallow.&quot;<p>And now it means &quot;people can find all bugs, because there are always a lot of eyeballs to read the source code&quot;. Now it can refer to all sorts of things beyond its scope. It is a serious mistake. Notably, security vulnerabilities are different - it usually does not have any user-visible effects and can only be triggered by carefully crafted malicious inputs, not normal uses. This is the reason it doesn&#x27;t work for security. Thus, maybe a more accurate reflection of this rule could be: Given enough eyeballs, all user-visible bugs (e.g. crashes) are shallow.<p>At the end of the day, my conclusion was: Perhaps &quot;Linus Law&quot; was not as wrong as it seemed. ESR simply misinterpreted his observations.')