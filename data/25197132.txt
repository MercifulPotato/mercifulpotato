Item(by='amzans', descendants=None, kids=[25197747], score=None, time=1606213370, title=None, item_type='comment', url=None, parent=25194795, text='Hey as a (way smaller) competitor of yours, I honestly feel you.<p>I understand you may not want my advice. But anyways, here it goes :)<p>I have dealt with similar issues too at my full-time job. We ingest data in the billions range too, and our costs are a lot lower than what you describe.<p>* On the public endpoint, can you move the first point of contact closer to the edge? You want to block requests before they even reach your ingestion pipeline. If not, add a few geographical Load Balancers with the sole job of accepting requests before forwarding them to your Lambda. Divert traffic at the DNS level using a geo routing policy on Route53.<p>* Are you also hitting DynamoDB for every request as part of your spam system? I found it quite expensive on-demand, unless you provision capacity. We used to pay tens of thousands per month for DynamoDB in the past, when a single Redis instance would have done it. Specially if it&#x27;s temporary, non-critical data such as spam detection.<p>* Do you batch the incoming events before triggering SQS?<p>* How are your networking costs going? They tend to creep up in the AWS bills too.<p>It just sounds to me you clearly need something in-between the public endpoint and those Lambdas. But maybe I&#x27;m missing some info. Otherwise you&#x27;re going to keep paying for capacity that a &quot;traditional&quot; server could handle, without costing you more for each request.<p>If you can&#x27;t fight back, and don&#x27;t want real requests to be lost, put a server at the battle-front, and buffer all raw HTTP requests into a queue made for this (like Kinesis). You can then process events and recover the data at your own pace. I did this in the past, and could handle 60k+ req&#x2F;s with 2 instances on AWS. I used a simple Go tool to capture the traffic <a href="https:&#x2F;&#x2F;github.com&#x2F;buger&#x2F;goreplay" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;buger&#x2F;goreplay</a><p>Also, at my full-time job we use Kinesis to buffer all analytics events, it&#x27;s cheaper than SQS and handles billions of data points per month. This also keeps the ingest rate constant, but you seem to already do that with your workers.<p>Full disclosure: I&#x27;m Anthony from <a href="http:&#x2F;&#x2F;panelbear.com&#x2F;" rel="nofollow">http:&#x2F;&#x2F;panelbear.com&#x2F;</a> , and I just want to offer honest help.')