Item(by='raphlinus', descendants=None, kids=[24705984], score=None, time=1602049401, title=None, item_type='comment', url=None, parent=24705297, text='It&#x27;s not obvious to me that this is the case. Chris Olah and others talk about &quot;superposition&quot; as a mechanism to explain &quot;polysemantic&quot; neurons that arise in image classifiers. To me, that suggests (using very vague, hand-wavy terms) that the optimization process is attempting to pack in as many concepts as possible into the finite parameter space. Certainly the scaling of GPT-3 suggests that these larger models are not necessarily any sparser than smaller ones.<p>[1]: <a href="https:&#x2F;&#x2F;distill.pub&#x2F;2020&#x2F;circuits&#x2F;zoom-in&#x2F;" rel="nofollow">https:&#x2F;&#x2F;distill.pub&#x2F;2020&#x2F;circuits&#x2F;zoom-in&#x2F;</a>')