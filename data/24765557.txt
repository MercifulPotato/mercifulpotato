Item(by='dolni', descendants=None, kids=[24779511], score=None, time=1602597371, title=None, item_type='comment', url=None, parent=24762079, text='Sure you can do that, and that works ok in some scenarios. But there are some problems.<p>In a scenario like:<p>&gt; Now I have one lambda that gets pointed at a new record stream from an S3 bucket, and I&#x27;m done.<p>Ok, so you got AWS set up to fire your Lambda when an object is created in an S3 bucket. You decide you need another &quot;stream&quot;, we&#x27;ll call it, so you start dumping stuff into another prefix. How does one go about testing that the right function is invoked?<p>A smart person will probably say that they have a dev environment and they manage infrastructure with Terraform. Great! That&#x27;s probably the best solution there is.<p>But that still leaves a massive, glaring problem: it&#x27;s quite difficult to implement any sort of automating testing of this Lambda function setup. In all likelihood, you&#x27;re probably just pushing a file up to an S3 bucket in dev and watching it run through.<p>Let&#x27;s say you made a pass at automated testing, and let&#x27;s continue with the example of creating resized avatar images. The end product of this Lambda resizing process is probably a different file somewhere in S3. So you fire off the automated test and it fails. How did it fail? Well, if you&#x27;re lucky, the Lambda function actually had an execution that errored out. Then it&#x27;s up to you, or your automation, to look up logs in CloudWatch to troubleshoot the failure. What if it didn&#x27;t error out, and instead just put the file in the wrong place?<p>This kind of stuff is where Lambda falls over. Running Docker images on EC2 in some fashion puts way more sanity around testing as a whole. You have real Docker artifacts that you ran tests in, not just some zipfile abomination that does nothing to create a good local development environment.')