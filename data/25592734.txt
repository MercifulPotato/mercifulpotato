Item(by='sillysaurusx', descendants=None, kids=None, score=None, time=1609423231, title=None, item_type='comment', url=None, parent=25592011, text='e^loss. It&#x27;s a bad name for a confusing concept: Loss. (e^loss is just another way of plotting loss, after all.)<p>Loss isn&#x27;t the whole story -- the steepest slope during training often produces the worst quality language models. You want a nice, gentle downward slope.<p>SubsimulatorGPT2 (<a href="https:&#x2F;&#x2F;reddit.com&#x2F;r&#x2F;subsimulatorgpt2" rel="nofollow">https:&#x2F;&#x2F;reddit.com&#x2F;r&#x2F;subsimulatorgpt2</a>) continued to improve in terms of human evaluation even though the loss stayed flat for over a week.')