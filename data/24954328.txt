Item(by='Silhouette', descendants=None, kids=[24954437], score=None, time=1604171604, title=None, item_type='comment', url=None, parent=24951897, text='<i>The ultimate realization of self driving will be successful, and will have profoundly positive impacts on society</i><p>This is clearly possible in principle. After all, fully autonomous vehicles can have much more capable sensor systems than any human driver, can process the input from those sensors faster, and can then apply any necessary adjustments to the vehicle&#x27;s behaviour almost instantaneously, all without ever getting tired or distracted. No human driver will ever match that potential.<p>The problem I have with this whole argument, and thus the reason I&#x27;m not sure the moral&#x2F;ethical arguments stand up either, is that <i>we don&#x27;t know how to reliably write excellent software yet</i>.<p>The entire argument for autonomous driving rests on the premise that we will at some point in the usefully near future reach a situation where the cars drive themselves much better than we humans collectively do. But there is, to the best of my knowledge, no evidence so far that we as a society can actually create the necessary software yet.<p>Until we can, any autonomous vehicle control system will be at risk of life-threatening bugs. In particular, it will be at risk of <i>widespread</i> failures of the same type that could cause much more harm than any single human driver&#x27;s failure could, whether caused by defects in the software alone or by a malicious actor exploiting a security vulnerability. That is a huge risk that is getting far too little attention so far IMHO.')