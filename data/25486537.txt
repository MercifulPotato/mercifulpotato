Item(by='hajile', descendants=None, kids=None, score=None, time=1608475741, title=None, item_type='comment', url=None, parent=25485903, text='Consider tensor cores. They are basically just 4&#x2F;8-bit SIMD units. Add a very basic integer control unit and some specialized, custom tensor instructions. It&#x27;s literally just another CPU core from an integration perspective. It shares the same memory&#x2F;coherency architecture in every way without a bunch of subtle edge cases laying in wait. It even largely shares the same programming model for software making optimizations easier and faster to create in the compiler. Along the same lines, if the OS is aware of the extensions on each core, it can view <i>all</i> processors in the system as &quot;cpu cores&quot;, but target specific cores based on their available extensions.<p>This same process applies to most of the GPU. Nvidia uses RISC-V controllers for this reason. AMD uses a scalar unit of whatever ISA to do one-off calculations and control SIMD flow. A shared privilege model would also be good here. The current GPU landscape is rife with ways to bleed into privileged space. A shared hardware privilege model would go a long way toward dealing with this issue.<p>&gt; For a general purpose high performance SoC, you don&#x27;t want a simple CPU design, you want a fast CPU design, and you have space for all the coprocessors you want anyway.<p>You don&#x27;t want your one core that does fast CPU execution OR fast tensor OR gpu OR whatever else. You want dedicated cores to do those things AND fast CPU cores too. There are quite a few RISC-V extensions aimed at improving single-thread performance and code density. Like with other ISAs, if there&#x27;s any low-hanging fruit at the instruction level, it will be added to an extension soon enough.')