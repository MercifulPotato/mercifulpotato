Item(by='jpau', descendants=None, kids=[25584040, 25542018, 25542160], score=None, time=1608955900, title=None, item_type='comment', url=None, parent=25540583, text='Snowflake&#x27;s `Snowpark` product that they recently announced, which is to bring Spark-like APIs to Snowflake.<p>Having a DS background, I love what SQL-orchestration tool dbt (and peers) have enabled: data consumers to <i>rapidly</i> create our own safe data pipelines. There&#x27;s easily a 10x productivity improvement for most of my transformation pipelines vs. when I write them in Python or PySpark.<p>But batch ML and SQL are not that friendly (even BigQuery ML is too limiting). I end up butchering dbt&#x27;s value (simplicity and iteration speed), splitting the DAG into pieces and orchestrating them with Airflow so that I can wedge in other non-dbt parts (like feature engineering, inference, logging, detecting stale models, ...). This isn&#x27;t what the future looks like.<p>I&#x27;ve tried switching to Databricks, but do not see this as the path forward for unioning the warehouse + batch ML.<p>Hopefully Snowpark is a step forward :)<p>-------------------<p>Separately, <a href="https:&#x2F;&#x2F;materialize.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;materialize.com&#x2F;</a> is something I&#x27;m paying attention to! Being able to implement all of my SQL-based pipelines as materialized views would be immensely valuable. They recently raised capital and they could become huge.')