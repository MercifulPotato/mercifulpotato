Item(by='mattkrause', descendants=None, kids=None, score=None, time=1604336712, title=None, item_type='comment', url=None, parent=24965420, text='&quot;Inconclusive&quot; can mean several things. You can get inconclusive results that don&#x27;t strongly support or refute a particular hypothesis. These should be published. However, a lot of experiments end with &quot;no&#x2F;bad data&quot; and publishing that is, IMO, often a waste of time.<p>Suppose you want to see how different types of neurons are distributed in the brain. You hypothesize that two specific subtypes of neurons are always found in close proximity in one condition (brain area, developmental stage, disease vs health, etc), but not another. There are a lot of ways to do this, so you pick one and start.<p>If things go well, your antibodies selectively label each neuron type. You count the pairs of neurons that are neighbors (or not) in condition A, those that are neighbors (or not) in condition B, and do some stats. If you get this far, I agree it ought to be possible to publish something, regardless of whether the proportions are wildly different, exactly the same, or somewhere in between.<p>However, things often go wrong. These protocols have a lot of free parameters and it&#x27;s often not feasible to calculate the best ones from first principles. As a result, you try something and notice that the result is wildly implausible: maybe everything is labelled as one of your cell types, even stuff that isn&#x27;t neurons. You tweak the protocol, and now nothing is labelled. This is <i>also</i> implausible--the tissue is from a normal animal--so you make some more adjustments and try again. Perhaps you even change techniques altogether and use FISH or a viral vector instead of immunohistochemistry.<p>The final protocol (if successful) is always included in a paper, but these intermediate failures are usually not and I&#x27;m not sure it makes sense to. Suppose the solution was to use a better antibody from a different company. The pilot experiments where we varied the incubation time, sample prep, etc using a dud antibody are fantastically uninteresting. Furthermore, people often change multiple parameters at the same time; going back and convincingly demonstrating which one &quot;matters&quot; would require a lot more work for a fairly limited payoff.<p>Finally, people also adapt their research question based on the data they can obtain. Maybe you can reliably label one type of neuron, but not the other, so you decide to focus on how those cells&#x27; locations vary during development. If so, it&#x27;d be weird to report a bunch of failures of an unrelated technique in the resulting paper.')