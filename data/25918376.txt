Item(by='hctaw', descendants=None, kids=[25918820, 25918706], score=None, time=1611681110, title=None, item_type='comment', url=None, parent=25917826, text='I mean you can do trivial little toys in the browser sure, but low-latency, real-time audio rendering can&#x27;t be done in a garbage collected environment (unless the GC is running concurrently and guaranteed not to stall the audio rendering thread). Which the browser does not provide you.<p>You can get away with it because the complexity is low. When you begin dealing with higher complexities (like even a modest amount of polyphony in a decent synthesizer) you will push up against the limits of what the browser is capable of. That&#x27;s what I&#x27;m trying to say. There are products like bandlab that do incredibly things in the browser, but their competitors do far more with less just by leaving it.<p>As for higher level APIs... sure you can do it. There are things like WebAudio, Supercollider, Max&#x2F;MSP, Pure Data, the new SOUL language posted recently, etc. But ultimately what every app needs is an API where they pick which samples to fill a buffer with (what you&#x27;re calling &quot;sound waves to the sound driver&quot; I think). Mostly because the high level APIs sound bad and you will eventually need non-naive DSP.<p>Look - everyone knows low level APIs and languages kinda suck to program against. But it&#x27;s not for lack of trying that serious audio software isn&#x27;t running in the browser or in managed languages.')