Item(by='arc776', descendants=None, kids=[24855027], score=None, time=1603322915, title=None, item_type='comment', url=None, parent=24851947, text='Of course bigints require more than one instruction to add them, but even then you can reduce the work at compile time down to a series of integer operations, whereas the above code requires interpretting the program before it even gets to the add.<p>In your example text processing in `unicode_concatenate` is going to be very, <i>very</i> much slower than a bulk load of the native numerical data directly from memory and processing it. For each character, Python needs to check a number is still a number at run time then convert the result to a native numeric. I can only assume this string processing is at worst performed once and cached(?), because otherwise it doesn&#x27;t seem like it would run well at all and surely Python&#x27;s bigint performance is pretty important.<p>&gt; Python code can be made more high performance if there&#x27;s some way to tell the implementation the types, either explicitly or by inference or tracing.<p>At that stage, I would just use Nim and get better performance and a decent static type system included and either call it from Python, or call Python from Nim.')