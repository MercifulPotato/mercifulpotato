Item(by='BorisTheBrave', descendants=None, kids=[25176367], score=None, time=1606039038, title=None, item_type='comment', url=None, parent=25159154, text='Incredible work.<p>What&#x27;s most impressive is they&#x27;ve separated the rendering algorithm (Mitsuba 2) from the retargeting framework (Enoki).<p>Enoki look amazingfrom their paper. It supports vectorized CPUs, JITTed GPUs, forward&#x2F;back autodiff, nested array types.<p>Mitsuba 2 then expands that range even further by templating on key types and operations. For example, a materials color property might be represented by a RGB tuple for basic rendering, or an array that captures the full spectrum of light frequencies for a spectral renderer. They supply some example code, which is absurdly clean, as it&#x27;s devoid of any specifics of storage and calculation, and focusses just on the high level algorithm.<p>They claim that the GPU impl is superior to PyTorch &#x2F; TensorFlow in some regards as it can split the difference between eagerly sending every operation to the GPU, or processing the entire graph at once.<p>The amount of work and understanding to produce something like this is insane - they just casually mention how they&#x27;ve implemented a novel light transport scheme, an &quot;extensive mathematical support library&quot;, and sophisticated python bindings.')