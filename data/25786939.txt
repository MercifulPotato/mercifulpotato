Item(by='zackmorris', descendants=None, kids=[25787152], score=None, time=1610684195, title=None, item_type='comment', url=None, parent=25786459, text='In case anyone is curious, this is literally the future of programming (I realized it 20 years ago after reading Genetic Programming III by John Koza). The fact that we don&#x27;t already do this just blows my mind.<p>For small-scale examples of this, I highly recommend reading up on basic stuff like Karnaugh map simplification and compiler optimization. Once you realize that all computation is just mapping inputs to outputs, and that the main task is actually pruning the search space (not working the problem), everything changes.<p>Of course, knowing all that, setting up the initial conditions, figuring out the types&#x2F;ranges&#x2F;valid values of input, and what the output should be, is half the battle. And it turns out that these are just exactly the tasks you have to do for stuff like training neural nets. It&#x27;s all going to be machine learning in 10 years is what I&#x27;m saying.<p>Oh and also for anyone interested, today&#x27;s processors are almost perfectly wrong for this sort of work. Since we&#x27;re just piping data around (like video games), the cache is borderline useless. Data locality is important though, so just about every core needs its own memory.<p>My feeling is that AI hasn&#x27;t improved appreciably in our lifetimes because we&#x27;re so focused on serial computation that we completely missed the fact that parallel is the way to go. Our brains are 100 billion neurons running at 1 kHz. Kinda hilarious&#x2F;sad to think about IMHO, but I digress.')