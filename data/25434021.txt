Item(by='jjk166', descendants=None, kids=[25459030], score=None, time=1608060649, title=None, item_type='comment', url=None, parent=25432253, text='&gt; He realized that nurses were telling patients, “Well, the computer did it—it’s not me.” “That’s what tipped us off,” he says.<p>This seems to be the real crux of the issue. These industrial-scale algorithms should be treated the same as any other industrial equipment. If you run over someone with a bulldozer, you can&#x27;t say &quot;the bulldozer did it, not me.&quot; Using the excuse &quot;I don&#x27;t even know how to operate a bulldozer&quot; only makes it worse. I think it&#x27;s perfectly reasonable that if an institution doesn&#x27;t train people to properly use an algorithm, take reasonable precautions to make sure it doesn&#x27;t cause severe damage, and&#x2F;or has no reasonable system in place for fixing problems it creates, they should be liable for negligence the same way any other operator of potentially dangerous equipment would.')