Item(by='xoa', descendants=None, kids=[24844190], score=None, time=1603245291, title=None, item_type='comment', url=None, parent=24843494, text='Perhaps rather then filtering per se, focus on the economic equation of moderation. Fundamentally moderation is about the time&#x2F;resource cost of the moderator(s) vs the time&#x2F;resource cost of evasion. Good moderation is probably an AI-complete problem, so it&#x27;s hard to automate right now. Most efforts at improving that seem to either use broad brush measures and heuristics on the mod side, or so-so proxy measures for the evasion side. From captchas to money to asking for ID, all at the end of the day are about trying to make it more &#x27;expensive&#x27; to evade bans. If the expense is really high, then even a small bit of moderation can keep up.<p>But instead of any of that why not just do a time token directly and with full pseudonomyity? Matrix.org could ask people to do something like brute force RSA, choosing key lengths based on how much time they want to represent, and then sign a &quot;Time Level&quot; certificate result. Community operators could then dynamically adjust how much &quot;time investment&quot; they wanted to require in order to participate, and would have a mechanism to ban independent of IP or anything else. And this could be expected to increase over time as people let their systems run a day or two a month. If in a few years it requires a token equivalent to a month of computation time that would be a high bar to evasion.  It would not require any money, identity, or knowledge of behavior elsewhere, but people would have strong incentives not to burn their Time Level tokens, or at least to comply with non-permanent bans. You could further tweak things by having per-community tokens which can only be issued once per cert, so identity can&#x27;t be as easily tracked across communities while still stopping evasion. This should all be near completely automatable as well.<p>Anyway, just some musing. I guess the question is if communities had effective cryptographicly guaranteed rate controls and moderation stickiness, would they really need more in practice to keep up?')