Item(by='chrismorgan', descendants=None, kids=None, score=None, time=1606980523, title=None, item_type='comment', url=None, parent=25286289, text='You’re getting the narrative quite wrong here and assuming a great deal of bad faith that simply doesn’t exist.<p>People often seem to think Google presented SPDY and QUIC to IETF as <i>faits accomplis</i>, and they were just adopted as HTTP&#x2F;2 and HTTP&#x2F;3 because Google said so.<p>This is not how the standardisation processes work. Rather: (1) many involved parties recognised that something like this would be of value; (2) Google developed something, because they happened to be one of the parties that cared the most about it; (3) Google gave it to IETF; (4) all the relevant stakeholders joined in on improving it until there was consensus and practical experience that it really was worth it; and (5) it was finalised and published.<p>What ends up being standardised normally has some quite major differences from what was initially proposed. IETF QUIC is definitely quite different from gQUIC, as HTTP&#x2F;2 is from SPDY. Standardisation within IETF brings diverse parties together to improve things based upon their experience and expertise. Certainly there will be dissenters, because there are trade-offs everywhere (e.g. the Varnish author was lukewarm about HTTP&#x2F;2, reckoning it wasn’t worth it and that more radical changes should be made to HTTP semantics), but the end result will be better than what was initially presented, and there must be broad consensus that what is to be published is better than what preceded it (in this case HTTP&#x2F;1.1). At Fastmail I observed a fair bit of the process of the standardisation of JMAP at IETF, and it benefited enormously from the process, changing shape quite significantly in some areas from what Fastmail initially presented.<p>The end result of HTTP&#x2F;2 is definitely harder to implement than HTTP&#x2F;1 (though it’s still not too bad—I implemented it in the draft days and didn’t have any real trouble, there was mostly just more to implement than with HTTP&#x2F;1), but of its operational parameters, it’s better in every way than HTTP&#x2F;1. Turns out that a protocol being plain-text really just isn’t useful, so long as the semantics are conveyed—literally the only people that need to care about the wire protocol are the people making tools that speak it (that is, HTTP libraries).<p>There’s really just one issue with HTTP&#x2F;2: it makes it possible to use a single TCP connection where HTTP&#x2F;1 probably used up to six, but this leads to TCP head-of-line blocking issues becoming more serious.<p>And make no mistake, TCP head-of-line blocking is a real issue on high-loss networks like the outskirts of wi-fi and cellular networks.<p>HTTP&#x2F;2’s multiplexing solved real problems, and HTTP&#x2F;3’s HOLB-fixing solves the last real problem with HTTP&#x2F;2.<p>Google didn’t browbeat people into doing their will; rather, they presented a draft, and then everyone worked together to improve upon that draft, and they all (or at the least, almost all) agreed that the end result was a good improvement.<p>&gt; <i>a deliberate effort to deprive the web of its own nature by making it so complicated that only Google is capable to implement it.</i><p>… are you aware of how many HTTP&#x2F;3 implementations there are already? In Rust alone, there are at least three fairly mature implementations: Quinn by various people, Quiche by Cloudflare, Neqo by Mozilla; as well as a handful more not-so-mature implementations.<p>Look, I’m not fond of Google, and I <i>do</i> think they abuse their position in many and various places, but this is not one of them.')