Item(by='lostdog', descendants=None, kids=None, score=None, time=1606161622, title=None, item_type='comment', url=None, parent=25185619, text='Many companies aren&#x27;t ready to succeed at ML until they have failed at least once. Leadership doesn&#x27;t understand that building a good ML models takes more time and effort. It takes a failure of an ML project (and sometimes multiple failures) to break their preconceptions free and get them to understand how much effort it really takes. In a world where writing unit tests and refactoring are skipped to speed up execution, how many companies have the patience to build good validation infrastructure for an ML project?<p>There are a few ways to attack this, though all are tenuous. First, the ML project must be vital to the product. If it&#x27;s not vital, then as soon as it starts slipping it will get cut. Second, you need to overcommunicate the level of difficulty and the amount of infrastructure necessary to get an ML model working. Third, it&#x27;s extremely useful to have some authority and experience to point to. If you can confidently say &quot;I have done this type of work before, and this is what it takes,&quot; you&#x27;ll get much more acceptance of the longer timeline.<p>Of course, to keep support for your project, you needed to be better plugged in to the politics at the company. You needed more 1-to-1 communication with someone higher up, and to present your work more regularly to larger groups. It&#x27;s not just to show them what&#x27;s going on, but also to understand the current criticisms and the overall attitude towards your project. As with anything, if you were surprised by the result, then you weren&#x27;t talking to (and listening to) enough people.')