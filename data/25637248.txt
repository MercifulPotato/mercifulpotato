Item(by='jhgg', descendants=None, kids=None, score=None, time=1609791388, title=None, item_type='comment', url=None, parent=25634678, text='Our secret sauce is Elixir&#x2F;BEAM and Rust :)<p>Well for the real time side, I can&#x27;t tell you how big a boon it&#x27;s been to build our platform on top of Elixir&#x2F;BEAM. Hands down the best runtime &#x2F; VM for the job - and a big big secret to our success. Where we couldn&#x27;t get BEAM fast enough - we lean on rust and embed it into the VM via NIFs.<p>2021 is the year of rust - with the async ecosystem continuing to mature (tokio 1.0 release) we will be investing heavily in moving a lot of our workloads from Python to Rust - and using Rust in more places, for example, as backend data services that sit in front of our DBs. We have already piloted this last year for our messages data store and have implemented such things as concurrency throttles and query coalescing to keep the upstream data layer stable. It has helped tremendously but we still have a lot of work to do!<p>To help scale those super large servers, in 2020 we invested heavily in making sure our distributed system can handle the load.<p>Did you know that all those mega servers you listed run within our distribution on the same hardware and clusters as every other discord server - with no special tenancy within our distribution. The largest servers are scheduled amongst the smallest servers and don&#x27;t get any special treatment. As a server grows - it of course is able to consume a larger share of resources within our distribution - and automatically transitions to a mode built for large servers (we call this &quot;relays&quot; internally.) At any hour, over a hundred million BEAM processes are concurrently scheduled within our distributed system. Each with specific jobs within their respective clusters. A process may run your presence, websocket connection, session on discord, voice chat server, go live stream, your 1:1&#x2F;group DM call, etc. We schedule&#x2F;reschedule&#x2F;terminate processes at a rate of a few hundred thousand per minute. We are able to scale by adding more nodes to each cluster - and processes are live migrated to the new nodes. This is an operation we perform regularly - and actually is how we deploy updates to our real time system.<p>I was responsible for building and architecting much of these systems. It&#x27;s been super cool to work on - and - it&#x27;s cool to see people acknowledge the scale we now run at! Thank you!! It&#x27;s been a wild ride haha.<p>As for scale, our last public number perhaps comparable to Slack is ~650 billion messages sent in 2020, and a few trillion minutes of voice&#x2F;video chat activity. However given the crazy growth that has happened last year due to COVID - the daily message send volumes are well over the 2 billion&#x2F;day average.')