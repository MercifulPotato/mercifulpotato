Item(by='ackbar03', descendants=None, kids=None, score=None, time=1603725172, title=None, item_type='comment', url=None, parent=24894275, text='I don&#x27;t really have a good solution for it. I&#x27;ve toyed around with deep learning based SaaS type projects though so I know cloud server costs are a major factor.<p>What sort of worked was I routed the data so the inference ran on my own local server (i.e. my work station), although the downside is you can&#x27;t use your GPU for other stuff. At the time I looked into it, 3 months of cloud server costs were enough to buy your GPU work station. Also tried to do whatever I could to optimize inference.<p>I have no idea what kind of volume your getting but I imagine itd be even worse for video based Gan stuff. Maybe go for quality an target super high end? You probably have a much better idea than me.<p>All the best, will be interested to know how it goes')