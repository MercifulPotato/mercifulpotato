Item(by='kthejoker2', descendants=None, kids=None, score=None, time=1602175405, title=None, item_type='comment', url=None, parent=24720267, text='I mean .. I disagree?<p>It&#x27;s certainly simple to give &quot;a sense&quot; of how deep learning works -<p>1) translate real-world states and behaviors into data structures (typically multi-dimensional arrays);<p>2) use (relatively straightforward) math to find patterns in the large matrices;<p>3) assume those patterns are representative of the real-world states and behaviors it translated;<p>4) produces a model which &quot;works in reverse&quot; i.e. uses the patterns it found to generate real-world states and behaviors, particularly states and behaviors it has never translated or seen before.<p>And therefore what it&#x27;s good at - math, finding patterns - are simple to get a sense of, what it&#x27;s bad at - assuming the patterns it&#x27;s found are representative - is simple to understand, and why it feels like magic - the speed at which it can acquire a skill, that it&#x27;s trained solely through observation - and why it doesn&#x27;t feel like magic - it&#x27;s just math and pattern-matching, things we teach in preschool.<p>Every new breakthrough in AI&#x2F;DL research is either &quot;more math&quot;, &quot;same math but faster&quot;, &quot;more patterns&quot;, &quot;better patterns&quot; ... Always good to read and see how very smart people solved problems, but the underlying principles are really simple.<p>What&#x27;s way harder to wrap your head around is the distributed compute and data pipelines and hardware architectures required to support the scales at which these simple mathematical pattern-matching algorithms need to operate to be useful.')