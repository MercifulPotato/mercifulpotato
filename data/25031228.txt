Item(by='JHonaker', descendants=None, kids=[25032020], score=None, time=1604892979, title=None, item_type='comment', url=None, parent=25030829, text='There are two main reasons why frequentist[1] methods are losing popularity:<p>1. Your tests make statements about some pre-specified null hypothesis, not the actual question you’re usually interested in: Does this model fit my data?<p>2. The probability statements from frequentist methods are usually about the properties of the estimator, not about the thing you’re estimating. This is very unintuitive and confusing.<p>So why are these big deals? Let’s tackle the null hypothesis first. The null hypothesis isn’t necessarily that the effect is null, or there is no effect. It’s exact meaning is very specific to the test.<p>The easiest way to think about it is imagine you have some test that you’ve designed that tests if a person’s height is 5’ 10”. You build some measurement error into the test, so if a person is reported at slightly above or below 5’ 10” they won’t be automatically eliminated. This is how you design a frequentist test. You set up a scenario like this, and you study the properties of your test so you can make a statement like if a person is 5’ 10”, I’ll only be wrong with this test 5% of the time (false positive rate, or Type I error) or, alternatively, if they’re not 5’ 10”, this test will say they’re not 5’ 10” 80% of the time (statistical power).<p>The problem with this approach is only a problem if you’re situation doesn’t match the conditions the test was originally designed for. You probably don’t care if someone was 5’ 10” exactly. You’re probably more interested in knowing what the likely height of a person is also while accounting for measurement error. You also might not necessarily have the same type of measurement error. You have different measuring tools and different people collecting your data. If you know frequentist statistics, this isn’t such a huge deal because you can make your own test by modifying the conditions of this one. If you don’t and you just use this original test, then you might end up with some really odd results (like the replication crisis in the early 2000s in psychology). Most frequentist tools are exactly this kind of thing. The null hypothesis of the test is usually that some effect is zero, but that effect being zero or non-zero is not really that meaningful. Your model could be easily misspecified and still give you non-zero effects.<p>If we look back at the story of the height test, then you can already see the beginnings of our second point. The probability statements concerning the test aren’t statements about the likelihood of the quantity of interest. They’re statements about the behavior of the test. Our test, repeated enough times is theoretically guaranteed to only make errors of one type, false positives, 5% of the time, and only make errors of another type, false negatives, 20% of the time. We don’t actually say anything about the value of the height and its likelihood with this.<p>Isn’t that weird?<p>This is the exact problem with confidence intervals and p-values (which are basically two ways of talking about the same thing). The 95% confidence interval isn’t saying that there’s a 95% of the true height in there. It’s saying that this construct, the confidence interval, will include 5’ 10”, when 5’ 10” is not their true height, only 5% of the time.<p>This is so strange and unintuitive that people, even trained statisticians, incorrectly interpret them. If anyone says they’ve never looked at a CI and thought about the endpoints as rough expectations for the possible ranges of “height”, they’re lying. Obviously we don’t go publishing those unnaturally easy mistaken interpretations as findings in academic papers, but anyone that does by mistake (!) should be forgiven or at least sympathized with.<p>I don’t say all of this to convince you that they’re useless. In fact they’re not at all! Bayesian statistics actually relies quite heavily on the frequentist theory of estimators to evaluate the results they get from their conditioning procedures (Hamiltonian Monte Carlo, Metropolis-Hastings, and other Markov Chain Monte Carlo techniques). Frequentist statistics is very useful and very valuable. It’s just very easy to misunderstand and abuse. The estimators are like little domain specific tests that get too broadly applied because they’re very easy to fire and forget. Unfortunately a lot of decisions went into developing the exact scenario that they’re testing, and most people don’t know how to assess those conditions or modify them to better suit their needs.<p>I hope that was helpful, sufficiently interesting to read, and easy enough to follow!<p>[1]: I believe you meant frequentist, not descriptive. Descriptive statistics are just things that describe data, like how many modes does this have, what’s the mean or median, etc.')