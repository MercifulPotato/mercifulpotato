Item(by='lmm', descendants=None, kids=None, score=None, time=1609816687, title=None, item_type='comment', url=None, parent=25636785, text='&gt; Well, you want to do that anyways, but then you realize that instead of simply renaming a column, you&#x27;ll probably do a rolling migration for the apps that use the DB, therefore you need to create a new column that the app will write data into, then migrate all of the app instances to the new version and then clean up the old column, god forbid validations use the wrong column while this is going on. I don&#x27;t think it&#x27;s possible to work around problems like this with technologies like MongoDB either, since then dealing with missing data in an &quot;old&quot; version of a document would still be annoying. I don&#x27;t know of any good solutions to address how data evolves over time, regardless of technology.<p>IME the best way to do it is to build your system on stream transformation (i.e. Kafka) and then you can just produce the new representation in parallel, wait for it to catch up, migrate the readers over gradually and then eventually stop producing the old representation. That tends to be what you end up doing with a traditional RDBMS too, but if you&#x27;re using something like Kafka then the pieces that you use are more normal parts of your workflow so it&#x27;s less error-prone.<p>&gt; It seems like this problem affects most distributed systems and i&#x27;m not sure how to address it, short of making each new data entry reference the previous state, like CouchDB does with revisions ( <a href="https:&#x2F;&#x2F;docs.couchdb.org&#x2F;en&#x2F;stable&#x2F;intro&#x2F;api.html#revisions" rel="nofollow">https:&#x2F;&#x2F;docs.couchdb.org&#x2F;en&#x2F;stable&#x2F;intro&#x2F;api.html#revisions</a> ) and even that won&#x27;t always help.<p>There are two approaches that I&#x27;ve known to work: 1. actual multiple concurrent versions as you say, with vector clocks or equivalent, forcing the clients to resolve conflicts if you&#x27;re not using CRDTs - Riak was the best version of this approach, 2. having a clear shard key and allowing each partition to have its own &quot;owner&quot;, making it clear what you do and don&#x27;t guarantee across partitions - e.g. Kafka.<p>&gt; Partially agreed, SQL is pretty reasonable for what it does, despite its dialects being somewhat inconsistent, many of the procedural extensions being clunky and most of the in-database processing heavy systems that i&#x27;ve encountered being a nightmare from a debugging and logging perspective, though i guess that&#x27;s mostly the fault of the tooling surrounding them.<p>I wasn&#x27;t talking about the fancy analytics so much as just the basic data model - e.g. having a collection-valued column is just way harder than it should be. Everything being nullable everywhere is also a significant pain.')