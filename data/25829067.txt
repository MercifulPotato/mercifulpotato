Item(by='didibus', descendants=None, kids=[25830956], score=None, time=1611021279, title=None, item_type='comment', url=None, parent=25828017, text='&gt; The problem is, in many software companies, none of the tasks look alike. So your past data is going to be somewhat dirty, particularly at team level<p>Tasks don&#x27;t really give you anything though. I think if it was measured in terms of features, that would work a lot better.<p>And with a Monte Carlo simulation, you get to know the time it would take you to complete any random feature on any random period. So maybe you can&#x27;t perfectly predict that next feature, but in the year, on the average, your predictions should tend towards good accuracy.<p>And you could take it further, machine learn the feature request to the time it took. And then run the ML inference on any new feature request. Maybe let devs add some labels, it&#x27;s not exactly estimating, but they could mention if say they think something is &quot;complex&quot;, &quot;ambiguous&quot;, &quot;straightforward&quot;, etc.<p>I&#x27;m sure there&#x27;d be ways to do it.')