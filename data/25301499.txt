Item(by='greenkey', descendants=None, kids=[25301659, 25301715], score=None, time=1607084607, title=None, item_type='comment', url=None, parent=25301103, text='That’s awesome!<p>In comparison, here a quote from the OP’s blog entry:<p>“Fast forward to today. A program to load &#x2F;usr&#x2F;share&#x2F;dict&#x2F;words into a hash table is 3-5 lines of Perl or Python, depending on how terse you mind being. Looking up a word in this hash table dictionary is a trivial expression, one built into the language. And that&#x27;s it. Sure, you could come up with some ways to decrease the load time or reduce the memory footprint, but that&#x27;s icing and likely won&#x27;t be needed. The basic implementation is so mindlessly trivial that it could be an exercise for the reader in an early chapter of any Python tutorial.<p>That&#x27;s progress.”<p>But is a simpler, less efficient method progress? Sure it allows more words to be added&#x2F;removed with ease, and I don’t want to advocate over-optimization, but the solution you made for the Spectrum seems better because words don’t change much. Why don’t we use a similar specialized hash and compressed dictionary format to increase spellchecking speed and allow more words in less space? We could still produce that format using &#x2F;usr&#x2F;share&#x2F;dict&#x2F;words and similar.')