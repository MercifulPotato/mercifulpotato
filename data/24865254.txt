Item(by='abeppu', descendants=None, kids=[24865791, 24867696], score=None, time=1603417652, title=None, item_type='comment', url=None, parent=24862507, text='I don&#x27;t want to discount the usefulness of log probabilities. But this post gets off to a poor start.<p>&gt; Probabilities are very rarely added together, and probability distributions even more rarely.<p>Umm, we _often_ add probabilities when we want to know the probability that any of a number of finite but mutually exclusive outcomes will happen.<p>We often add distributions (perhaps with weights) when we think about mixture models, or when there are multiple mechanisms which can both give rise to the same outcomes.<p>A point the author didn&#x27;t make about log probabilities which likely relevant to this audience is that we often think about the product of many probability terms when modeling a complex outcome of many steps (e.g. a language model where words are &#x27;drawn&#x27; from a distribution, and so the probability of a sentence is a product of many terms corresponding to many generative steps). In these cases log probabilities are often also important for computations to avoid underflow issues. I.e. when you have to reason about large, complex, composed structures generated from stochastic processes, _everything_ can be astoundingly unlikely in absolute terms, and log probabilities let us keep track of the important differences between astoundingly unlikely things.')