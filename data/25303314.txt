Item(by='PaulHoule', descendants=None, kids=[25303682], score=None, time=1607095752, title=None, item_type='comment', url=None, parent=25300942, text='If you are extracting information from Wikipedia and trying to parse the markup you&#x27;re doing it wrong.  It&#x27;s the difference between &quot;screwed around with handwritten parsers for years and it still doesn&#x27;t work 100% right&quot; and &quot;look this CSS selector extracts what you want.&quot;<p>Freebase,  DBpedia,  and many others (me) have tried,  but the reality is that the markup language is poorly defined and the only path that is really tested is the one that ends up rendering HTML.<p>If you feed HTML from Wikipedia into a web parser that supports the DOM (say Beautiful Soup) you can generally parse out what you want pretty effectively.  Once I switched from the &quot;markup rabbithole&quot; to &quot;parsing standard HTML&quot; I was able to turn my MediaWiki extractor into a Flickr extractor in about 15 minutes.')