Item(by='Ancapistani', descendants=None, kids=[25861173, 25862079], score=None, time=1611247828, title=None, item_type='comment', url=None, parent=25860707, text='I don’t <i>think</i> so.<p>Without digging into the source - and I intend to do that, if someone more familiar with this doesn’t chime in - it appears that it’s targeted at reducing resource consumption.<p>UTF-8 can encode emoji fine. Consider  (“ grinning face with smiling eyes”), which is `\\xF0\\x9F\\x98\\x81` in bytes. That’s four bytes. From the pg-emoji Readme:<p>&gt; A lookup-table is constructed from the first 1024 emojis from [<a href="https:&#x2F;&#x2F;unicode.org&#x2F;Public&#x2F;emoji&#x2F;13.1&#x2F;emoji-test.txt" rel="nofollow">https:&#x2F;&#x2F;unicode.org&#x2F;Public&#x2F;emoji&#x2F;13.1&#x2F;emoji-test.txt</a>], where each emoji maps to a unique 10 bit sequence.<p>&gt; The input data is split into 10 bit fragments, mapped to the corresponding emojis.<p>If my understanding is correct thus far, then instead of storing four bytes for each emoji, you’d only need 10 bits.<p>I don’t know where this would be worthwhile.<p>I’m further confused by the purpose of `to_text()` and `from_text()`. Their example shows a string composed of mostly Latin characters being encoded into a string of emoji and back.')