Item(by='Athas', descendants=None, kids=[24814111, 24813758], score=None, time=1602971377, title=None, item_type='comment', url=None, parent=24813377, text='Strong sequential consistency is a big one.  Most architectures that have tried to diverge from this for performance reasons run into trouble with the way people like to write C code (but will not have trouble with languages actually built for concurrency).<p>Arguably the scalar focus of CPUs is also to make them more suited for C-like languages.  Now, attempts to do radically different things (like Itanium) failed for various reasons, in Itanium&#x27;s case at least partially because it was hard to write compilers good enough to exploit its VLIW design.  It&#x27;s up in the air whether a different high-level language would have made those compilers feasible.<p>It&#x27;s not like current CPUs are completely crippled by having to mostly run C programs, and that we&#x27;d have 10x as many FLOPS if only most software was in Haskell, but there are certainly trade-offs that have been made.<p>It is interesting to look at DSPs and GPU architectures, for examples of performance-oriented machines that have <i>not</i> been constrained by mostly running legacy C code.  My own experience is mostly with GPUs, and I wouldn&#x27;t say the PTX-level CUDA architecture is <i>too</i> different from C.  It&#x27;s a scalar-oriented programming model, carefully designed so it can be transparently vectorised.  This approach won over AMDs old explicitly VLIW-oriented architecture, and most GPU vendors are now also using the NVIDIA-style design (I think NVIDIA calls it SPMT).  From a programming experience POV, the main difference between CUDA programming and C programming (apart from the massive parallelism) is manual control over the memory hierarchy instead of a deep cache hierarchy, and a really weak memory model.<p>Oh, and of course, when we say &quot;CPUs are built for C&quot;, we really mean the huge family of shared-state imperative scalar languages that C belongs to.  I don&#x27;t think C has any really unique limitations or features that have to be catered to.')