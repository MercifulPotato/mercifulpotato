Item(by='wfleming', descendants=None, kids=None, score=None, time=1607211883, title=None, item_type='comment', url=None, parent=25319130, text='I’m largely guessing here, but I think at least one aspect of the hardware contributing to this is the M1 shares the same RAM for the CPU &amp; GPU. Normally that’s not the case, so a display change requires recalculating the display buffer for the entire screen and then copying that to the GPU. The M1 can skip that copy phase, it just tells the GPU where the buffers already are in RAM. That definitely can’t account for multiple seconds, but it’s probably part of the story.<p>We also know that Apple spent time optimizing very specific operations in their CPU - optimizing retain&#x2F;release operations on objects is the one that’s gotten mentioned a lot. Maybe they spent similar time optimizing things in the GPU for changing modes&#x2F;outputs?')