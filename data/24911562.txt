Item(by='skybrian', descendants=None, kids=[24911850], score=None, time=1603830853, title=None, item_type='comment', url=None, parent=24907855, text='If GPT-3 has a consistent position on anything, it&#x27;s only because the corpus it was trained on was consistent about it. So, for example, it will reliably autocomplete Jabberwocky because there are a lot of copies of this poem in the corpus and they are all the same.<p>If there were two versions of this poem that started the same way, it would pick between the variations in the corpus randomly. In other cases it might choose based on the style of prose or other stuff like that.<p>GPT-3 can get some trivia right, but it&#x27;s only because the editors of Wikipedia already came to consensus about it and Wikipedia was weighted more. It doesn&#x27;t have a way of coming to a consistent conclusion on its own.<p>Without consistency, how can it be said to know or believe anything? You might as well ask what a library believes. Sure, the authors may have believed things, but it depends which book you happen to pick up.')