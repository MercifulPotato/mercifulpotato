Item(by='Animats', descendants=None, kids=None, score=None, time=1603235537, title=None, item_type='comment', url=None, parent=24835336, text='Now that&#x27;s fascinating.<p>I&#x27;d thought of machine learning as a form of optimization. \nThings like support vector machines really were hill climbing for some kind of local optimum point. But at a billion dimensions, you&#x27;re doing something else entirely. I once went through Andrew Ng&#x27;s old machine learning course on video, and he was definitely doing optimization.<p>The last time I actually had to do numerical optimization using gradients, I was trying to solve nonlinear differential equations for a physics engine in about a 20-dimensional space of joint angles that was very &quot;stiff&quot;. That is, some dimensions might be many orders of magnitude steeper than another. It&#x27;s like walking on a narrow zigzagging mountain ridge without falling off.<p>So deep learning is not at all like either of those. Hm.')