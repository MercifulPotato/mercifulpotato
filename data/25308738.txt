Item(by='breatheoften', descendants=None, kids=[25308837, 25310617], score=None, time=1607119239, title=None, item_type='comment', url=None, parent=25308231, text='This is pretty dystopian ...<p>1. There exist laws to prevent discrimination against people based on protected attributes\n2. ML models make predictions based on attributes without interpretability  (it&#x27;s not possible to prove that protected attributes are not factoring into model predictions)\n3.  Empirical observation that a model proxies a protected property exposes corporation to liability for regulatory non compliance\n4.  Therefore any study that could expose bias of a model used in production is to be road blocked or prevented ...<p>To combat flows like above -- seems like regulators are going to need to update rules with third party audits and an incentive structure that encourages self-regulation and derisks self-detection and self-reporting of non-intentional violations...  ideally google should not be put into a position where it is incentivized to police its own ai ethics research to ensure that such research doesn&#x27;t expose their own illegal&#x2F;non-compliant activity ...')