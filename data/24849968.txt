Item(by='MrPowers', descendants=None, kids=None, score=None, time=1603300854, title=None, item_type='comment', url=None, parent=24849503, text='The spark.sql(&quot;&quot;&quot;select ... from some_name ...&quot;&quot;&quot;) bit is how to write pure SQL from the Scala or Python execution context.  If you&#x27;re in the SQL execution context, this syntax isn&#x27;t required.  I never write Spark code like this.<p>At first glance, the F.col(), .withColumn() syntax isn&#x27;t as intuitive as pure SQL, but it has a lot of advantages when you get used to it.  You can make abstractions, use programming language features like loops, and use IDEs.<p>I find the PySpark syntax to be uglier than Scala.  Lots of teams are terrified to use Scala and that&#x27;s the reason PySpark is so popular.')