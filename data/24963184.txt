Item(by='bibabaloo', descendants=None, kids=[24963771], score=None, time=1604270458, title=None, item_type='comment', url=None, parent=24961900, text='You&#x27;re correct, but from my understanding shifting the trust to the FPGA is a productive move as an potential attack is much more difficult to execute. Bunnie explains on his blog [1] better than I can:<p>&gt; The CPU is, of course, the most problematic piece. I’ve put some thought into methods for the non-destructive inspection of chips. While it may be possible, I estimate it would cost tens of millions of dollars and a couple years to execute a proof of concept system. Unfortunately, funding such an effort would entail chasing venture capital, which would probably lead to a solution that’s closed-source. While this may be an opportunity to get rich selling services and licensing patented technology to governments and corporations, I am concerned that it may not effectively empower everyday people.<p>&gt; The TL;DR is that the near-term compromise solution is to use an FPGA. We rely on logic placement randomization to mitigate the threat of fixed silicon backdoors, and we rely on bitstream introspection to facilitate trust transfer from designers to user. If you don’t care about the technical details, skip to the next section.<p>[1] <a href="https:&#x2F;&#x2F;www.bunniestudios.com&#x2F;blog&#x2F;?p=5706" rel="nofollow">https:&#x2F;&#x2F;www.bunniestudios.com&#x2F;blog&#x2F;?p=5706</a>')