Item(by='tphyahoo2', descendants=None, kids=[25314726], score=None, time=1607177001, title=None, item_type='comment', url=None, parent=25313602, text='what if there was a section 230 carveout where you are not liable for comments on your blog, say, as long as they are<p>1) digitally signed (can be by anonymous identity)<p>2) content is id-filterable by id, by user agents (aka browsers + user controlled software), easily enough, following a reasonable man test. so users can moderate their own content following blacklists and whitelists, if they want. law enforcement and gov can of course have their own white and blacklists.<p>3) you take illegal content down when notified with reasonable latency period. This can be automated for mom and pops with limited resoures, if you follow illegal content blacklists maintained by gov. If someone wants to fight the blacklist, ok, the eff can go to court, supreme court if necessary. This isn&#x27;t going to happen as long as black lists aren&#x27;t abused.<p>This puts your private blog on the same footing as social media giants. Everybody follows the same rules. If government blacklist is too aggressive, society debate can go to there, where it should be. Sue the government, in court, for doing black lists too aggressively. Mom and pop isps and blog owners aren&#x27;t at risk.<p>This also forces social media giants to make their sites content filterable by user agents.<p>They call it a user agent for a reason...<p>There doesn&#x27;t have to be a government blacklist for this to work, either. I&#x27;m just saying there could be. And if there was, this should be the focus of litigation, not 230.<p>IE, if the blacklist was truly used only for child porn, I don&#x27;t think this would go to court. But government and &quot;powers that be&quot; can&#x27;t hide behind social media giants for censorship enforcement. They make themselves directly responsible, and it better be in a way that society finds acceptable.')