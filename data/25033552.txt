Item(by='YeGoblynQueenne', descendants=None, kids=[25035085], score=None, time=1604920298, title=None, item_type='comment', url=None, parent=25031321, text='I&#x27;m happy to see we&#x27;re still in healthy disagreement. However, I have to\napologise for confusing you by describing my field as &quot;program learning&quot; which\nis admittedly vague, but I didn&#x27;t want to go into the particulars. My field is\nnot program synthesis, which is constructing programs from complete, formal\nspecifications. Rather, it&#x27;s Inductive Programming and more specifically Inductive\nLogic Programming (ILP), which is learning programs from examples, i.e.\n&quot;incomplete specifications&quot;. I&#x27;m not familiar with the General Program\nSynthesis Benchmark Suite, but the problem you list (test three strings are\nordered by length) is trivial for ILP approaches. Again, I don&#x27;t want to point\nto my own research, directly (I&#x27;m going through a bit of a modesty phase) (oh,\nalright, it&#x27;s just that the documentation of my project is crap).  However, I\nhave to say that even so, if something is a difficult problem for program\nsynthesis approaches, then it&#x27;s very unlikely that neural networks will do any\nbetter at it. For instance, do you know how well deep neural nets perform on\nthis benchmark? I can&#x27;t find any results with a quick search.<p>You make the point that one does not need to learn these &quot;obsolete&quot; AI\napproaches because they are not relevant anymore. I don&#x27;t understand why you\nsay that. These approaches are still state of the art for their respective\ntasks and there is no other approach that has been shown to do any better,\nincluding deep neural networks. In what sense are they &quot;no longer more than\nbriefly and tangentially relevant&quot; as you say?<p>Regarding the gold rush, the point of the analogy is that in a gold rush only\na very few people will ever strike gold. This is exactly the state of research\ninto deep learning currently. After a few initial big breakthroughs, like CNNs\nand LSTMs, progress has stalled and the vast, vast majority of published\npapers (or papers put on arxiv permanently) present incremental results, if\nthat. Literally thousands of deep learning papers are published each month and\nthe chance to have an impact is miniscule. From my point of view, as a\nresearcher, going into deep learning right now would be career suicide. Not to\nmention that, while the first few successes were achieved by small academic\nteams, who had typical academic motives (er, glory), the game has now passed\nto the hands of big corporate teams that have quite different incentives, so\nit&#x27;s almost impossible for small teams or individual researchers to make a\ndent.<p>As to the winter and whether GOFAI works, perhaps I haven&#x27;t convinced you with\nmy sources, but in that case, I have to go back to my earlier question and ask\nwhere your knowledge comes from. You clearly have a strong opinion on GOFAI\nand the AI winter of the &#x27;80s, but what knowledge does this opinion come from?\nCan you say? And if this sounds like a challenge, well, that&#x27;s because it is.\nI&#x27;m challenging you to re-examine the basis of your convictions, if you like.\nBecause to me, they sound like they are not well-founded and that you should\nput some water in your wine. The things you say &quot;don&#x27;t work&quot;, work and the\nthings you say work, don&#x27;t work as well as you say.<p>For my part, I certainly agree that GPT-3 or the next iteration of a large\ntransformer-built language model can be a useful tool, but such a tool will\nalways be limited by the fact that it&#x27;s, well, a language model, and it can\nonly do what language models do, which does not include e.g. the ability for\nreasoning (despite big claims to the contrary) or arithmetic (ditto) or\ngeneration of novel programs. For instance, the append() example you\nshow above is clearly memorised: you haven&#x27;t given the model any examples of\nappend(), so it can&#x27;t possibly learn its definition from examples. It only\nreturns a correct result because it&#x27;s seen the results of append() before. Not\n<i>the same</i> result, but close enough. Like I say, this ability can definitely\nbe useful- but its usefulness is limited compared to the ability to learn\narbitrary programs, never before seen.<p>btw, why do you need to give it the list &quot;a&quot;? What happens if this is ommitted\nfrom the prompt?')