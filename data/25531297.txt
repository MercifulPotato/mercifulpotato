Item(by='staticassertion', descendants=None, kids=[25531373], score=None, time=1608843169, title=None, item_type='comment', url=None, parent=25531239, text='&gt; The term &quot;defense in depth&quot; comes to mind.<p>Perhaps my least favorite phrase in security, used constantly to justify weak, meaningless, or harmful work as &quot;another layer&quot;.<p>U2F is just one layer. It&#x27;s a real, meaningful layer - it addresses real threats in a non-phishable way. Gating access by device, acls, etc, or locking down sharing permissions, are other real and meaningful layers.<p>&gt; some amount of bad stuff will land with the users<p>That&#x27;s the security team&#x27;s problem to solve.<p>&gt; But you can also imagine someone complying with that but then falling for a well crafted phish (that happened to me, as I mention elsewhere in this thread.)<p>I can just assume that one person will fail the phishing test already, and work from that angle. Way better than assuming I can teach an entire company to be untrickable.<p>&gt; Is there no data that humans can leak out by entering it in the wrong place?<p>Wire transfers were one example - there are others, and we have other ways to mitigate those without assuming users should bear the responsibility.<p>By &#x27;most types&#x27; I mean either phishing for credentials or as a delivery mechanism for malware - these would both be extremely difficult to do, or otherwise mitigated by other policies.<p>&gt; but you can imagine that in many businesses there is.<p>That&#x27;s their security team&#x27;s problem to solve.<p>Feel free to train users, I have no problem with it. We do it for compliance purposes, but it&#x27;s also a fun opportunity to engage with people about security, including meaningful security. And you <i>do</i> want people to be able to spot and report phishing, it&#x27;s just not something you should ever rely on, or compromise for.')