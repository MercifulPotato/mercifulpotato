Item(by='jedbrown', descendants=None, kids=[25641566, 25639828], score=None, time=1609802027, title=None, item_type='comment', url=None, parent=25634970, text='The index type for CSR need only index nodes. It&#x27;s the offsets (one per row) that need to index edges.<p>The blog&#x27;s portrayal of NVMe vs distributed memory is a bit off:<p>&gt; With modern NVMe drives random seeks arenâ€™t slow anymore, much faster than distributed network calls like you do when scaling the linked list-based graph.<p>Distributed memory machines has 1 microsecond off-node latency and 15-20 microsecond reductions (with thousands of nodes). These latencies have been pretty flat for the past 20 years in supercomputing, and have been widely available at cloud providers for the past few years. NVMe is not as fast as it&#x27;s made out to be. <a href="https:&#x2F;&#x2F;twitter.com&#x2F;SwiftOnSecurity&#x2F;status&#x2F;990797948354211840" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;SwiftOnSecurity&#x2F;status&#x2F;99079794835421184...</a><p>The other issue is that NVMe is more expensive than DRAM or HBM when you care about bandwidth (and graph&#x2F;network analysis is almost always memory bandwidth limited, even on HBM). Suppose you need to do 1000 traversals of a 1 TB data structure. This takes about 10 seconds with 100 HBM devices ($1 at on-demand pricing, assuming amortized startup), but days of saturating NVMe bandwidth.')