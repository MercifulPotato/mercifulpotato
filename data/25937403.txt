Item(by='iandanforth', descendants=None, kids=None, score=None, time=1611801336, title=None, item_type='comment', url=None, parent=25930190, text='I&#x27;ve built this as well! I won an internal hackathon with this and so I ran up against <i>many</i> of the issues you&#x27;ll find here.<p>1. There is unlimited flexibility in the prompt.<p>Seemingly irrelevant changes to the prompt can change whether you get out correct SQL or not. Sometimes you can just repeat things in the prompt and get different and better results. &quot;Write correct SQL. Write correct SQL&quot;<p>For any one input question you may be able to tweak the prompt to get the correct answer out. But you need to do this tweaking for each question (and know the correct answer you need). Tweaking one prompt may break all other input-output pairs.<p>2. Real questions involve multiple large schemas.<p>I deal with tables with thousands or tens of thousands of columns. There is no way you can get GPT-3 to deal with that scale with a simple input as shown here. And of course you want to join across many tables etc.<p>3. Syntax<p>Natural language is more robust than SQL, you can get <i>close</i> and get the point across. Most language models trained on general corpora are fundamentally not suited to the symbolic manipulation of languages like SQL.<p>This isn&#x27;t to say that GPT-3 couldn&#x27;t be part of a solution to this problem, but please restrain your exuberance, it&#x27;s not going to solve this problem out of the box.')