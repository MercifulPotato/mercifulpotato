Item(by='btilly', descendants=None, kids=None, score=None, time=1611711237, title=None, item_type='comment', url=None, parent=25922734, text='<i>What if you ingest 10s of millions of rows a day, and need to conditional updates based on those 10s of millions of rows?</i><p>Know your problem, then set things up appropriately.<p>I was addressing someone whose problem looked like a reporting query about a consumer application that was affecting the responsiveness of their consumer application.  For that case separate the transactional and reporting database and tune each appropriately.  That means, for example, different numbers of connections, different memory per connection, different amounts of temporary table space, and so on.<p>The problem that you&#x27;re describing is much like the one I&#x27;m currently facing, ingesting time series from a busy factory floor, then doing various kinds of analytics.  For that case, you can simply use one database, optimize reasonably, tune appropriately for the workload, and set appropriate expectations on responsiveness.<p>In all these cases you don&#x27;t need a distributed system.  Not unless your requirements are a lot harsher than what has been described so far.')