Item(by='lambda_obrien', descendants=None, kids=[25132259, 25130570, 25129500], score=None, time=1605644278, title=None, item_type='comment', url=None, parent=25127371, text='Why couldn&#x27;t several coordinating specialized search engines share their data via something like &quot;charge the downloader&quot; S3 buckets? Then you get an org like StackExchange who could provide indexed data from their site and the algorithms to search the data the most efficiently, GitHub can do the same for their specific zone of speciality, Amazon, etc.<p>Then anyone who wants to use the data can either copy it to their own S3 buckets to pay just once, or can use it with some sort of pay-as-you-go method. Anyone who runs a search engine can use the algorithms as a guide for the specific searches they are interested in for their site, or can just make their own.<p>You could trust the other indexers not to give you bad data, because you&#x27;d have some sort of legal agreement and technical standards that would ensure that they couldn&#x27;t&#x2F;wouldn&#x27;t &quot;poison the well&quot; somehow with the data they provide. Further, if a bad actor was providing faulty data, the other actors would notice and kick them out of the group or just stop using their data.<p>It would have to be fully open source, I agree with the other parts of Drew&#x27;s essay here, but I think we <i>could</i> share the index&#x2F;data somehow if we got together and tried to think about it. We just need a standard for how we share the data.')