Item(by='cpgxiii', descendants=None, kids=None, score=None, time=1605124630, title=None, item_type='comment', url=None, parent=25061313, text='FPGA vendor support for higher-level synthesis tools is still pretty poor. Not surprised on that front.<p>Offload-from-GC runtime tools do exist, e.x. Cudafy would translate .Net code into Cuda kernels and handle kernel dispatch. Of course, you were very limited in what constructs and types you could put in kernel functions, but you could write your whole application in C# and accelerate the important blocks.<p>In practice, a lot of beginner GPU computing has moved to the world of NN training and inference, in which the complexities of GPU offload are entirely wrapped by the libraries you use.<p>For traditional GPU-accelerated tasks, the limited languages available are not the problem. Decomposing your problem into a form that is amenable to GPU offload can be difficult, and if you&#x27;re experienced enough to do that well, writing Cuda kernels and dispatch in C++ is not an obstacle. For example, Cudafy meant you didn&#x27;t need to know Cuda-specific syntax and expressions, but you still had to understand the behavior and limitations of GPUs to write performant code.')