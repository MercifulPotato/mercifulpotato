Item(by='sumtechguy', descendants=None, kids=None, score=None, time=1611258670, title=None, item_type='comment', url=None, parent=25862264, text='That really depends on your software.<p>Something like a NOSQL style it is kind of built in that it will be distributed.  But that backs the compute cost back into the clients.  Each node is &#x27;crap&#x27; but you have hundreds so it does not matter.<p>Something like SQL server it comes down to how fast you can get the data out of the machine to clone it somewhere else (sharding&#x2F;hashing, live&#x2F;live backups, etc).  This is disk, network, CPU.  Usually in that order.<p>In most of the ones I ever did it was almost always network that was the bottleneck.  Something like a 10gb network card (was state of the art neato at the time, I am sure you can buy better now) you were looking at saturation of 1GB per second (if you were lucky). That is a big number.  But depending on your input transaction rate and how the data is stored it can drop off dramatically.  Put it local to the server and you can 10x that easy.  Going out of node costs a huge amount of latency.  Add in the req of say &#x27;offsite hot backup&#x27; and it slows down quickly.<p>In the &#x27;streaming&#x27; world like kafka you end up with a different style and lots of small processes&#x2F;threads which live on &#x27;meh&#x27; machines but you hash it and dump it out to other layers for storage of the results.  But this comes at a cost of more hardware and network.  Things like &#x27;does the rack have enough power&#x27;, &#x27;do we have open ports&#x27;, &#x27;do we have enough licenses to run at the 10GB rate on this router&#x27;.  &#x27;how do we configure 100 machines in the same way&#x27;, &#x27;how do we upgrade 100 machines in our allotted time&#x27;.  You can fling that out to something like AWS but that comes at a monetary cost.  But even virtual there is a management cost.  Less boxes is less cost.')