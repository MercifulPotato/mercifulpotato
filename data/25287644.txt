Item(by='jlokier', descendants=None, kids=None, score=None, time=1606992415, title=None, item_type='comment', url=None, parent=25286315, text='It&#x27;s actually not trivial to optimize dynamic prioritisation across multiple connections.<p>To keep a TCP <i>efficient</i>, the sending process needs to fill up the send buffer to a reasonable amount, generally by writing data to the kernel with write()&#x2F;send().  If the sending process doesn&#x27;t do this, the sending TCP will not send full frames as fast as the network or receiver allows, and do so at a steady cadence.<p>But to prioritise the data flow of multiple responses across multiple connections, the sender needs to <i>pause existing TCP flows</i> in progress as soon as it has higher priority response data ready to send if the higher priority TCP will send at full rate.  Yet if the higher priority TCP is sending slower than full rate temporarily due to slow start, congestion control or receive window full, etc., the lower priority TCP needs to be resumed <i>just enough</i> to fill the gaps.<p>It&#x27;s not even possible to do this with the ordinary sockets API, so it&#x27;s certainly not trivial.<p>With HTTP&#x2F;2 and TCP in kernel, it&#x27;s still not optimal because prioritised response data will be queued behind data already in the TCP send buffer, but at least there&#x27;s only one send buffer&#x27;s worth to compete with rather than lots.<p>With HTTP&#x2F;3 and QUIC in userspace, adaptive prioritisation can be optimised further because the decision is made on every packet just before it leaves the machine.<p>Per-packet prioritisation would be possible in theory with HTTP&#x2F;1 and HTTP&#x2F;2 by implementing TCP in userspace, or by implementing HTTP in kernelspace, in either case tightly coupling TCP and HTTP.  I don&#x27;t know of anyone doing it, because it would be a lot of work for a marginal gain.')