Item(by='charlesdaniels', descendants=None, kids=[24911299], score=None, time=1603828891, title=None, item_type='comment', url=None, parent=24911098, text='I agree yes. &quot;Traditional computing paradigms&quot; are (IMO) not all that interesting as research topics at this point. As far as I know, most of the work in that space is in branch prediction and cache replacement policies.<p>FPGAs are what you really want when you need to deal with high resolution data that is coming in at very high data rates. Often even a very fast general-purpose processor with hand-tuned assembly simply won&#x27;t have even the theoretical memory throughput to process your data without &quot;dropping frames&quot;. They also have the benefit of deterministic performance, which with modern caching&#x2F;branch prediction systems you can&#x27;t guarantee (AFAIK, my computer architecture knowledge isn&#x27;t that cutting edge).<p>They can also work really well if you have some computation you want to do that is so far off the beaten path for general-purpose processors (or so memory bound) that FPGAs can take the cake.<p>There is also some work in sprinkling even more hardlogic into the FPGA dies, like processors or accelerator cores for various applications. FPGAs are great for implementing the glue logic to move data between those.')