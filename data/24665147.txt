Item(by='dahart', descendants=None, kids=[24665572], score=None, time=1601661303, title=None, item_type='comment', url=None, parent=24664440, text='I&#x27;m curious, what does cheaper mean exactly, and how much cheaper is it? Is that cheaper to acquire the inferencing hardware, or cheaper in terms of energy efficiency? Is your inferencing running on servers, or commodity hardware... in the cloud or on user&#x2F;consumer devices?<p>I&#x27;d agree with the sibling comment; this depends completely on what you are trying to do, and how fast you need to do it. There&#x27;s nothing wrong with inferencing on a CPU, and I have no doubt it&#x27;s much cheaper in certain ways, but it&#x27;s also slower than what you can do on a GPU or custom ASIC, and there are reasons some people need it to go faster. One example that&#x27;s in wide deployment would be Nvidia&#x27;s DLSS for video games. It&#x27;d be pretty hard to run that in real time at 4k resolution on a CPU.')