Item(by='josephernest', descendants=None, kids=None, score=None, time=1606726387, title=None, item_type='comment', url=None, parent=25249109, text='To clarify: if you start from a given nonce and key:<p><pre><code>    cipher = AES.new(key, AES.MODE_GCM, nonce)\n    while True:\n        block = f.read(16*1024*1024)\n        if not block:\n            break\n        out.write(cipher.encrypt(block))\n</code></pre>\nyou get <i>exactly</i> the same result as if you do (with a big RAM, bigger than your file) it in one pass:<p><pre><code>        cipher = AES.new(key, AES.MODE_GCM, nonce)\n        out.write(cipher.encrypt(f.read()))\n</code></pre>\nPlease try it with pycryptodome, you will see it is.<p>You might find this unforunate in the naming, and .init(), .update(), etc. might have been better names to emphasize this.<p>So this shows that, in its current state, the chunking is just a &quot;RAM-efficient&quot; way to encrypt, but it writes exactly the same encrypted content, as if you did encrypt(...) in one pass. So as long as the file is under ~2^39 bits, it is fine (see  <a href="https:&#x2F;&#x2F;csrc.nist.gov&#x2F;publications&#x2F;detail&#x2F;sp&#x2F;800-38d&#x2F;final" rel="nofollow">https:&#x2F;&#x2F;csrc.nist.gov&#x2F;publications&#x2F;detail&#x2F;sp&#x2F;800-38d&#x2F;final</a>).<p>___<p>Then, there is <i>another layer</i> of chunking that would be possible, and that would add many benefits: even better deduplication, avoid to reencrypt a whole 10GB file if only a few bytes have changed.  \nThis would be an interesting addition, it&#x27;s on the Todo list, and I know some other programs do it, of course.<p>But to clarify: this &quot;content-chunking&quot; is independent to the &quot;RAM-efficient&quot; one I use here.<p>If you want to continue the discussion (more convenient than here), you&#x27;re very welcome to post a Github issue.<p>Thanks for your remarks, I appreciate it.')