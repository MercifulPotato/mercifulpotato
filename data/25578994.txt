Item(by='nexuist', descendants=None, kids=[25579189, 25579769, 25579199, 25579196], score=None, time=1609307590, title=None, item_type='comment', url=None, parent=25578815, text='&gt; What I don&#x27;t miss are the days of thunking, marshalling, bank switching, and segmented memory.<p>Been thinking about this for a while. Why don&#x27;t instruction sets define arrays at the hardware level? That seems to be where practically all the pain of memory management comes from - dynamically sized arrays (and 2D arrays i.e. matrices) that grow or shrink throughout the program&#x27;s lifecycle. Why aren&#x27;t `malloc` and `free` architecture-level instructions? Let the hardware worry about finding space within memory, it&#x27;ll almost certainly be faster than any software algorithm. And if you can do that, can&#x27;t you putdynamically sized arrays into the architecture as well? This solves so many software related problems. x86 is CISC so it&#x27;s not like they bother with instruction count; is there something I&#x27;m missing? Has this been tried before? I know SIMD is something similar, but I don&#x27;t think anything exists that tries to replace malloc&#x2F;free.')