Item(by='wahern', descendants=None, kids=None, score=None, time=1608083406, title=None, item_type='comment', url=None, parent=25437565, text='In general the law is absolutely not so rigorous. It&#x27;s more like general philosophical literature in terms of logical rigor--diverse, disjoint, etc. But certain subdomains of the law can be closer to a formal system.<p>The French tax code is peculiar (though I&#x27;m not sure its unique) in literally being defined by the rules encoded in an official program. A recent paper on a new language for compiling those rules, &quot;A Modern Compiler for the French Tax Code&quot; (<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2011.07966.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2011.07966.pdf</a>, via HN a couple of weeks ago), contains a blurb at the very end,<p>&gt; Closer to the topic of this paper, the logical structure of the US tax law has been extensively studied by Lawsky [18, 19], pointing out the legal ambiguities in the text of the law that need to be resolved using legal reasoning. She also claims that the tax law drafting style follows default logic [24], a non-monotonic logic that is hard to encode in languages with first-order logic (FOL). This could explain, as M is also based on FOL, the complexity of the DGFiP codebase.<p>See <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Default_logic" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Default_logic</a> and <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Non-monotonic_logic" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Non-monotonic_logic</a> But note that it&#x27;s written in that &quot;style&quot;, not that it&#x27;s done consistently or correctly. Unfortunately I couldn&#x27;t easily find a copy of the cited papers, but I made a note for later reference.<p>EDIT: I once took a class in law school taught by a Professor of Systems Engineering from the parent university. I forget why, but long ago he took an interest in the rules of evidence in the common law. While the rules evolved organically over more than a thousand years, they actually strongly reflect a formal system of abductive reasoning: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Abductive_reasoning" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Abductive_reasoning</a>. And there&#x27;s significant, hidden rigor. In one project he had everyone in class create a tree consisting of evidence (e.g. size 7 shoe) at the leaves, with the branches as inferences all the way up to the top, which was the core legal claim--1) Jim did 2) break and 3) enter into 4) said building.... Anyhow, being a programmer I decided to create my tree using the DOT language and render it using Graphviz. While I was doing that it occurred to me that some of the more esoteric, technical rules of evidence, such as that any piece of evidence can only be used to prove a single element, actually ensures that the tree is an acyclic graph. I&#x27;m not sure precisely why (perhaps the professor had more insight), but I believe it&#x27;s because the rules are in part crafted to ensure that the finder of fact is presented with a <i>tractable</i> problem to solve. The process would get too confusing (and possibly logically inconsistent?) if you didn&#x27;t keep the tree of evidence and inference simple. No judge or lawmaker likely ever had in mind the literal shape of the evidence tree. In fact, AFAIU nobody thought to represent it as a tree until the late 19th century, when the famous scholar of common law evidence, John Wigmore (<a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;John_Henry_Wigmore" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;John_Henry_Wigmore</a>), developed a system for analyzing and preparing trial evidence in that manner.<p>Anyhow, a proper and infinitely more rigorous treatment of this is presented in the book, &quot;Analysis of Evidence, 2nd Ed.&quot; by Terence Anderson, David Schum, and William Twining. (Schum taught the class.) A large part of the book explores and explains the law of evidence as a system of Bayesian reasoning. (Oh, that&#x27;s why! I think Prof. Schum first stumbled into the legal realm after he got the idea of using Bayesian statistics to resolve historically famous and contentious legal trials.)')