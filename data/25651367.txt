Item(by='thunderbird120', descendants=None, kids=[25652592, 25651667], score=None, time=1609882177, title=None, item_type='comment', url=None, parent=25650236, text='It&#x27;s not really surprising given what we now know about autoregressive modeling with transformers. It&#x27;s essentially a game of predict hidden information given visible information. As long as the relationship between the visible and hidden information is non-random you can train the model to understand an amazing amount about the world by literally just predicting the next token in a sequence given all the previous ones.<p>I&#x27;m curious if they do a backward pass here, would probably have value. They seem to describe sticking the text tokens first meaning that once you start generating image tokens all the text tokens are visible. That would have the model learning to generate an image with respect to a prompt but you could also literally just reverse the order of the sequence to have the model also learn to generate prompts with respect to the image. It&#x27;s not clear if this is happening.')