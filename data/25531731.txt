Item(by='maxov', descendants=None, kids=None, score=None, time=1608846369, title=None, item_type='comment', url=None, parent=25531510, text='I&#x27;m not sure what this implies. Nuclear is a good example, because it can have immense positives in providing clean and safe power. War has existed for millennia, but that doesn&#x27;t mean nuclear weapons aren&#x27;t a uniquely dangerous technology to enable it.<p>The example I gave is perhaps the worst possible scenario, where AI systems are specifically engineered for the <i>goal</i> of racial bias. The recent advancements in facial recognition technology (helped by the great progress in image recognition by neural nets) make possible a wide-spread surveillance system. I would certainly call the scale enabled by the automatable human-level performance of facial recognition systems dangerous, just like I would call the scale of destruction of nuclear weapons dangerous, even if they are dangerous in different ways.<p>Even then, e.g. in the United States AI systems aren&#x27;t necessarily engineered for bias. However, if we&#x27;re not careful, existing racial, gender, or socioeconomic biases in society can enter these systems and can be reinforced by them (this has already happened in well-documented ways). There I think AI ethics researchers can provide immense value in helping us identify and fix these urgent problems, and I welcome ethics researchers playing a part in any field for this reason.')