Item(by='desideratum', descendants=None, kids=[25653200, 25657472, 25656373, 25660332, 25653163], score=None, time=1609888847, title=None, item_type='comment', url=None, parent=25649557, text='Some truly impressive results. I&#x27;ll pick my usual point here when a fancy new (generative) model comes out, and I&#x27;m sure some of the other commenters have alluded to this. The examples shown are likely from a set of well-defined (read: lots of data, high bias) input classes for the model. What would be really interesting is how the model generalizes to &#x2F;object concepts&#x2F; that have yet to be seen, and which have abstract relationships to the examples it has seen. Another commenter here mentioned &quot;red square on green square&quot; working, but &quot;large cube on small cube&quot;, not working. Humans are able to infer and understand such abstract concepts with very few examples, and this is something AI isn&#x27;t as close to as it might seem.')