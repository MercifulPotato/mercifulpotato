Item(by='d_e_solomon', descendants=None, kids=None, score=None, time=1607188415, title=None, item_type='comment', url=None, parent=25315853, text='&gt; We&#x27;re talking about tech firms that have access to the entire internet and use it.<p>I think you&#x27;re trying to say that a large enough dataset will be free of bias. I don&#x27;t see how that follows. If I train a model on home mortgage decisions, I will replicate the bias on that currently exists on that dataset - <a href="https:&#x2F;&#x2F;news.northwestern.edu&#x2F;stories&#x2F;2020&#x2F;01&#x2F;racial-discrimination-in-mortgage-market-persistent-over-last-four-decades&#x2F;" rel="nofollow">https:&#x2F;&#x2F;news.northwestern.edu&#x2F;stories&#x2F;2020&#x2F;01&#x2F;racial-discrim...</a> - unless there are conscientious choices to reduce that bias.<p>Researchers in ethics in ML are specifically trying to enable tech companies to do a better job of not replicating bias and justifiably point out where that is occurring.<p>Third, I would argue that applying an ML model to do something faster if it replicates the bias of a previously human decision is even worse. The bias has taken the human element completely out and systematized the bias and made it possible with even less friction.')