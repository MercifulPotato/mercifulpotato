Item(by='webmaven', descendants=None, kids=None, score=None, time=1608520657, title=None, item_type='comment', url=None, parent=25489404, text='<i>&gt; But we&#x27;re still at the point where we don&#x27;t understand intelligence as well as we understood aerodynamics when building the first planes</i><p>Actually, I&#x27;d say that our understanding of intelligence is  right about at the level of aerodynamics at the dawn of heavier than air flight:<p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;Sp7MHZY2ADI" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;Sp7MHZY2ADI</a><p><a href="https:&#x2F;&#x2F;youtu.be&#x2F;gN-ZktmjIfE" rel="nofollow">https:&#x2F;&#x2F;youtu.be&#x2F;gN-ZktmjIfE</a><p>I mean, we could quibble about exactly where we are pre- or post-Wright Flyer, but given the amount of AI research that amounts to brute-force flailing about in search of incremental improvements, disagreements on the importance of &quot;biological plausibility&quot; and so on, it&#x27;s pretty clear that, roughly speaking, AI is currently <i>somewhere</i> in the equivalent of the Lilienthal-Langley-Wright-Curtis continuum (ie. 1890-1910-ish) and still prior to the most important theoretical breakthroughs. IOW, AI has not in my opinion yet achieved an equivalent to aerodynamics&#x27; Prandtl lifting-line theory: <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Lifting-line_theory" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Lifting-line_theory</a>')