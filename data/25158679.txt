Item(by='acqq', descendants=None, kids=[25158712], score=None, time=1605863258, title=None, item_type='comment', url=None, parent=25158623, text='NTFS on Windows was indeed always significantly slower when doing a lot of file operations. It was noticeable even long before WSL existed: NTFS and the whole infrastructure connected to it has by design bigger maintenance cost for every opening of the file, for example. That&#x27;s undeniable. One can say that NTFS could have maybe been implemented faster on some other system (with less hooks etc), but NTFS on Windows is provably slower for the file operations people do every day on Linux, that&#x27;s a simple fact. Like working with big source repositories containing a lot of files (git, node.js). The people who decided to make WSL2 faster for Linux programs achieved the speedup by going full VM. I would also prefer that they worked on NTFS on Windows long enough until the file operations become faster for everybody, but it didn&#x27;t happen.<p>That&#x27;s one of the lost opportunities that the original article laments about.<p>Edit: a reply to mehrdadnâ€™s &quot;try your operations on another file system&quot; answer: I don&#x27;t have to, I remember: there was a time when people used FAT formatted media much more than today -- and NTFS was slower than FAT too, under the same Windows, on the same hardware, without installing anything from third parties. It can be that on Windows 10 FAT got to be comparably slow, but in earlier times, on slower machines, FAT was visibly faster compared to NTFS. But NTFS was more robust to failures, and I preferred using NTFS for anything that is not temporary. I admit that the whole Windows infrastructure around what we consider purely &quot;a filesystem&quot; is also a serious part of the problem, by design. And as I wrote, it&#x27;s a lost opportunity that the bottlenecks weren&#x27;t identified and the changes made to the benefit of everything on some future Windows.')