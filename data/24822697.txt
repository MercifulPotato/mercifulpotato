Item(by='dredmorbius', descendants=None, kids=None, score=None, time=1603072043, title=None, item_type='comment', url=None, parent=24820317, text='For the code here, which I used on an actual dataset (~500 NYT Headlines 1965--1974), the efficiency gaains of a Go &#x2F; Python rewrite are ... slight.<p><pre><code>  real    0m0.176s\n  user    0m0.060s\n  sys     0m0.060s\n</code></pre>\nOn an early-2015 Android tablet running Termux.<p>I&#x27;ve thrown multimillion row datasets at awk (usually gawk, occasionally mawk, nawk on OSX, and, hell, busybox on occasion) without any practical performance issues.  I&#x27;m virtually always writing for one-off or project-based analyssys, not live web-scale realtime processing.  A second or even ten won&#x27;t be missed.<p>I&#x27;m also aware that building a pipeline out of grep &#x2F; cut &#x2F; sed &#x2F; tr &#x2F; sort &#x2F; uniq &#x2F; awk is often conceptually <i>nearer at hand</i>.  It almost always mirrors how I start exploring some dataset.<p>But a quick translation to straight awk gives cleaner code, more power, easier conversion to a script, and access to a small library of awk-based utilities I&#x27;ve acumulated.<p>All with far-more-than-adequate performance.<p>We&#x27;ve spent far more time discussing this than coding, let alone running, it.')