Item(by='accraze', descendants=None, kids=[25353700, 25353109], score=None, time=1607459502, title=None, item_type='comment', url=None, parent=25346456, text='Three papers stick out for me in the IML &#x2F; participatory machine learning space this year:<p>1) Michael, C. J., Acklin, D., &amp; Scheuerman, J. (2020). On interactive machine learning and the potential of cognitive feedback. ArXiv:2003.10365 [Cs]. <a href="http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2003.10365" rel="nofollow">http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2003.10365</a><p>2) Denton, E., Hanna, A., Amironesei, R., Smart, A., Nicole, H., &amp; Scheuerman, M. K. (2020). Bringing the people back in: Contesting benchmark machine learning datasets. ArXiv:2007.07399 [Cs]. <a href="http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2007.07399" rel="nofollow">http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2007.07399</a><p>3) Jo, E. S., &amp; Gebru, T. (2020). Lessons from archives: Strategies for collecting sociocultural data in machine learning. Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 306–316. <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;3351095.3372829" rel="nofollow">https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;3351095.3372829</a><p>Also a great read related to IML tooling for audio recognition:<p>1) Ishibashi, T., Nakao, Y., &amp; Sugano, Y. (2020). Investigating audio data visualization for interactive sound recognition. Proceedings of the 25th International Conference on Intelligent User Interfaces, 67–77. <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;3377325.3377483" rel="nofollow">https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;3377325.3377483</a>')