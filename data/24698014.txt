Item(by='thesz', descendants=None, kids=None, score=None, time=1601994637, title=None, item_type='comment', url=None, parent=24695023, text='&gt;In the brain, neurons cannot wait for a sequential forward and backward sweep.<p>I think that neurons hate when we animate them.<p>Being a little more serious, is it possible to perform gradual back propagation? I.e., for iteration 1 train only last layer, for iteration 2 change two last layers, for iteration 4 train three last layers, etc.<p>I also have to say that in my spare time I am investigating a way to train networks on the whole set as opposed to the single sample or batch back propagation and one result I&#x27;ve got so far is not quite uninteresting, in my opinion: <a href="https:&#x2F;&#x2F;github.com&#x2F;thesz&#x2F;higgs-logistic-regression" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;thesz&#x2F;higgs-logistic-regression</a><p>The approximation of gradients is still use of gradients. It still computes updates which are need to be shared and still has some bottleneck on scalability.')