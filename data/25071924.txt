Item(by='YeGoblynQueenne', descendants=None, kids=None, score=None, time=1605201008, title=None, item_type='comment', url=None, parent=25069341, text='&gt;&gt; Because priors are hard to embed in a model.<p>That&#x27;s a limitation of neural networks, where inductive biases are very difficult to represent. Other approaches don&#x27;t have any such problem, e.g. all the other approaches I listed above have well-defined, clean and tidy representations for inductive bias.<p>As to AlphaGo, this may come as a shock, but AlphaGo was not the first system to surpass humans in anything. It was the first system to surpass humans _in Go_ but e.g. the first computer system to beat a human grandmaster in chess was Deep Blue [1], in 1997, the first computer system to win a world championship against human players was the checkers (draughts) player Chinook [2], in 1990, the first computer system to outperform humans in medical diagnosis was MYCIN in the 1970&#x27;s and so on. All those were systems that used strong inductive biases.<p>And of course, AlphaGo itself was limited by human priors- e.g. piece moves, checkerboard dimensions and structure were hard-coded into its architecture and a search for moves was performed by MCTS.<p>In any case, the lack of good enough priors is not a reason to not use any priors- it&#x27;s a reason to look for better priors.<p>Edit: Has any end-to-end approach rediscovered an entire state-of-the-art architecture, like CNNs or LSTMs?<p>___________________<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Deep_Blue_(chess_computer)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Deep_Blue_(chess_computer)</a><p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chinook_(computer_program)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chinook_(computer_program)</a><p>[3] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mycin" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mycin</a>')