Item(by='core-questions', descendants=None, kids=None, score=None, time=1607964770, title=None, item_type='comment', url=None, parent=25418707, text='&gt; If an ML system is designed to maximize accuracy in predicting (say) criminality and there is a correlation between criminality and skin color, it’s quite likely that there will be more false positives of some skin colors than others. It’s not discrimination.<p>How is this wrong? Have you even looked at the statistics of crime by race, at all? If you&#x27;re expecting a perfectly proportionate level of criminality representative of the host population, I&#x27;ve got news for you: it&#x27;s not like that.<p>ML systems are simply &quot;naive&quot; in the sense that they don&#x27;t know when they should hide the truth because it disagrees with officially promoted narratives. I predict a market for ML censorware that can tell you when your ML system has discovered yet another uncomfortable truth and help you to prevent it from escaping so that you don&#x27;t end up with someone attacking you on Hacker News.<p>The OP is lambasting someone and assassinating their character simply for saying things that anyone with an open mind can research and confirm for themselves with a quick perusal of crime states. Disgusting. Cowardly, too, using a lame pseudonym: &quot;Ann Imus&quot;, which is obviously a thinly veiled reference to &quot;racial animus&quot;.<p>How about instead of leveling such insults, you instead familiarize yourself with reality, and then if you&#x27;re still bothered, pursue a life where you can make a difference to these outcomes instead of hiding behind a keyboard insulting people who notice them?')