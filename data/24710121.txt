Item(by='leereeves', descendants=None, kids=[24711790], score=None, time=1602089485, title=None, item_type='comment', url=None, parent=24708692, text='Number of parameters remains an important practical concern, and an important goal for research (see [1] for a recent example).<p>It is true that this model requires a large amount of unlabeled data, in addition to a small amount of labeled data, but gathering unlabeled data is often easy.<p>So I think it&#x27;s potentially misleading to say &quot;this approach remains at a severe disadvantage when amount of effort and time required to gather data and train something useful is accounted for&quot;.<p>I&#x27;d say this approach actually has a serious <i>advantage</i> compared to GPT3, which is locked inside the walls of OpenAI, can only be used with their permission, and is too big for most people to use (let alone train) anyway. The cost and effort to use this approach on large real world problems is probably less than using GPT3.<p>And it may also have an advantage in terms of the total amount of data and training required, when all of the data and training in the original pretrained models is included. That is, it may be a more efficient way to train new models from scratch for tasks for which few labeled examples are available.<p>1: <a href="https:&#x2F;&#x2F;ai.googleblog.com&#x2F;2020&#x2F;09&#x2F;advancing-nlp-with-efficient-projection.html" rel="nofollow">https:&#x2F;&#x2F;ai.googleblog.com&#x2F;2020&#x2F;09&#x2F;advancing-nlp-with-efficie...</a>')