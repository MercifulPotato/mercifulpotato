Item(by='YeGoblynQueenne', descendants=None, kids=[25042015], score=None, time=1604959284, title=None, item_type='comment', url=None, parent=25035085, text='In the interest of pruning this conversation a bit I will not continue the\ndiscussion about GPT-3. Apologies, but this thread is growing too fast and I\ndon&#x27;t have the time to give your comments the attention they deserve. I am\nhappy for you to have the last word in that matter.<p>&gt;&gt; These techniques were invented from the field of AI, but that does not mean\nthey remain in the field of AI.<p>Like I say above, it is pretty uncontroversial that these approaches are part\nof the field of AI research. You can consult wikipedia or e.g. the calls for\npapers from major AI conferences, AAAI and IJCAI, if in doubt.<p>So I have to ask again, why do you say these approaches are are not in the\nfield of AI research? According to whom? And based on what?<p>I would please like an answer to the above question.<p>Further, I can certainly point you to successes of symbolic AI, which you say\ndon&#x27;t exist. For one thing, the entire fields of automated theorem proving,\nplanning, search, game playing, knowledge representation and reasoning, etc.\nthat you say are &quot;not AI&quot;, but are like I say still active and still state of\nthe art in their respective tasks. These are certainly successful- they have\nproduced systems and techniques that still work best than any alternative and\nactually quite well.<p>For examples of specific systems that were successful in their time, see Logic\nTheorist [1] that proved 38 of the first 52 theorems in Principia Mathematica;\nChinook [2], the first computer program to win a world championship against\nhumans (in checkers&#x2F;draughts); Deep Blue [3], the first AI system to defeat a\nhuman grandmaster (Garry Kasparov) in chess; MYCIN [4] the first AI system to\noutperform human experts in disease diagnosis (specifically, diagnosis of\ninfections); and so on.<p>Of course these systems have been superseded - but they were successes\nnonetheless. Another reason to learn the history of AI is to become aware of\nthose systems- they, indeed, were &quot;there&quot;.<p>Again I have to ask you- where does your knowledge of AI come from? When\nyou make such strong statements about what works and what doesn&#x27;t, what failed\nand what succeeded, are you sure you are well informed? Do you draw your\nknowledge from primary sources, or are you trusting the opinions of others who\nclaim to be experts- but may not be (like in the article above)?<p>&gt;&gt; How would you tackle this with ILP?<p>Below I&#x27;ve defined the problem in the format expected by Louise [5]:<p><pre><code>  ?- list_mil_problem(ordered&#x2F;3).\n  Positive examples\n  -----------------\n  ordered([a],[b,c],[d,e,f]).\n  \n  Negative examples\n  -----------------\n  []\n  \n  Background knowledge\n  --------------------\n  shorter&#x2F;2:\n  shorter(A,B):-length(A,C),length(B,D),C&lt;D.\n  \n  Metarules\n  ---------\n  triadic_chain metarule &#x27;P(x,z,y):- Q(x,z), R(z,y)&#x27;.\n  true.\n</code></pre>\nGiven this problem definition, Louise can learn the following (Prolog) program:<p><pre><code>  ?- learn(ordered&#x2F;3).\n  ordered(A,B,C):-shorter(A,B),shorter(B,C).\n  true.\n</code></pre>\nTo explain, shorter&#x2F;2 is a predicate defined as background knowledge by me.\ntriadic_chain is a metarule, a second-order clause that provides inductive\nbias. length&#x2F;2 is an ISO Prolog predicate.<p>Like I say, this is a trivial problem, not least because its solution is easy\nto figure out and the background knowledge and metarules are trivial to define\nby hand. Louise can also perform <i>predicate invention</i> to define new\nbackground knowledge (kind of like inventing new features) and also new\nmetarules. That is to say, Louise can learn the shorter&#x2F;2 and length&#x2F;2\nprograms, also from very few examples- and then reuse them as background\nknowledge. But showing how to do that would make for a larger example. I&#x27;m\nhappy to oblige if you are curious.<p>I should point out that there exists no neural net approach that can learn the\nsame (or a similar) program from a single positive example- not least because\nneural nets cannot make use of background knowledge (i.e. a library of\nprograms from which to build other programs).<p>__________________<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Logic_Theorist" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Logic_Theorist</a><p>[2] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chinook_(computer_program)" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chinook_(computer_program)</a><p>[3] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Deep_Blue_versus_Garry_Kasparov" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Deep_Blue_versus_Garry_Kasparo...</a><p>[4] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mycin" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mycin</a><p>[5] <a href="https:&#x2F;&#x2F;github.com&#x2F;stassa&#x2F;louise&#x2F;" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;stassa&#x2F;louise&#x2F;</a>')