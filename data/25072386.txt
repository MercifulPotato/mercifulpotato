Item(by='bloaf', descendants=None, kids=[25075966, 25079317], score=None, time=1605203049, title=None, item_type='comment', url=None, parent=25068678, text='I am sympathetic to Gates&#x27; position to this day.  Some thoughts:<p>If you gave someone in 1994 the GPT-3 code and dataset, it would be impossible for them to regress and very difficult to run even if we regressed it for them. AI algorithms may not be limited by &quot;what we tell them&quot; but they ARE limited by the hardware we run them on.<p>NN models do converge to something (both in the sense of regressions converging, but also in the sense that adding more nodes eventually stops improving performance at a given task.)  I suspect but cannot prove that in most cases what it converges to could be expressed more concisely and efficiently as something other than a NN.  (I.e. that NNs can approximate any function does not imply they can do so efficiently)<p>So at the end of the day, the programmer needs to understand the algorithm well enough to know if a NN-based implementation of it would achieve sufficient performance on available hardware.  If the answer is no, then the programmer still has to come up with something alone.')