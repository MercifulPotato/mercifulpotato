Item(by='meowface', descendants=None, kids=[24806846], score=None, time=1602873605, title=None, item_type='comment', url=None, parent=24800220, text='&gt;In a trial a judge will often tell the jury to disregard information that has been improperly brought forth. It&#x27;s difficult to enforce, but what wouldn&#x27;t it make sense to have something similar in the court of public opinion?<p>No, I don&#x27;t think it&#x27;d make any sense. Courts of law are very specific, rigorous systems. Since people&#x27;s lives are on the line, it&#x27;s necessary to abide by a very precise spec. I don&#x27;t think Twitter and criminal trial courts can be considered analogous at all, and I very much hope they stay as separate as possible until the end of time.<p>&gt;Also, it&#x27;s a slippery slope argument, but I&#x27;ll point out that &quot;once it&#x27;s been said, it&#x27;s true&quot; is a social anti pattern. If I lie, and someone else quotes me, does that make it information that is &quot;out there&quot; or is it just noise?<p>It is a social anti-pattern, but it&#x27;s the role of respondents to discuss and assess if something is true or not. If something has significant indications of possibly being a hoax, Twitter may be in the right to add a label saying it may be a hoax, but I don&#x27;t think they have the right to just remove it. If it&#x27;s a truly unsubstantiated and damaging and&#x2F;or absurd conspiracy theory (Seth Rich, Pizzagate, Q, etc.), they can put it behind a warning wall with links to resources showing it&#x27;s false, but even then I still don&#x27;t think they have a right to just remove it.<p>In a case like this, where as far as I can tell there isn&#x27;t currently any strong evidence it&#x27;s a hoax (just information that happened to be obtained unscrupulously and possibly illegally), it&#x27;d be especially egregious to remove it or even put a warning near it. I don&#x27;t think tech executives should hold the power to judge what is and isn&#x27;t a social anti-pattern and to ban them, beyond what&#x27;s already banned in their terms of service (abuse&#x2F;harassment&#x2F;etc.).<p>Also, to turn the slippery slope around, do you think Twitter should have banned all references to Snowden&#x27;s NSA leaks, due to the information being released illegally? Or the Pentagon Papers, if Twitter existed then? What about the Shadow Brokers compromise&#x2F;leak (which possibly was a result of Russian intelligence hacking NSA or noticing some tools they mistakenly left on a system, though the attribution is still unconfirmed)?<p>When is Twitter supposed to judge that disclosure of illegally-obtained information is okay or not okay to censor? Obviously there are some cases where they should censor the material, like someone&#x27;s explicit photos being leaked as a result of an iCloud account compromise, but especially when it comes to high-profile political leaks or hacks, censorship seems like a terrible idea.<p>I&#x27;m definitely on the anti-Trump, left-leaning side, but even with the current US polarization I&#x27;m kind of surprised how many people seem to have a massive bias and blindspot here. If this were Donald Trump Jr.&#x27;s emails plucked by a repair shop owner, discussing arrangement of some large payment from Lukoil, I don&#x27;t think any of the people making these arguments would be at all consistent (beyond maybe agreeing the acquisition was unethical).<p>The way to address the exposure is to actually look at the contents of the emails and determine what it may imply about Joe Biden and his son, if anything; not to just try to get them removed from the internet Streisand-style. If there is actual misconduct or malfeasance here that implicates Joe Biden, that&#x27;d be especially unethical and irrational to call for. So far I&#x27;m kind of skeptical that that is the implication here, but it still needs to be assessed impartially.')