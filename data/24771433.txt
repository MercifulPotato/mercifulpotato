Item(by='shagie', descendants=None, kids=None, score=None, time=1602631065, title=None, item_type='comment', url=None, parent=24768970, text='This gets to a different philosophy of voice assistant computing between the companies.<p>Google (and Amazon) have significant cloud infrastructures.  The sequence of wake -&gt; audio clip -&gt; cloud -&gt; process -&gt; command -&gt; device --- that&#x27;s how they do it.<p>Apple has taken a different route with a limited set of &quot;domains&quot; which have voice processing associated with them.  These can be seen in <a href="https:&#x2F;&#x2F;developer.apple.com&#x2F;documentation&#x2F;sirikit" rel="nofollow">https:&#x2F;&#x2F;developer.apple.com&#x2F;documentation&#x2F;sirikit</a> which has different apps register that they can handle different domains.<p>This means that Google (and Amazon) will have a stronger parsing of those sentences and commands for arbitrary queries.  Siri, however, has a stronger integration with arbitrary commands that are part of an existing &#x27;domain&#x27; being handled by an existing app.<p>The multiple device wake is an interesting problem (I&#x27;ve seen Alexa, when two devices both wake, verify that the correct one had the response).  With Siri, I&#x27;ve seen multiple devices wake, but I haven&#x27;t had multiple ones respond - I suspect there&#x27;s some network traffic to decide which one has the best audio signal and ability to process the information... but that&#x27;s my experience, I could very well be wrong there.<p>The thing is that this really goes to a difference in philosophy about how voice assistants work and integrate with different 3rd party applications.')