Item(by='tmabraham', descendants=None, kids=None, score=None, time=1607457843, title=None, item_type='comment', url=None, parent=25350470, text='recently, a lot of neural network models, especially those in NLP (like GPT-3, BERT, etc.) use &quot;attention&quot; which basically is a way for neural networks to focus on certain subset of the input (the neural network can focus its &quot;attention&quot; to a particular part of the input). Explanations just refers to ways for explaining the predictions of the neural networks.')