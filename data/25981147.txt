Item(by='zackmorris', descendants=None, kids=None, score=None, time=1612117516, title=None, item_type='comment', url=None, parent=25978383, text='Ya the method I want to try is transpiling Lisp to C and then running that on GPU (so no segfaults). As far as I can tell, the problem is that I can only run 10,000 copies of the same shader, not 10,000 different shaders at once on the same data.<p>This is the closest I can come to a &quot;proof&quot; that today&#x27;s hardware is on the wrong branch of the search space of possible hardwares.<p>I&#x27;m hoping to be proven wrong though, and that someone knows a way to run say 16 or more different shaders simultaneously on a GPU. Maybe there is a way to encode the variations in sub-shaders and run those at the same time or something?<p>Edit: a few more links about running concurrent GPU kernels:<p><a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;53341888&#x2F;539149" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;53341888&#x2F;539149</a><p><a href="https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;52978372&#x2F;539149" rel="nofollow">https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;52978372&#x2F;539149</a><p><a href="https:&#x2F;&#x2F;community.amd.com&#x2F;t5&#x2F;opencl&#x2F;opencl-concurrent-kernel-execution&#x2F;td-p&#x2F;112686" rel="nofollow">https:&#x2F;&#x2F;community.amd.com&#x2F;t5&#x2F;opencl&#x2F;opencl-concurrent-kernel...</a><p><a href="https:&#x2F;&#x2F;community.khronos.org&#x2F;t&#x2F;concurrents-kernels-in-opencl&#x2F;7604" rel="nofollow">https:&#x2F;&#x2F;community.khronos.org&#x2F;t&#x2F;concurrents-kernels-in-openc...</a><p><a href="http:&#x2F;&#x2F;ecosimulation.com&#x2F;chrisgregg&#x2F;Publications&#x2F;Fine-GrainedResourceSharing.pdf" rel="nofollow">http:&#x2F;&#x2F;ecosimulation.com&#x2F;chrisgregg&#x2F;Publications&#x2F;Fine-Graine...</a><p><a href="http:&#x2F;&#x2F;docs.potionmagic.eu&#x2F;per.pdf" rel="nofollow">http:&#x2F;&#x2F;docs.potionmagic.eu&#x2F;per.pdf</a><p><i>Unfortunately, concurrent kernels execution is only possible with CUDA on NVIDIA graphics cards. For other cards, OpenCL does not offer this functionality.</i><p>Looks like it may only be possible on NVIDIA, according to the last link. Since this was the first thing I wanted to do with OpenCL, it doesn&#x27;t bode well for the standard or AMD. As a software developer, I see this issue a lot. What happened is, their public interface is too thick so doesn&#x27;t reflect the actual capabilities of the hardware. I hit this with OpenGL too way back before ES2 and shaders were mainstream. I just wanted direct access to some of the matrix hardware math but couldn&#x27;t get to it.<p>I&#x27;d vote to scrap current GPU implementations and move to a pure 2D or 3D grid of compute units (a bit like AWS EC2) running something like Docker. Then write OpenGL, OpenCL, Vulkan, Metal and the rest as niche libraries implementing use cases above the runtime. That would give us bare metal access to get real work done with languages like C, Rust, MATLAB, Julia, Erlang, Go, etc and finally drop the distinction between CPU and GPU.')