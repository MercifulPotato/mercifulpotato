Item(by='visarga', descendants=None, kids=None, score=None, time=1605185931, title=None, item_type='comment', url=None, parent=25068990, text='&gt; Why would we not use those finely honed biases of ours and all the knowledge we&#x27;ve collected to kickstart a new form of intelligence?<p>Because priors are hard to embed in a model. For example, CNNs are great for translation invariance, but rotation and scaling don&#x27;t come out of the box. Why don&#x27;t they simply add the rotation invariance to the model? Because it&#x27;s hard to express.<p>Also, human priors are limited. If AlphaGo was to be limited to human priors it would never have surpassed us.<p>The best approach so far is to make a network as free from priors as possible (like the transformers) and let it learn from the data, in essence let it rediscover the convolution or other efficient operations from mountains of data.')