Item(by='jdale27', descendants=None, kids=None, score=None, time=1610000887, title=None, item_type='comment', url=None, parent=25667687, text='Ideally research does get reproduced from scratch; I think what people usually mean when they talk about the replication&#x2F;reproducibility crisis in science is not being able to reproduce an experiment with new samples, independent data analysis, etc.<p>However, if you can&#x27;t even reproduce an analysis with the authors&#x27; own data and code, that&#x27;s a red flag before you even get to the starting line. Ensuring that level of reproducibility is, I think, an essential ingredient to enabling the stronger form of reproducibility.<p>Personally, I made the mistake during my graduate career of trying to reimplement an analysis using a certain rather complicated ML algorithm, from scratch, in a different language than the original authors had used. After struggling mightily to get it to work, I finally bothered to try to get their own code working. (I had been hesitant to do so because I wasn&#x27;t proficient in the language they used, and it wasn&#x27;t even clear they had released all the necessary code, aside from the core algorithm.) Once I did that, I discovered that I couldn&#x27;t even get their own code working on their own data, and gave up. This was researched published in Science by a group from a top-tier research university. (I don&#x27;t fully blame the authors, it may well have been my own incompetence that was the issue. But it just serves as yet another illustration of how pervasive and disregarded the reproducibility issue was for a long while.)')