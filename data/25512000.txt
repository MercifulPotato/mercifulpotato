Item(by='Thorrez', descendants=None, kids=None, score=None, time=1608675539, title=None, item_type='comment', url=None, parent=25502688, text='The word entropy can refer to 2 separate things, but they are somewhat related:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Entropy_in_thermodynamics_and_information_theory" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Entropy_in_thermodynamics_and_...</a><p>&gt;My greatest concern was what to call it. I thought of calling it &#x27;information,&#x27; but the word was overly used, so I decided to call it &#x27;uncertainty.&#x27; When I discussed it with John von Neumann, he had a better idea. Von Neumann told me, &#x27;You should call it entropy, for two reasons. In the first place your uncertainty function has been used in statistical mechanics under that name, so it already has a name. In the second place, and more important, no one really knows what entropy really is, so in a debate you will always have the advantage.&#x27;<p><a href="https:&#x2F;&#x2F;en.wikiquote.org&#x2F;wiki&#x2F;Claude_Elwood_Shannon" rel="nofollow">https:&#x2F;&#x2F;en.wikiquote.org&#x2F;wiki&#x2F;Claude_Elwood_Shannon</a>')