Item(by='DonaldPShimoda', descendants=None, kids=None, score=None, time=1603822671, title=None, item_type='comment', url=None, parent=24903337, text='I want to preface this by saying that most of this comment is kind of blunt and wordy, but I really don&#x27;t intend it to be taken rudely. I just wanted to address your points very explicitly to explain my position more clearly. I value your contributions and hope you&#x27;ll take this response in the spirit I intend it.<p>&gt; My point was that &quot;parsing with derivatives&quot; not necessarily a slow thing and I provided example supporting that point.<p>I actually don&#x27;t think you supported this point, because I specifically said (emphasis new):<p>&gt; A fun one to include might be <i>Might&#x27;s &quot;Parsing with Derivatives&quot;</i>, which is algorithmically novel (though not very performant).<p>I was explicitly talking about the 2011 paper titled &quot;Parsing with Derivatives&quot; which generalizes Brzozowski&#x27;s derivatives from REs to CFGs, and which has absolutely terrible performance compared to most other parsers for CFGs.<p>You went on a bit of a tangent by arguing about &quot;using derivatives to parse REs in general&quot; (to paraphrase). This was never the scope of what I was talking about. Whether derivatives can be used to parse REs efficiently is irrelevant when I was specifically referring to the 2011 paper, which provides a novel, general parsing algorithm — not LL, not LR, not GLL, not GLR, but just &quot;general&quot;, for all CFGs in existence.<p>&gt; I have not misinterpreted your argument. I have provided a point where it does break because I consider that point important.<p>I still think you misinterpreted me, because you&#x27;re talking about &quot;how can derivatives be used to parse things efficiently&quot; while I was talking about &quot;the contributions of this specific 2011 paper that introduced a new general parsing algorithm that can handle all CFGs and which happens to be called &#x27;Parsing with Derivatives&#x27;&quot;.<p>At this point I want to say that I&#x27;m not trying to be mean here, and I really hope that&#x27;s not how I&#x27;m coming across. I just think something isn&#x27;t connecting in our dialogue, so I&#x27;m trying to be overly explicit and cautious in my wording to make sure I don&#x27;t introduce any possibility for misinterpretation.<p>&gt; The reader of our conversation will, from now on, I hope, not consider the original &quot;parsing with derivatives&quot; paper as the state of the art and, probably, will come up with something himself.<p>See, this is the thing. The 2011 paper I referenced isn&#x27;t about REs, but your papers <i>were</i> about REs. The 2011 paper introduced a brand-new general parsing algorithm to the world. It was subsequently refined by Adams, Hollenbeck, and Might in 2016&#x27;s &quot;On the Complexity and Performance of Parsing with Derivatives&quot; [0], and then again refined by Darragh and Adams in &quot;Parsing with Zippers&quot; [1] (published at ICFP this year). To the best of my knowledge, the materials you&#x27;ve linked so far do not even reference the 2011 paper and so cannot be said to improve on the state of the art in that regard, where &quot;state of the art&quot; refers to &quot;state of parsing all CFGs using a derivative-based approach rooted in the Brzozowski derivative&quot;. They instead start with the 1964 Brzozowski paper that originated the derivative of regular expressions and improve on that directly — meaning they are not addressing CFGs in general, as the 2011 paper I was talking about does. Your paper and the 2011 paper are more like siblings in that they both descend from the same 1964 paper, but solve different problems. So I think it would be misleading to suggest that your paper is an improvement on the state of the art of the 2011 paper because they&#x27;re really very different problem domains, despite both involving &quot;parsing&quot; and &quot;derivatives&quot;.<p>&gt; I think that parsing with derivatives can be used as a tool to parse (in parallel! possibly sharing derivatives computed!) parts of text with regular subgrammars and then something like CYK can be applied (again, in parallel like in [1]) to the regions parsed.<p>So, if I&#x27;m understanding you right, you&#x27;re suggesting using a hybrid approach. I think that&#x27;s an interesting idea! I don&#x27;t know that I&#x27;ve seen much done like that. I do know that CYK is almost completely ignored in PL these days, so perhaps there is some other strategy to use there to augment the derivatives-of-REs subcomponents. I&#x27;ll have to think about that. What a neat idea!<p>[0] <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;2980983.2908128" rel="nofollow">https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;2980983.2908128</a><p>[1] <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;3408990" rel="nofollow">https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;3408990</a>')