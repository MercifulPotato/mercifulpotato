Item(by='adeledeweylopez', descendants=None, kids=[25204657, 25204332], score=None, time=1606254913, title=None, item_type='comment', url=None, parent=25202407, text='Entropy is a measure of the uncertainty that an observer has over the microstates (i.e. the exact state of every atom) given their knowledge of the macrostate (i.e. what they are capable of describing: like &quot;the water is just above freezing&quot;). So it&#x27;s inherently a subjective concept. The most common unit for entropy is the bit, same unit as information.<p>Anyway, entropy is measurable just like any other physical quantity. You need to determine what your model of the microstates is (often an &quot;ideal gas&quot;, with independent molecular point particles with their own positions and velocities, and all interactions are perfectly elastic collisions), what you currently know (stuff like type of gas, pressure&#x2F;volume&#x2F;temperature), and then there is a clear answer to what the entropy is.<p>The true law underlying the second law of thermodynamics is conservation of information. In (classical) physics, this is typically cast as Liouville&#x27;s theorem, which shows that the area of the phase space of a system must remain constant. (In quantum, it&#x27;s only true for unitary transformations, which may or may not be everything depending on your interpretation of QM).<p>Anyway, if you&#x27;re curious about learning more, I highly recommend <a href="http:&#x2F;&#x2F;www.av8n.com&#x2F;physics&#x2F;thermo" rel="nofollow">http:&#x2F;&#x2F;www.av8n.com&#x2F;physics&#x2F;thermo</a> which is an amazing online (and free) book that clarifies the concepts of thermodynamics brilliantly.')