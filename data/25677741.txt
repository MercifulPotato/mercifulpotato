Item(by='kllrnohj', descendants=None, kids=[25678140], score=None, time=1610054812, title=None, item_type='comment', url=None, parent=25676242, text='&gt; Desktop Nvidia simply converts them to 32-bit floats up front so the performance is kept but memory is wasted<p>Pascal has native FP16 operations and can execute 2 FP16&#x27;s at once ( <a href="https:&#x2F;&#x2F;docs.nvidia.com&#x2F;cuda&#x2F;pascal-tuning-guide&#x2F;index.html#fp16" rel="nofollow">https:&#x2F;&#x2F;docs.nvidia.com&#x2F;cuda&#x2F;pascal-tuning-guide&#x2F;index.html#...</a> )<p>BUT, and this is where things get fucked up, Nvidia then neutered that in the GeForce lineup because market segmentation. In fact, it&#x27;s <i>slower</i> than FP32 operations: &quot;GTX 1080â€™s FP16 instruction rate is 1&#x2F;128th its FP32 instruction rate&quot; <a href="https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;10325&#x2F;the-nvidia-geforce-gtx-1080-and-1070-founders-edition-review&#x2F;5" rel="nofollow">https:&#x2F;&#x2F;www.anandtech.com&#x2F;show&#x2F;10325&#x2F;the-nvidia-geforce-gtx-...</a>')