Item(by='cle', descendants=None, kids=None, score=None, time=1607985534, title=None, item_type='comment', url=None, parent=25423610, text='One of the big reasons for this that I&#x27;ve seen is that it&#x27;s easier to measure &quot;coverage&quot; with unit tests. Many managers and engineers like things that are easier to measure, even if they&#x27;re measuring the wrong thing. It can also be a cover-your-ass strategy--if a major catastrophe occurs, you don&#x27;t want to be defending your decisions without data. From that perspective, &quot;we feel like we had sufficient integration test coverage&quot; is much worse than &quot;we have 95% unit test coverage&quot;. You don&#x27;t want to make it easy to become a scapegoat, and mountains of data are good protection, whether they&#x27;re relevant data or not.<p>I too generally only write unit tests for tricky pieces of code, especially when it&#x27;s dealing with concurrency which tends to be difficult to test deterministically at the API level. There are other good reasons to write unit tests, such as execution speed, complexity of setting up a testing environment, faster development feedback loops, etc.')