Item(by='bnegreve', descendants=None, kids=None, score=None, time=1601622160, title=None, item_type='comment', url=None, parent=24658991, text='I don&#x27;t think Relus are the proplem. Relus are good, but artificial neural networks can work with sigmoid activation fonctions instead. The neurones in an ANN with sigmoids are somewhat close to what is described in this article.<p>The main problem is that the neurons in this article are not trainable (you can&#x27;t update the weights dynamically) and not differentiable (you can&#x27;t use the usual gradient-based training procedures to update the weights). They could be used for inference only though.')