Item(by='jorangreef', descendants=None, kids=[25222171, 25222293, 25222169], score=None, time=1606411953, title=None, item_type='comment', url=None, parent=25221805, text='The advertised bandwidth for RAM is not actually what you get per-core, which is what you care about in practice.<p>If you want to know the upper bound on your per-core RAM bandwidth:<p>64 bytes (the size of a cache line) * 10 slots (in a CPU core&#x27;s LFB or line fill buffer) &#x2F; 100ns (the typical cost of a cache miss) * 1000000 * 1000 (to convert ns to ms to seconds) = 6400000000 bytes per second = 5.96 GiB per second RAM bandwidth per core<p>There&#x27;s no escaping that upper bound per core.<p>Nanosecond RAM latencies don&#x27;t help much when you&#x27;re capped by the line fill buffer and queuing delay kicks in spiking your cache miss latencies. You can only fetch 10 lines at a time per core and when you exceed your 5.96 GiB per second budget your access times increase.<p>If you compare with NVMe SSD throughput plus Direct I&#x2F;O plus io_uring, around 32 GIB per second and divide that by 10 according to the difference in access latencies, then I think the author is about right on target. The point they are making is valid: it&#x27;s the same order of magnitude.')