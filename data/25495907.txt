Item(by='bgrsgeg', descendants=None, kids=[25496408, 25496132], score=None, time=1608565514, title=None, item_type='comment', url=None, parent=25493804, text='I think cameras are done. And not because of cellphones. I think Lytro did them in.<p>First a cop out to what I&#x27;m about to say. My arguments are specifically for geometric optics as used in photography. Also, my argument is in the limit that (non-optical) technology gets better. Also, while I took (and loved) many optics classes at university a lifetime ago, I ultimately did not become an optical engineer. I&#x27;m sure there are many nuances in my arguments bellow.<p>But largely they should be correct.<p>The Lytro camera is a camera that records the angle of incidence of light rays. If you have the angle of incidence of rays then the entire problem of (geometric) lens design is finished. Everything a lens can do can be done in software. Think of Lytro as software defined radio.<p>With a light field camera you can design the physical lens with a single objective: f-stop. Gather as much light as possible. You can adjust everything else in software. This is like SDR where (I guess) you optimize the antenna for bandwidth and noise.<p>By adjust I don&#x27;t mean &quot;adjust&quot; as in apply AI or heuristic to make it <i>appear</i> as if you&#x27;ve achieved a goal. This is what your cellphone does. I actually change the lens. Since you have the ray&#x27;s angle of incidence you can roll the rays back to before they reached the camera lens, and then put your own, software defined, lenses. This is probably not how you would implement the algorithm, but it illustrates the point.<p>Therefore you can change focal length, aperture, break physical limits (ridiculous index of refractions with no dispersion. infinitely thin lens).<p>Back to reality, what does it take to achieve all of this? Optically the Lytro all ready did all of this. It failed, but for the reasons that an Apple product would hit it out of the ballpark - implementation. With better software&#x2F;computer power the product would be easier more convenient to use. With bigger, better sensors (to better capture the ray&#x27;s angle) the camera would be able to emulate more lenses.<p>Therefore, 20th century type photography is dead. A modern photographer could just take a camera out, really take a shot without minding much about aiming it [1], completely ignore light and focus, and everything else could be done in software.<p>Frankly I think this will kill photography - but honestly, I think cell phones have killed most non-art, non-professional photography already. Amateurs are far worse (i.e. boring) photographers today then 30 years ago. That&#x27;s a judgement call, sure, but that&#x27;s what I enjoy.<p>[1] As long as the subject is captured, it won&#x27;t really matter. You can pan in post processing. You can even adjust for perspective [2]! Just roll the rays outside the physical lens, and move your software lens to where you want it.<p>[2] Perspective - the size of elements of the scene wrt to each other - is strictly about where the camera is wrt to the subject. It has nothing to do with the lens. Lazy photographers make the mistake of &quot;zooming&quot; into the subject to get close - but the subject is as flat. In software, you can move the lens, and therefore even change perspective.')