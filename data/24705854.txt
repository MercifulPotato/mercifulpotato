Item(by='shoo', descendants=None, kids=None, score=None, time=1602052802, title=None, item_type='comment', url=None, parent=24705150, text='(this answer from limited practical experience 10 years ago, but at least the theory doesn&#x27;t go out of date):<p>random forest is less prone to over fitting as each tree in the ensemble is independent, if the base tree doesn&#x27;t over fit then a random Forest of them also will not over fit.  Whereas trees in a boosted model are not independent, boosting trains a sequence of models where model n depends on the previous models.<p>This is a double edged sword: you can probably get better predictive accuracy with boosting if you have enough data &amp; have controls to prevent over fitting.  Whereas a random forest is much more idiot proof to over fitting but it will not perform as well as a boosted model trained but not overfit on a large dataset.')