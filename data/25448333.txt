Item(by='derbOac', descendants=None, kids=[25449179, 25448531, 25449729, 25449487, 25448541], score=None, time=1608151483, title=None, item_type='comment', url=None, parent=25444299, text='Underlying this all is a sort of scientism issue. On the one hand you have a culture that assumes the framework of a scientific framework is &quot;truth&quot; and that the lingua franca of risk should be demonstrable evidence. On the other is a culture that denies the realism of the scientific studies, and sees risk in misrepresentative evidence.<p>Generally speaking, the latter camp gets labeled as &quot;antiscientific&quot; by the former, and the former gets labeled as &quot;elitist&quot; or having conflicts of interest. It&#x27;s part of a theme that seems to be popping up a lot in the last several years or so in numerous settings: which is worse, lack of evidence or misleading evidence?<p>This example with the salmon is interesting to me because (if I&#x27;m understanding it correctly), the compound in the tire isn&#x27;t the problem, it&#x27;s a byproduct of tire breakdown. So I could see a chemist in the lab sitting there saying &quot;ok we ran our tests on X it&#x27;s fine&quot; without understanding that in the real world, X reacts and breaks down into other compounds that are problematic. It&#x27;s kind of a prime example of how the scientific model isn&#x27;t the correct one to be using in the first place. Within the bounds of the model, X is fine, but the model is wrong as a representation of reality, so the conclusions are wrong.<p>I think underlying a lot of this are differing ideas of what is &quot;scientific&quot;, or what constitutes the universe of risks. I don&#x27;t see this dynamic changing until certain cultures surrounding scientific authority change.')