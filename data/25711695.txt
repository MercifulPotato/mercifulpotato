Item(by='polm23', descendants=None, kids=[25729643], score=None, time=1610262033, title=None, item_type='comment', url=None, parent=25711669, text='This is a short overview of the state of NLG by Robert Dale, co-author of &quot;Building Natural Language Generation Systems&quot;, which is basically the book for NLG.<p>He give a list of commercial providers and concludes that most of them just offer smart templates. This is the important part:<p>&gt; To the extent that you can tell from the clues to functionality that are surfaced by these various products, all the tools are ultimately very similar in terms of how they work, which might be referred to as ‘smart template’ mechanisms. There is a recognition that, at least for the kinds of use cases we see today, much of the text in any given output can be predetermined and provided as boilerplate, with gaps to be filled dynamically based on per-record variations in the underlying data source. Add conditional inclusion of text components and maybe some kind of looping control construct, and the resulting NLG toolkit, as in the case of humans and chimpanzees, shares 99% of its DNA with the legal document automation and assembly tools of the 1990s, like HotDocs (<a href="https:&#x2F;&#x2F;www.hotdocs.com" rel="nofollow">https:&#x2F;&#x2F;www.hotdocs.com</a>). As far as I can tell, linguistic knowledge, and other refined ingredients of the NLG systems built in research laboratories, is sparse and generally limited to morphology for number agreement (one stock dropped in value vs. three stocks dropped in value).<p>That sounds pretty negative, but he emphasizes that putting an easy-to-use UI on well understood technology is meeting real business needs.<p>At the end he briefly touches on GPT2 and related technology.')