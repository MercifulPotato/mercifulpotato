Item(by='bastawhiz', descendants=None, kids=None, score=None, time=1609369975, title=None, item_type='comment', url=None, parent=25586063, text='When I worked at Uber, one of the big goals of my team was converting spreadsheets from the finance team to Python and Java. The second two problems that the author mentions (pulling in more data and software best practices) were two huge factors. In the former case, you simply cannot have an org where analysts have full read access to every data store to dump a CSV (of sensitive data collocated with lord knows what) at any time. It&#x27;s a security nightmare. And in the latter case, when you&#x27;ve reached a point of sufficient complexity, you can no longer &quot;roll out an update&quot; to a team of more than a few people. Without versioning and source control, the model_v2_final_FINAL(1)(1).xlsx problem becomes extreme (even on cloud platforms). This leads to mistakes, and mistakes cost time and money.<p>Excel has other problems that aren&#x27;t described in the article. First, it intermingles data and logic. If you&#x27;re not especially careful and deliberate, running an experiment with multiple inputs means that you&#x27;ll inevitably fuck up one of the inputs (or forget to change some data, or otherwise fail to do the steps necessary to reliably run the model again), leading to bad output. This is a reusability problem: you <i>can</i> do it right (one file per experiment, &quot;template&quot; spreadsheets, error handling logic), but in practice very few folks do this or even care.<p>Second, there&#x27;s no meaningful way to test. If you&#x27;ve got critical logic, there&#x27;s no way to write proper unit tests against the spreadsheet to ensure something hasn&#x27;t broken. If I had a dollar for every improperly written linear regression in a spreadsheet... Conversely, writing spreadsheets as code means that you can rest assured that important units of logic are sound, which pays dividends when you&#x27;re dealing with stuff used by a whole org.<p>Third, spreadsheets are really only useful as the &quot;last step&quot; in data processing. It&#x27;s not good or easy to use a spreadsheet as input to something else. The inputs to the spreadsheet are usually manually updated (importing a CSV as a sheet), and then the output is graphical by default unless you&#x27;re parsing the spreadsheet (good luck) or dumping it to CSV to import elsewhere (manual step with the risk of human error). In any business where the model you&#x27;re dealing with pipes into other processes, there&#x27;s almost always a manual step to get that data into &quot;the next thing&quot;, be it another model, a dashboard, a database, etc. You can hack around this, but I&#x27;ve never seen a hack here that isn&#x27;t incredibly brittle.<p>This isn&#x27;t to say that Excel is bad, but when you use it &quot;at scale&quot; there are very rough edges that dramatically increase the ongoing costs of running a business built around it. When you&#x27;re building a model, it&#x27;s great. When you&#x27;re running that model with different data more than a few dozen times a day and using the output in other systems, the costs quickly start to add up. That&#x27;s the point where someone needs to step in and say &quot;okay y&#x27;all, production use of this needs to run on a server&quot;. And if the production implementation is built well, you&#x27;ll often find it simplifies the lives of the analysts, because they can download a blob of already- or partially-processed data to work with.')