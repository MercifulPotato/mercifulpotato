Item(by='wutbrodo', descendants=None, kids=None, score=None, time=1607743739, title=None, item_type='comment', url=None, parent=25394650, text='TL;DR:\n&gt; Look at Reddit&#x27;s ban on toxic subreddits. They found that banning toxic subreddits reduced the toxicity in the website as a whole, and that &quot;post-ban, hate speech by the same users was reduced by as much as 80-90 percent.&quot;<p>No, they didn&#x27;t<p>----<p>&gt;  They found that banning toxic subreddits reduced the toxicity in the website as a whole, and that &quot;post-ban, hate speech by the same users was reduced by as much as 80-90 percent.&quot;<p>This only holds for the creative (and frankly, dishonest) definition of hate speech that the study[0] used.<p>&gt; First, we automatically extract\nterms which are unique to the two subreddits that were banned due to hate speech and harassment.\nThe resulting term list includes a number of words that indicate hate speech, as well as some\nother terms that appear to be specific to the Reddit context. We then qualitatively filter these lists,\nobtaining a high precision hate lexicon. These lexicons are publicly available to the community as\na resource.<p>Not only did they start from a corpus of _words unique to the banned subreddits_, they &quot;qualitatively&quot; filtered it down, with no description of the procedure used. Anyone who&#x27;s spent any time on smaller subs knows that they, like any online community, develop their own lexicons, up to and including jargon[1].  Everyone who&#x27;s ever gawked at hate subs like &#x2F;r&#x2F;coontown or &#x2F;r&#x2F;shitredditsays know that this tendency is on overdrive. A reduction in the vocabulary _unique_ to the banned subreddit means that a ban refugee from &#x2F;r&#x2F;fatpeoplehate could be just as active on &#x2F;r&#x2F;HamplanetHateMail (a non-banned sub mentioned in the study) but would be counted as vastly reducing her hate speech, as long as she switched from &#x2F;r&#x2F;fatpeoplehate&#x27;s &quot;landwhale&quot; to &#x2F;r&#x2F;hamplanethatemail&#x27;s preferred &quot;lard-ass&quot; (I made these examples up, as I&#x27;ve had little exposure to the fat-activist&#x2F;fat-hate corners of the Internet in particular).<p>What this study actually shows is: &quot;usernames from banned subreddits don&#x27;t go to other subreddit&#x27;s and communicate with the same username in the banned subreddit&#x27;s hyper-specific jargon&quot;. Which is to say, &quot;when a community is broken up and dispersed among other communities, the _specific_ inside jargon of the community is a lot less common, with no reference to whether the substance of the comments have changed&quot;.<p>I mean, duh.<p>This would perhaps be excusable in 2015 or something, but one should really know better by now than to uncritically cite popular coverage of sociology studies, particularly social-justice-aligned ones, without at least skimming the paper. Studies on hate speech are particular easy to check, given that (as this study puts it), &quot;there is no universally accepted definition of the phrase&quot;; at a minimum, seeing what they actually define as hate speech is core to understanding the findings. In this case, the authors start with a standard definition from the European Court of Human Rights and torture out a metric that&#x27;s convoluted, qualitative (in their own words!), and full of holes that the authors don&#x27;t even pretend not to fill with their own biases. (Seriously, I recommend reading Section 2.2)<p>[0] <a href="http:&#x2F;&#x2F;comp.social.gatech.edu&#x2F;papers&#x2F;cscw18-chand-hate.pdf" rel="nofollow">http:&#x2F;&#x2F;comp.social.gatech.edu&#x2F;papers&#x2F;cscw18-chand-hate.pdf</a>\n[1] Some examples: &quot;rentoid&quot; or &quot;renthog&quot; on &#x2F;r&#x2F;loveforlandlords, &quot;monkee&quot; on &#x2F;r&#x2F;PoliticalCompassMemes, and famously, &quot;shitlord&quot; on &#x2F;r&#x2F;shitredditsays back in the day)')