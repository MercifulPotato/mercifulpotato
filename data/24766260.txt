Item(by='CogentHedgehog', descendants=None, kids=None, score=None, time=1602601518, title=None, item_type='comment', url=None, parent=24764605, text='That&#x27;s a good speedup but why are they not using locality-sensitive hashing?  Or doing some basic math to convert X and Y to binned indices for a lookup table -- you can easily precompute values for a few million cells and hold them in memory.  If the lookup table is small enough it would even fit in a single CPU cache, and lookup would be nearly instant.  Both of these approaches provide O(1) lookup for grid cells rather than O(log n).<p>I used a similar optimization when I was younger to enable interactively plotting very large (at the time) 2D point datasets. We stripped out points that were so close together that the difference would not be visible.  The X,Y coordinates were each binned to an integer pixel location and both were packed into a single long integer.  Then we stored a hashset of longs so we knew what pixels had points occupied.  When adding a point to render, we did O(1) hashtable lookups to see if the location already had a point in it.  The result was an extreme speedup because we could avoid rendering all points which were not visible, and it scaled linearly with the number of points.')