Item(by='derangedHorse', descendants=None, kids=[25316197], score=None, time=1607182083, title=None, item_type='comment', url=None, parent=25314788, text='It&#x27;s always obvious in hindsight, much like what can be said of something like Dijkstra&#x27;s algorithm, but the fact of the matter is not everyone can spend the energy to both understand the context of the problem and direct their attention towards the evaluation of ethics within that context. Some people even find it hard to understand the situations of others enough to identify where their technologies can be used for harm.<p>The problem that AI ethics research addresses are ethical problems that executives and employees aren&#x27;t paying attention to. It may seem obvious when stated explicitly because of the amount of ease it takes to grasp the concepts (and the seemingly simple derivation of cause and effect relationships), but I assure you it is not obvious to a lot of people I know in the field at least.<p>There&#x27;s also a clear misunderstanding of what ethics research should entail:<p>* AI being forced to chose between two &quot;bad&quot; scenarios will result in an unfavorable outcome for one party<p>This is a trivial result that doesn&#x27;t hold much value as a standalone observation and probably wouldn&#x27;t be touted as a research point in a respectable publication of AI ethics.<p>* AI could reveal truths people don&#x27;t want to hear e.g. it might say the best team for a project is an all white male team between 25 - 30 rather than a more diverse team. It might say that a &#x27;perfect&#x27; society needs a homogeneous population.<p>The fact that you made this comment may be a cause for an ethics discussion in itself. You used &quot;truths&quot; to describe the statement &quot;the best team for a project is an all white male team between 25 - 30 rather than a more diverse team.&quot; This shows a disregard for the reality that most data is contextualized and biased. Using terms like &quot;best team&quot; and &quot;more diverse team&quot; make the statement like the one you made at risk for having took a misguided conclusion from data.<p>Maybe the following revised statement would be closer to what we can call a contextualized &quot;truth&quot; generated by an ML model:<p>&quot;Teams that comprise of white males between 25 - 30 have a statistically larger chance of meeting milestones set by leadership rather than teams with one or more non-white male.&quot;<p>Even statements like that aren&#x27;t complete as my definition of &quot;meeting milestones&quot; could be sourced from self-reported data (in which case it <i>could</i> mean that white males just self-report more milestone completions).<p>* AI could disrupt a lot of lower paid jobs first without governments having proper supports and retraining structures in place<p>A problem to consider, sure, but this is one of the more popular observations and has been echoed over time within the context of technological advancements in general.')