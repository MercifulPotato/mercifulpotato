Item(by='dklend122', descendants=None, kids=None, score=None, time=1603806268, title=None, item_type='comment', url=None, parent=24906584, text='I understand CPU is slower, but it&#x27;s not going anywhere, and matmul is just a benchmark.<p>It&#x27;s extremely impressive that a high level (using index notation for multiple backends) Julia library can compete with hand tuned kernels. Also bodes well for Julia compiler tech generally that can easily be extended<p>Julia is  going to get to the point of beating pytorch, just taking a but more time due to smaller team and approaching it from a more general position..so when it does it will be more flexible and ergonomic and easily extensible to new techniques, in pure Julia.<p>1.6 will be a big step as much of the compiler hacks underlying   the current ad&#x2F;gpu codegen (which just fell out accidentally of lispy design) will be replaced with proper tooling for composable compiler passes on typed IR. This will be a phase change imo.<p>There&#x27;s already a new faster AD that&#x27;s almost ready for debut based on 1.6 tech')