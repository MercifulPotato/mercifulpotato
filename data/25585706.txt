Item(by='ALittleLight', descendants=None, kids=[25586251, 25586996, 25586266, 25591326, 25589605, 25587184, 25586125, 25586169], score=None, time=1609360209, title=None, item_type='comment', url=None, parent=25584775, text='The article points out that the energy to train BERT is comparable to a flight across America. There are hundreds of thousands of flights every day - why should we be concerned about the equivalent of one extra? Especially given that BERT improves ~10% of English language Google search results, it seems like we&#x27;re getting a lot in return for relatively small energy use. On top of that, Google buys 100% of their energy usage from Green sources.<p>I think it&#x27;s great to talk about other methods of training or architectures that don&#x27;t require so many parameters. The point about how BERT consumes vastly more text than humans do when they learn to read is interesting. But trying to phrase this like an environmental issue just seems disingenuous and misleading.')