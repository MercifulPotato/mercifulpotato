Item(by='elmo2you', descendants=None, kids=None, score=None, time=1609759958, title=None, item_type='comment', url=None, parent=25629483, text='Let&#x27;s not forget that this is a commercial company.<p>Even if people will know it is a bot, these people&#x27;s rational capacities will in most cased be diminished under such circumstances, at best. Many will be easily (emotionally) manipulable, even more than with all the psychological trickery in product advertisement and big data exploitation these days.<p>Opinion: this clearly crosses the line of criminal behaviors, exploiting people who are clearly in a vulnerable positions (at least more than usual). I think the track record of tech companies rather clearly shows that their promised of taking good care of collected data (and privacy) mean little to nothing. At the end of the day, they do this for profit. That&#x27;s enough for me to make this cross the line.<p>Also, what&#x27;s really the &quot;invention&quot; here? Would something like this ever deserve a patent monopoly? If you take (dead) people&#x27;s personal data and build a neural net (or any other &quot;AI&quot;) to mimic&#x2F;compliment that data (needed for answering questions), have you not just done what any&#x2F;every neural net already does? If we&#x27;re going to call that novel and innovative, then hold my beer ... or is this just again a big tech company abusing the patent system to hijack an obvious (use of) technology, excluding anyone who doesn&#x27;t belong to their cozy little cross-licensing inbreed family from using what should be free to use in the first place?<p>#end-of-rant')