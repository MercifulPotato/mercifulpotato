Item(by='dragontamer', descendants=None, kids=[24982459], score=None, time=1604426189, title=None, item_type='comment', url=None, parent=24982027, text='Think of the following line of code:<p><pre><code>    blah = blah-&gt;next\n</code></pre>\nA simple linked-list traversal: 50-nanoseconds on a typical consumer CPU. This could represent a DOM-tree traversal. Or it could be a Javascript object being allocated. Or it could be the text getting added to the end of your rope-data structure. Or it could be a binary-search (finding a new address to check next). Or a malloc() (which traverses a linked-list to find memory). This dereference happens very often.<p>50-nanoseconds to hit main-RAM, 10-nanoseconds if L3 cache, 4-nanoseconds if in L2 cache, 1-nanosecond if in L1 cache.<p>This sort of operation is very fast on CPUs, especially if you&#x27;re cached. Heck, your CPU won&#x27;t even wait on the result: its going to branch-predict the answer and start executing the next bit of code before it even knows its correct.<p>----------<p>That same memory-dereference is 300-nanoseconds from GPU VRAM, and maybe 100-nanoseconds if you&#x27;re in GPU L1 cache.<p>If you got a tree, its probably going to be far faster to traverse on a CPU. Where the GPU wins is Raytracing: you can have millions of individual tasks traversing the same tree, in parallel, at larger overall bandwidths than a CPU ever could.<p>IE: GPUs can perform 1000 binary searches faster than a CPU can perform 1000 binary searches.<p>But how many applications need 1000 binary searches? Usually, you need 1 binary search, and once you get the result, you need to do something else. (And that result can be branch predicted for even further accelerations to speed).')