Item(by='fock', descendants=None, kids=None, score=None, time=1611650653, title=None, item_type='comment', url=None, parent=25912393, text='hmm, I&#x27;d like to digress<p>&gt;- Lots of different kinds of nodes<p>well, that&#x27;s not a problem of slurm (which will happily start your process on all nodes), but of typical MPI programming. And once you are running something computationally intensive over multiple nodes today, you are still using MPI.<p>&gt;- anything more complex dependency wise than a handful of shared Conda envs<p>you can put whatever dependencies you want on your NFS (or copy them to your node). If you&#x27;re running on a single node it behaves 100% like running with a special login shell on os XYZ, so I don&#x27;t know what problems happen with dependencies. The main problem would be that it doesn&#x27;t include any &quot;service discovery&quot; beyond OpenMPI.<p>&gt;- anything involving docker<p>have not used it, but there&#x27;s enroot&#x2F;singularity. The first of which is apparently dogfooded at Nvidia. Probably might need some adjustements for bases images (because MPI)... As I don&#x27;t know about the policy within these 5k+ cloud companies: can employees just execute any random image from dockerhub there? This seems a little dangerous...<p>&gt; anything vaguely untrusted<p>linked to the docker case? Does kubernetes reboot nodes then? Slurm can do this. And while classical Slurm use cases definitely require a shared account (because of the shared fs), slurm should afaik merrily execute your programs even without any shared account than slurm. You can attack this obviously, but so you can attack kubernetes and while it gets more scrutiny it&#x27;s also a byzantine collection of FANG-style requirements.<p>EDIT: What you can&#x27;t work around is Slurm needing a comms-channel back to the controller, which you though could just firewall off (jobs don&#x27;t use Slurm to communicate...). As each job can execute a Prolog-script, you can even only selectively allow traffic to flow between allocated nodes quite simply.<p>&gt;- any kind of partitioning worse than 3 nines e.g. connectivity or uptime instability<p>that&#x27;s indeed the case<p>&gt;- anything more complex than 3-5 priority levels of scheduling<p>what kind of scheduling does kubernetes implement? I guess you could write a plugin for slurm doing that<p>&gt; It&#x27;s great if you hit that niche but it frankly struggles with the complexities of even moderately heterogeneous work loads.<p>except that your points didn&#x27;t pertain to this (except maybe for the dependencies, if you think about actual service-dependencies), I fully agree')