Item(by='hansvm', descendants=None, kids=None, score=None, time=1607271007, title=None, item_type='comment', url=None, parent=25323949, text='Part of the reason this is interesting is that deep learning has to have some kind of inductive bias to perform as well as we&#x27;ve seen (given a learning problem, it&#x27;s biased toward learning in particular ways). In general though, a neural network can approximate _any_ function, so reigning in that complexity and uncovering which functions are actually learnable (or efficiently learnable) by deep learning is an important research direction. This paper says that the functions uncovered by deep learning (with caveats) are precisely those which are close to functions represented by a different learning technique, which is notable because this new class of functions is not &quot;all functions&quot; and because the characterization is explainable in some sense, giving insight into how deep learning works. That connection also winds up having a bunch of other interesting implications that somebody else can cover if they&#x27;d like.')