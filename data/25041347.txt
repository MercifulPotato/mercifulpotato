Item(by='m0zg', descendants=None, kids=[25041724], score=None, time=1604965529, title=None, item_type='comment', url=None, parent=25041209, text='The answere is unfortunately &quot;it&#x27;s complicated&quot; and &quot;it depends on the task&quot;. Very large EfficientNet variants are impractical anyway. For detection I&#x27;ve been very impressed with <a href="https:&#x2F;&#x2F;www.paperswithcode.com&#x2F;method&#x2F;vovnetv2" rel="nofollow">https:&#x2F;&#x2F;www.paperswithcode.com&#x2F;method&#x2F;vovnetv2</a>. You can use &quot;plain&quot; convolutions when you need higher accuracy and depthwise separable convolutions when you need speed, at the expense of a relatively small accuracy drop. Generally GPU hardware prefers the kind of nets where it can &quot;stretch its legs&quot; so to speak. VoVNet does have more parameters, but it&#x27;s _far_ easier to train to practical levels of accuracy, and it does well on NVIDIA hardware, and especially under TensorRT. Note that you can plug in VoVNet2 as a backbone into just about any detector, it doesn&#x27;t have to be CenterNet. For mobile GPUs MobileNet V3 is still adequate for a lot of things.<p>If anyone from NVIDIA is reading this, I feel like this is a good, and under-explored area of research that&#x27;d be very tractable for you: figure out architectures custom-designed to do well on recent NVIDIA GPUs, and especially on Jetson Xavier.<p>One thing people don&#x27;t realize is that EfficientNet&#x2F;EfficientDet aren&#x27;t necessarily the best choice _for their specific dataset_. In a way, a lot of these academic networks are overfit to the task of e.g. detecting objects in MSCOCO. If your dataset doesn&#x27;t look like MSCOCO, there&#x27;s no guarantee whatsoever that they will do well on it. Same with ImageNet for classification. ImageNet is very hard. To do well on it your net has to do something most humans won&#x27;t be able to do without substantial training - recognize the various dog breeds. If your problem is simpler (which nearly all of them are), chances are you don&#x27;t need as complicated a model to do well on it. Indeed, a &quot;complicated&quot; model is likely to actually do worse than a model that&#x27;s &quot;just complicated enough&quot;. Due to e.g. overfitting, or being more sensitive to noise in real-world data, and so on. Not to mention it will naturally limit your experiment throughput, which is one of the most important factors for getting a good model that does something practical.')